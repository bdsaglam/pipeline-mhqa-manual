{"id":"adeef57e52d2151538b028e975d5f9b6d5d197a2","name":"woven-salp","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.6633333333,"metrics.f1":0.775723564,"metrics.2hops.exact_match":0.7,"metrics.2hops.f1":0.8157623225,"metrics.3hops.exact_match":0.68,"metrics.3hops.f1":0.7759365079,"metrics.4hops.exact_match":0.61,"metrics.4hops.f1":0.7354718615,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"fea39a952605f42eb1fafacded2c761c06eab85e","name":"gutsy-vine","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.5966666667,"metrics.f1":0.7018764111,"metrics.2hops.exact_match":0.62,"metrics.2hops.f1":0.7502324079,"metrics.3hops.exact_match":0.6,"metrics.3hops.f1":0.6825555556,"metrics.4hops.exact_match":0.57,"metrics.4hops.f1":0.6728412698,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"5c32d10fbd52954c8ad351010a14273e3c2fce1b","name":"erect-furl","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.2833333333,"metrics.f1":0.346814901,"metrics.2hops.exact_match":0.7,"metrics.2hops.f1":0.8171951872,"metrics.3hops.exact_match":0.13,"metrics.3hops.f1":0.1719312705,"metrics.4hops.exact_match":0.02,"metrics.4hops.f1":0.0513182455,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"81514878020b22218c57033edd34039c5d326619","name":"sewed-limb","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0366666667,"metrics.f1":0.0463333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.1,"metrics.4hops.f1":0.129,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"667fbccdb702e97d387190d4cc16bd90f5d55da0","name":"azoic-noma","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.55,"metrics.f1":0.6634340474,"metrics.2hops.exact_match":0.66,"metrics.2hops.f1":0.7833351648,"metrics.3hops.exact_match":0.48,"metrics.3hops.f1":0.5882142857,"metrics.4hops.exact_match":0.51,"metrics.4hops.f1":0.6187526918,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"03504f312b9302f86e4892bb71ea0b1aa3b52f48","name":"toxic-plop","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.23,"metrics.f1":0.2897089947,"metrics.2hops.exact_match":0.36,"metrics.2hops.f1":0.4399047619,"metrics.3hops.exact_match":0.19,"metrics.3hops.f1":0.2486666667,"metrics.4hops.exact_match":0.14,"metrics.4hops.f1":0.1805555556,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"75e51f288ddbd35665f5ca1bb99f9951b8119201","name":"sixth-hood","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"d95622b74dc55bdde423a9f14a52bef70620a469","name":"bovid-feds","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"03828373bad7f9a8eaa4dbf280a60b2acb587001","name":"sulky-jake","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.01,"metrics.f1":0.0100501253,"metrics.2hops.exact_match":0.02,"metrics.2hops.f1":0.02,"metrics.3hops.exact_match":0.01,"metrics.3hops.f1":0.0101503759,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"29870df392409e41b2ec7e81b80cfd523509ccd2","name":"hefty-hate","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"28f00ad6caa559bf081dc9886fd295508afa73fa","name":"blest-jass","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.01,"metrics.f1":0.018031746,"metrics.2hops.exact_match":0.03,"metrics.2hops.f1":0.0540952381,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"c0aef6a645fee07623b2d870da2ab16dbefecdd2","name":"ahull-monk","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.16,"metrics.f1":0.196519992,"metrics.2hops.exact_match":0.29,"metrics.2hops.f1":0.3512319902,"metrics.3hops.exact_match":0.17,"metrics.3hops.f1":0.2048431373,"metrics.4hops.exact_match":0.02,"metrics.4hops.f1":0.0334848485,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"f513a0fee69e4ae1e3d49ee7b95c34d1a75d6fde","name":"split-gram","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"d71650f3da3232e353a2dc376c13bb4c7f959a6b","name":"spiry-fils","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"63a983f4be6d8cfcfee547dddf3816540c2021f6","name":"gutta-tuns","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0133333333,"metrics.f1":0.0180555556,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.015,"metrics.3hops.exact_match":0.01,"metrics.3hops.f1":0.0191666667,"metrics.4hops.exact_match":0.02,"metrics.4hops.f1":0.02,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"f7427ffe0ef20f416dc05124192a9970a114e83d","name":"pawky-cuss","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"5ad2ed4da79dcc2d8e7d1799f10100931acdd6df","name":"lurid-lien","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"6d510ec19d746f531e5942937ba1e770bc87a5ac","name":"messy-prat","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"12c2688f50e339ff934500f5e11c5d1f6040004e","name":"forky-daff","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"6ab02554978745f203d2bdb6e76a4266384587f9","name":"choky-junk","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0133333333,"metrics.f1":0.0191355311,"metrics.2hops.exact_match":0.04,"metrics.2hops.f1":0.0574065934,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"fe8ab3e130447a6fbd98f788dcb859f6d59c2216","name":"vatic-tarp","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"dfd5654c58b5c5f8a780fc69b4cd58ca9ff215a6","name":"tutti-loft","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0133333333,"metrics.f1":0.0166666667,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.03,"metrics.3hops.f1":0.04,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"cebd1ab61629aa8eee6a464c17c0185274c86a36","name":"dotal-toil","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"1fe3d46b5069cc6ed93d0548b54df10a1b594e8e","name":"world-ribs","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"f497a79f1bc3d42d4120242fc8bc18e9e82c5650","name":"quare-soft","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.5366666667,"metrics.f1":0.6572287157,"metrics.2hops.exact_match":0.65,"metrics.2hops.f1":0.7702142857,"metrics.3hops.exact_match":0.5,"metrics.3hops.f1":0.6055555556,"metrics.4hops.exact_match":0.46,"metrics.4hops.f1":0.5959163059,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"06a01cb4e915ca6ef09a6a9d5c4d3a1088bb6255","name":"bushy-azan","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0133333333,"metrics.f1":0.0166060606,"metrics.2hops.exact_match":0.04,"metrics.2hops.f1":0.0498181818,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"70c8be81b20452348c859e4c7f8d1cd9bea1fe2b","name":"hyoid-zips","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"4391d60c38f89864f839d3961b95a22f67d24e71","name":"cured-lier","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"d2f54ce9d88f7d6cac3e33bb732dedea933dff6c","name":"vogie-cull","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"279fd9d1d1fd95be335fa6709d91a8e84a431ec0","name":"bushy-scow","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"ad112feca762dee3452a04760fd55bf832b77ba1","name":"scary-darg","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"e2d09ca326b5a93a1662e675c3114e87b326d072","name":"eaten-dops","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"b65b67a66d6e888b7173af4aada77e029c68753f","name":"itchy-send","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"243f791f2c3bd1ac811cd46f1c2f365580ffe078","name":"batty-mene","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"82c5577e55eec25ced78184981014e39f31d6d85","name":"pawky-vows","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0066666667,"metrics.f1":0.0094444444,"metrics.2hops.exact_match":0.02,"metrics.2hops.f1":0.0283333333,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"9702eb9ceae42d05f9ec970e2422996108c0f5d1","name":"atrip-nave","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"d782f7b8fb902db7273e459c2f14d3f1ee91240d","name":"flush-auks","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"f75bb15bc5b962fc911cda29e69a1548b1df071d","name":"grapy-zags","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"a19c71a624f272269f455ddde883434c3cea1c1a","name":"strip-tics","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0041666667,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0025,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"f9a21245cbf8a12edeca4242952d89e4d04df8ae","name":"perdu-sike","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0633333333,"metrics.f1":0.0725793651,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.18,"metrics.4hops.f1":0.2077380952,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"be8f082e5fb39440a96e4729a84eb706c5643132","name":"curst-scow","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"48358d58931b3a82ce0538b647f9b35199e69cc7","name":"kacha-scud","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"2ea6df09f72ccbe10bffc342fe7048881ec8fb82","name":"slant-gray","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"79ac9a8cd6eeafa90f5a502eb35bd0a644e9e1b9","name":"japan-vega","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"a045a55895588effdec495ae0956960b3e11e2ba","name":"grand-dole","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"5cba0941e7cb870cc555252a69ec3d11dd6f3c4c","name":"amuck-vine","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"f579eb3eeafe85938ad5ba368b8d4c5db68aacec","name":"tacit-quay","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0333333333,"metrics.f1":0.0525238095,"metrics.2hops.exact_match":0.1,"metrics.2hops.f1":0.1575714286,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"bd07eadb68ec7bfc6bcfe0380d4287c99277d5bc","name":"rabic-seal","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0039393939,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0018181818,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"c54169eaa3aaa149f226e4888f1155888b7101b4","name":"sixty-barb","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"cb86e285941bd3f265088754855c0e564423a5bb","name":"xeric-coat","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.01,"metrics.f1":0.01,"metrics.2hops.exact_match":0.03,"metrics.2hops.f1":0.03,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"b96502acf013dc3353d934fb6c23948e9489feaa","name":"pudgy-gyms","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"c14478a958b1f14356f0f867150494e20aa998c2","name":"podgy-matt","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"7609f0224de15a7a787d86a6aa4989d78224d65e","name":"prize-razz","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0040740741,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0022222222,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"bc6c937c4bd09d3aacf969e0f431467255a145a3","name":"yarer-vela","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"8865c3ce8e14c241fa5cabe1ab49822b1385acd1","name":"sarky-whap","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0066666667,"metrics.f1":0.0066666667,"metrics.2hops.exact_match":0.02,"metrics.2hops.f1":0.02,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"a7bece698eea5a5dfdf56820d7bd6dbd4f3ac6d7","name":"taped-rial","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"1dc9257ea8120545c99fc4051a90ae2fef75ba6e","name":"peaty-moot","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"ec592cc7e27b67b96639c082320664bbf3f2299c","name":"sharp-joss","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0466666667,"metrics.f1":0.0585045788,"metrics.2hops.exact_match":0.14,"metrics.2hops.f1":0.1755137363,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"6b0dc72afa695bfa26d58a42b8e274b34c7dd614","name":"scrap-ball","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"d7a2f007228e7def0ce0bb5040494620a86fd005","name":"gamey-mush","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"e283f33286efe1bec6463b406d44c3d059c96f0d","name":"parky-sike","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"1a4794b6f29d742d4da56a74a43933d7e7a7f027","name":"oiled-dele","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"ac9a3d2ba7f5c49663031229d58f19039df49ef6","name":"fusil-pats","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0047979798,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.0143939394,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"37cb522ba27169cb628647e057aa3ba445d10503","name":"scaly-saut","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0,"metrics.f1":0.0153888889,"metrics.2hops.exact_match":0.0,"metrics.2hops.f1":0.004,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.013,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0291666667,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"0afe37931a57a6ef1099b112915930e93482fd2c","name":"eaten-mina","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0109786325,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.0329358974,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"b51bfbe40ba9046aca03b6c18bc085ac33736e80","name":"balmy-good","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"6365fdd097499453574d2065da12e72e11e5ea6a","name":"pavid-sere","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0066666667,"metrics.f1":0.0085714286,"metrics.2hops.exact_match":0.02,"metrics.2hops.f1":0.0257142857,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"21138f70f52679803300a1d9e386d64dc17cf155","name":"loved-sima","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0063286713,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0009090909,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0080769231,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"73014e1cc0b4353ff92aa62b1fc4c3ab20480d21","name":"smart-farl","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"a76872e239e3770497a922c897473fd9778d5855","name":"ovoid-pots","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0038461538,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0015384615,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"a24e38117fe8ae4f4dc4970fc74955e2e5dacabc","name":"splay-loss","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"ff6fa4ba1bf6714a9820434645137f1df1c77147","name":"massy-glee","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"f40c3962b6495514a64f202fd1e7ffe3f0d4f9bb","name":"burry-brio","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"fabf7f06b4ea258873bae9509d2b5959a180a61b","name":"swell-wart","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"4244f96da535e3cafc35188479a98c10eb65d45b","name":"gross-clay","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"d9422b0bdb7b36080be511397d18d51b9ec88157","name":"wrath-weep","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"59bfda66667b03df57c60e5348d96b506c8b681a","name":"focal-drab","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0054208754,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0044444444,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0018181818,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"7db8bab8ac41a10cb779409f02f12b499bd1f239","name":"bulgy-tarp","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"409b9629bf2cbfd6f6772e8afcaad0189193a57c","name":"guest-pump","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"e74643ceb4e1f809052e2e6c9776354c1c0030e4","name":"tatty-clay","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"4843c30c3b0033de07800724f72f9865f12a538b","name":"taunt-mesh","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.005,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.015,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"7472abd20cc516aa309b3bf9c83e66b7f07b17d6","name":"alive-acid","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"eb348406f373fc99cc3a897f565894b7c5c46a9f","name":"manky-mina","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"db8dfe0d347932b71a753cf0db3751f1788702e7","name":"sarky-rubs","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"f00e28d162ab210ae4de59e95a6d8dbfa8948628","name":"rowdy-roam","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"f2b11cc91795246991743fbcc71b0d62c60943b4","name":"techy-kale","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0766666667,"metrics.f1":0.0915916149,"metrics.2hops.exact_match":0.23,"metrics.2hops.f1":0.2747748447,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"0de3e5d97241e8c134bc2141000906da8f594f96","name":"japan-brio","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"bf017e66a98d1e7b6235c53f15c0e1ddb40e7d31","name":"fated-rugs","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0233333333,"metrics.f1":0.0273412698,"metrics.2hops.exact_match":0.07,"metrics.2hops.f1":0.0820238095,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"ab7e9e9981c0ed5723728895dd7f628706ad0381","name":"minim-army","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"82c3e1942a032882f57567fa941722c3c7b3a891","name":"volar-taal","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"0396ded069117711de6b9b60270bc8617dd68a19","name":"print-gula","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"2d7b8f92723bc21636d7fa702ccef93767b72960","name":"joint-dart","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"3449b4d448729a8f9dd9598602b6ce45e893e568","name":"spiny-cusp","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"f5bb83dd636c72e10723b1b834f52340ab0b9adf","name":"broch-vies","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"5eea4fb0433b903ba09c5aae306fb64b3bce3998","name":"cruel-fuzz","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0115417834,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.0244404762,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0101848739,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"22548357420d0d797841678ddccc27565ba615ea","name":"birch-dais","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"cb651711f1f92a611674c992543f09c2bb8cf1fb","name":"chirk-keep","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"6101cb17da4887e08caa253d0316fa212f5cd34b","name":"lucky-eric","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"5dba00b18c4e04ea5bcdcfc15a9e6957e2e15fc6","name":"kaput-pice","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"7789e7d905161c05cf8c98bfad95cd0e21bf156d","name":"based-sera","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"bd6577aabae0d3dcb0a0e595f3fab43ec7383193","name":"amuck-byte","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"414d1dbdcb77a8dd2c90638b2bd3406a014fb8c6","name":"astir-erns","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"ee3eca589b5f827cc0afcc7b70dda7572a928d37","name":"duddy-baby","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"6e93adc18ca70689807fed10e4690b4c499df2f5","name":"savvy-yank","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"d99a1ab0a1cc84642c2ccb85bd3e9887bc65d53d","name":"anile-boat","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"8633f3a8c62a707d89072297c931a8fdc9a10fb4","name":"crisp-joss","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0066666667,"metrics.f1":0.0158946609,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.01,"metrics.3hops.f1":0.031969697,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0057142857,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"8cdb0719619e201e3f5bd3ccfa8ae3d41367669c","name":"beery-belt","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"6ee2f90459185322fc228bdd2380b77eef369b9f","name":"rathe-soya","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"44b0bd6ab63c537a4a1b75b02b9842e464d8ca2b","name":"telic-grip","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"9d66b7c8a5279128a734afe5bf59d575978ca2e5","name":"slack-libs","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"f08dc2035d228a7c1ae0a36c78590e4bcd2632f6","name":"smoky-weld","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.1233333333,"metrics.f1":0.1525954786,"metrics.2hops.exact_match":0.13,"metrics.2hops.f1":0.1463015873,"metrics.3hops.exact_match":0.08,"metrics.3hops.f1":0.1106666667,"metrics.4hops.exact_match":0.16,"metrics.4hops.f1":0.2008181818,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"a12aa56bbb733bd04a4d607773aa798fe74d991d","name":"idled-huck","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"709e0e5aa79651ebe62b8f937a87fd7584fed8d1","name":"fresh-grig","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.02,"metrics.f1":0.0386426906,"metrics.2hops.exact_match":0.06,"metrics.2hops.f1":0.1109280719,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.005,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"b3d6fb79b0ee66351f65bc7ba0bd6ba42fbd8818","name":"dazed-abbs","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.58,"metrics.f1":0.6396777297,"metrics.2hops.exact_match":0.77,"metrics.2hops.f1":0.8420728716,"metrics.3hops.exact_match":0.69,"metrics.3hops.f1":0.7587936508,"metrics.4hops.exact_match":0.28,"metrics.4hops.f1":0.3181666667,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"4f11e2171cbf71581e361b5e56bbfcb08cb9868a","name":"dutch-shes","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0166666667,"metrics.f1":0.0268994709,"metrics.2hops.exact_match":0.02,"metrics.2hops.f1":0.030952381,"metrics.3hops.exact_match":0.03,"metrics.3hops.f1":0.0385555556,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0111904762,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"b8484e4bc60a1ff1cd8ef8b5f124f15b43de0b78","name":"dedal-noma","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":2,"metrics.exact_match":0.41,"metrics.f1":0.4745732323,"metrics.2hops.exact_match":0.69,"metrics.2hops.f1":0.7914570707,"metrics.3hops.exact_match":0.48,"metrics.3hops.f1":0.5617777778,"metrics.4hops.exact_match":0.06,"metrics.4hops.f1":0.0704848485,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"c634d2badd80f9d0b55382502d4443721e890b3a","name":"above-suss","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":2,"metrics.exact_match":0.0066666667,"metrics.f1":0.0066666667,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.01,"metrics.3hops.f1":0.01,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"797557be35432174b44b168e61f9a2b88937d781","name":"miffy-cart","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":2,"metrics.exact_match":0.0566666667,"metrics.f1":0.0778461081,"metrics.2hops.exact_match":0.17,"metrics.2hops.f1":0.2218716578,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0116666667,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"9f96037ea43cfed3c210bfd90f3b1f9a76b4342b","name":"sworn-vela","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":2,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"0cc87c10d0d5d3ae4fd5a594e8dbbe4ce8d6dd08","name":"licht-teff","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0066666667,"metrics.f1":0.0066666667,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.01,"metrics.4hops.f1":0.01,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":7.2533333333,"metrics.gen_token_count.all.std":15.0458326175,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":2.0,"metrics.gen_token_count.all.50%":4.0,"metrics.gen_token_count.all.75%":8.0,"metrics.gen_token_count.all.max":190.0,"metrics.gen_token_count.success.count":2.0,"metrics.gen_token_count.success.mean":19.5,"metrics.gen_token_count.success.std":20.5060966544,"metrics.gen_token_count.success.min":5.0,"metrics.gen_token_count.success.25%":12.25,"metrics.gen_token_count.success.50%":19.5,"metrics.gen_token_count.success.75%":26.75,"metrics.gen_token_count.success.max":34.0,"metrics.gen_token_count.fail.count":298.0,"metrics.gen_token_count.fail.mean":7.1711409396,"metrics.gen_token_count.fail.std":15.0156228196,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":2.0,"metrics.gen_token_count.fail.50%":4.0,"metrics.gen_token_count.fail.75%":8.0,"metrics.gen_token_count.fail.max":190.0,"params.qa.technique":"cot"}
{"id":"8d80c0c6fa4d7a0b0853486a9a9eaa79d6e63480","name":"cured-cart","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":1.1366666667,"metrics.gen_token_count.all.std":2.388235286,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":0.0,"metrics.gen_token_count.all.50%":1.0,"metrics.gen_token_count.all.75%":1.0,"metrics.gen_token_count.all.max":31.0,"metrics.gen_token_count.success.count":1.0,"metrics.gen_token_count.success.mean":0.0,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":0.0,"metrics.gen_token_count.success.25%":0.0,"metrics.gen_token_count.success.50%":0.0,"metrics.gen_token_count.success.75%":0.0,"metrics.gen_token_count.success.max":0.0,"metrics.gen_token_count.fail.count":299.0,"metrics.gen_token_count.fail.mean":1.1404682274,"metrics.gen_token_count.fail.std":2.3913296507,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":0.0,"metrics.gen_token_count.fail.50%":1.0,"metrics.gen_token_count.fail.75%":1.0,"metrics.gen_token_count.fail.max":31.0,"params.qa.technique":"cot"}
{"id":"7daeeeb67965b8d479e3f75daf0872a25a11d9ad","name":"balmy-orle","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":0.4766666667,"metrics.gen_token_count.all.std":1.0832205584,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":0.0,"metrics.gen_token_count.all.50%":0.0,"metrics.gen_token_count.all.75%":0.0,"metrics.gen_token_count.all.max":10.0,"metrics.gen_token_count.success.count":1.0,"metrics.gen_token_count.success.mean":0.0,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":0.0,"metrics.gen_token_count.success.25%":0.0,"metrics.gen_token_count.success.50%":0.0,"metrics.gen_token_count.success.75%":0.0,"metrics.gen_token_count.success.max":0.0,"metrics.gen_token_count.fail.count":299.0,"metrics.gen_token_count.fail.mean":0.4782608696,"metrics.gen_token_count.fail.std":1.0846839388,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":0.0,"metrics.gen_token_count.fail.50%":0.0,"metrics.gen_token_count.fail.75%":0.0,"metrics.gen_token_count.fail.max":10.0,"params.qa.technique":"ccot"}
{"id":"ee36d3dbccdac286b6df5fc67103140139458f03","name":"shock-chis","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.55,"metrics.f1":0.6525228264,"metrics.2hops.exact_match":0.62,"metrics.2hops.f1":0.7440588972,"metrics.3hops.exact_match":0.61,"metrics.3hops.f1":0.6837510352,"metrics.4hops.exact_match":0.42,"metrics.4hops.f1":0.5297585468,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"70d105c333ec6ed6fc58f8a82e9c29e84f5b8e9f","name":"worst-teff","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.6133333333,"metrics.f1":0.7405686242,"metrics.2hops.exact_match":0.68,"metrics.2hops.f1":0.7988150183,"metrics.3hops.exact_match":0.65,"metrics.3hops.f1":0.7552936508,"metrics.4hops.exact_match":0.51,"metrics.4hops.f1":0.6675972036,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"edf86131a1565f94f49aed680ae3b40dea18bc4c","name":"webby-dean","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.2733333333,"metrics.f1":0.3710312465,"metrics.2hops.exact_match":0.42,"metrics.2hops.f1":0.5527820513,"metrics.3hops.exact_match":0.19,"metrics.3hops.f1":0.271961039,"metrics.4hops.exact_match":0.21,"metrics.4hops.f1":0.2883506494,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"ffd1614d3ca6da1076f89d8190183454be15354b","name":"wormy-pein","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.46,"metrics.f1":0.5263314256,"metrics.2hops.exact_match":0.68,"metrics.2hops.f1":0.7625276101,"metrics.3hops.exact_match":0.49,"metrics.3hops.f1":0.5813555556,"metrics.4hops.exact_match":0.21,"metrics.4hops.f1":0.2351111111,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"483fd0e99f455a5b89cdcb409d78eb179a5c3909","name":"muzzy-coal","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.5933333333,"metrics.f1":0.6669603175,"metrics.2hops.exact_match":0.73,"metrics.2hops.f1":0.8134047619,"metrics.3hops.exact_match":0.64,"metrics.3hops.f1":0.7206190476,"metrics.4hops.exact_match":0.41,"metrics.4hops.f1":0.4668571429,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"970b4151b0a455ce60592f0832428fdb75c0fd74","name":"lower-lier","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"2e33e3f61ab0d2af7b6ca6c582e73fa0db4ed931","name":"flown-name","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"48efbc2613724440b629f375bb6573cceaf31bb6","name":"moody-sine","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"40bb70e277e514def0b36106c3e39898e88add0d","name":"gimpy-bree","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.2566666667,"metrics.f1":0.298015873,"metrics.2hops.exact_match":0.22,"metrics.2hops.f1":0.2849047619,"metrics.3hops.exact_match":0.33,"metrics.3hops.f1":0.3673333333,"metrics.4hops.exact_match":0.22,"metrics.4hops.f1":0.2418095238,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"4f654ad1686e597db674f43adb6587911fc247eb","name":"tenty-wads","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.01,"metrics.f1":0.0108333333,"metrics.2hops.exact_match":0.03,"metrics.2hops.f1":0.03,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0025,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"ae0fa527f8962d3c71d65c783a71fa6eeb8ada54","name":"comfy-cull","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.1366666667,"metrics.f1":0.1689126984,"metrics.2hops.exact_match":0.03,"metrics.2hops.f1":0.03,"metrics.3hops.exact_match":0.06,"metrics.3hops.f1":0.0821428571,"metrics.4hops.exact_match":0.32,"metrics.4hops.f1":0.3945952381,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"7d71802116254444bd5f0aab61e5f0f638fb9f6b","name":"guest-hull","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"0d027fc7a65a52cc294be49c2aa7ce7acee43588","name":"inner-tort","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"f65fa908cc676e8f0e5b4f93f648d57142bcf74e","name":"beady-keep","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"ba77af16af6ed734add7b9a15f1167ecf32e2017","name":"least-bael","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"5f865317e3797c61fe37b3264028e86ab28b289a","name":"cadgy-wise","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"bba108a971d85ac6c3a06db0660c9a88f129e0db","name":"outer-vlei","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"d1d7e8ccd3c62962ebce0bad40911cb6e5b993c2","name":"loamy-look","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"97bd50e4a1cd6bb7f249a53a0a53ea0768c34f0e","name":"least-pats","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"4489f00ff4e9aa5489602794ae7bc3381b95f661","name":"melic-clip","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"f412dfea3020face666cd66bed3b8856b4449f78","name":"aural-bait","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.16,"metrics.f1":0.1773433454,"metrics.2hops.exact_match":0.3,"metrics.2hops.f1":0.3200362319,"metrics.3hops.exact_match":0.15,"metrics.3hops.f1":0.1819938043,"metrics.4hops.exact_match":0.03,"metrics.4hops.f1":0.03,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"7cacbde889c1343bd9d28b8ce38a4c9b91c13245","name":"jaggy-keek","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"718a724f8bec09ce095dbf65fbf8e3915aeda4a5","name":"pyoid-mats","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0333333333,"metrics.f1":0.0470740741,"metrics.2hops.exact_match":0.09,"metrics.2hops.f1":0.1133333333,"metrics.3hops.exact_match":0.01,"metrics.3hops.f1":0.0256666667,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0022222222,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"080e36602cca13b70f7044068fbb9f6d3a463c3b","name":"about-clip","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"d73ab860b7889ec31d23ed9a9fd443dfc739330e","name":"agley-thar","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"9172f0b0dad9fbb384452421a383ec178646fac7","name":"loath-ludo","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"72cfe33da6e509553f9b802cc441a7c762b030dc","name":"iodic-tote","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0043202015,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.0129606046,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"b67228ea0df9597424e8140f0b2e7d26ad7ddf7e","name":"unapt-gude","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"d55d719a4d01a0388b74c4ff0dbfb398fe4a4f87","name":"beamy-quey","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"698ef2df3b8d6ec2a136b0b54f2c181333b642cc","name":"faint-life","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"c3c61a479b505cdfb76afd64b077f77f6f90a4c5","name":"ruddy-esse","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"0826bd912e8bbe6dbde853452f5df23d6f6ffea9","name":"nowed-tiff","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.1533333333,"metrics.f1":0.1902528892,"metrics.2hops.exact_match":0.46,"metrics.2hops.f1":0.5657586676,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.005,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"8e4e70cb64bf8d14c25a2d1df979453d95582442","name":"aspen-ados","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"5b3b61831c68c2d58bdb539068fe00a791190c86","name":"tutti-whop","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"9a87ec5670ef0dc242bafe9d9661e55cacc9b217","name":"bardy-jaws","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"4af6856cf63f7cd2e00afd559663c458fb8b8205","name":"melic-grip","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0133333333,"metrics.f1":0.02075,"metrics.2hops.exact_match":0.02,"metrics.2hops.f1":0.0289166667,"metrics.3hops.exact_match":0.02,"metrics.3hops.f1":0.0216666667,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0116666667,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"5a893ebb2d5f55337238087312d52e031721b075","name":"yarer-kids","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"53b56f5498764690de468a70233536e14130e2a1","name":"rabid-taka","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.006,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.018,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"00a1fc2c1d6f7e57ca8e8b280dcc099550a10492","name":"noted-mold","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"7226e9a9940dfbfc109843683612c43e8f511d8a","name":"humid-fils","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.1066666667,"metrics.f1":0.1200275444,"metrics.2hops.exact_match":0.32,"metrics.2hops.f1":0.3600826331,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"488acfb2b00b6ddee91227f0f932af44c08447cb","name":"soppy-doss","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.17,"metrics.f1":0.2069613672,"metrics.2hops.exact_match":0.24,"metrics.2hops.f1":0.2934475936,"metrics.3hops.exact_match":0.17,"metrics.3hops.f1":0.2241031746,"metrics.4hops.exact_match":0.1,"metrics.4hops.f1":0.1033333333,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"7441c5932732139f82c93dee485eb61a4833a861","name":"rusty-bunt","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033962264,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0001886792,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"319e1150a8df691233ebc6aa104b3f763c49d5e2","name":"melic-flit","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"993f639dac866abe24776a4723bfdbab0a3daf88","name":"undue-amyl","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.33,"metrics.f1":0.389039886,"metrics.2hops.exact_match":0.41,"metrics.2hops.f1":0.4763333333,"metrics.3hops.exact_match":0.24,"metrics.3hops.f1":0.2864273504,"metrics.4hops.exact_match":0.34,"metrics.4hops.f1":0.4043589744,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"db7422addff32e3af767b61ab46fda9579333fbf","name":"mossy-cors","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0166666667,"metrics.f1":0.0205,"metrics.2hops.exact_match":0.05,"metrics.2hops.f1":0.0598333333,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0016666667,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"f77da0378e96aa3e0bfe112affa9be14c1c1fb37","name":"yucky-axon","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"ac26f99aa9baecffb16cf5bc819df78837f05d00","name":"toric-rims","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"29486c44cdf48df308e976b0d8c85905351a6648","name":"weeny-size","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0133333333,"metrics.f1":0.0312380952,"metrics.2hops.exact_match":0.04,"metrics.2hops.f1":0.079,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.009,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0057142857,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"61d731dc606dbb6a2dc07b6e8a965bc63bae462a","name":"mesic-tors","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"451edd14bd17f47c19a155e251b500a4a8da8eb6","name":"buggy-teds","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"b896eba17f72d8d3554050506b2b288d1a4e4bf0","name":"uveal-yawl","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.37,"metrics.f1":0.4353873287,"metrics.2hops.exact_match":0.61,"metrics.2hops.f1":0.7120879121,"metrics.3hops.exact_match":0.43,"metrics.3hops.f1":0.4840740741,"metrics.4hops.exact_match":0.07,"metrics.4hops.f1":0.11,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"8dca32208ba0e60a5467ebcdc036756c57d063fa","name":"white-rede","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"b22b08ecbf17525ff86de12df2261ed276dcf5b9","name":"goofy-bolo","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.1266666667,"metrics.f1":0.1629891502,"metrics.2hops.exact_match":0.38,"metrics.2hops.f1":0.4889674507,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"caa2300584e58850f68ab14fa10d5786181bf535","name":"pupal-walk","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"828f1112f97261b41da33d4826d2c6c096ea8a00","name":"faery-sima","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"0334ed679ca6f44e1602e96ca3b94e04044d0aab","name":"elect-sech","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"bcb3c848161ff88f81ba617f19e02643550f3a67","name":"shill-furl","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"7b9064703975d2d36cd7f9895f10507f3da10560","name":"milky-plum","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"099a28e42497fced2c12e285fa1c4f221d849bb5","name":"piney-seam","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"b9f9ae9658677b40f12d4ff62063858ee351000f","name":"flory-cull","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"31e49bce83bb5695860e68fdc525888a97e711be","name":"calmy-shah","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0066666667,"metrics.f1":0.0082905983,"metrics.2hops.exact_match":0.02,"metrics.2hops.f1":0.0215384615,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0033333333,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"6454baed78a40a9db1587638f641b5ef384695a1","name":"quasi-saga","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"ae3ebbddeed568a2e68b15f198dd77267a6b7630","name":"nival-prob","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"be8e9395b262aadb106cd52942b93777d1bf21fb","name":"power-prat","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"0403e05c3c69d1006218e31c46a9ee352a5ff51a","name":"savvy-gird","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"d0e158d577be37845b4d6acd13407269ef83f487","name":"barky-ambo","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0366666667,"metrics.f1":0.0470799666,"metrics.2hops.exact_match":0.09,"metrics.2hops.f1":0.1052380952,"metrics.3hops.exact_match":0.02,"metrics.3hops.f1":0.0331038961,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0028979085,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"5df5970c2b01fda6c4e7bdd0a6b747aa1e66a80a","name":"toned-ossa","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0366666667,"metrics.f1":0.0489960317,"metrics.2hops.exact_match":0.11,"metrics.2hops.f1":0.1469880952,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"1092985eaeaf140f79362fd3e6d484050c021b37","name":"acold-neck","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"f6ea092930adc89cb7ea68fd0f519908703882f1","name":"tense-loge","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"54ed3b18ca57659b23c8a069ae0a5a5d84f2e2cc","name":"world-bate","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0066666667,"metrics.f1":0.0066666667,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.01,"metrics.4hops.f1":0.01,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"c392b39659a78ff8b1894ebc994bc19210940bd4","name":"slimy-fond","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"43c3dec805d32485e518cf32f58a91038131042f","name":"above-hows","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"adb00a59445d6cbdbc60d24bf724494fef429a03","name":"cased-mina","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"3ca63735a1c932b1dc67148404cb23ecd1e06e65","name":"fewer-chin","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"299f9668df3f8a30c2dbaa46c01b8036d4efb5f6","name":"least-bang","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0166666667,"metrics.f1":0.0229816207,"metrics.2hops.exact_match":0.05,"metrics.2hops.f1":0.0689448622,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"d90538f24d380ce4cea28bdd108f1191a1f259e0","name":"fetal-toke","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"f45cca27b37dc9daab1d8c6b143c9133a225ceb5","name":"sedgy-dado","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"3c012448c64d22857f713628f315b167da6e4175","name":"unapt-azan","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.18,"metrics.f1":0.2343167989,"metrics.2hops.exact_match":0.51,"metrics.2hops.f1":0.6584265873,"metrics.3hops.exact_match":0.03,"metrics.3hops.f1":0.0445238095,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"9fbcb6ca09074974575e54f7fb88fc2b3ca053b1","name":"bluff-wire","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0041666667,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0025,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"0c56fb4132c16881ad6cdbda72cf16a9aa56929e","name":"downy-flap","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.56,"metrics.f1":0.6887120657,"metrics.2hops.exact_match":0.65,"metrics.2hops.f1":0.7890494505,"metrics.3hops.exact_match":0.55,"metrics.3hops.f1":0.6568571429,"metrics.4hops.exact_match":0.48,"metrics.4hops.f1":0.6202296037,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"d7e98f5b5ed8a71ccf649d9a4c61391ca7644cc8","name":"goosy-pang","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"7530d5ba57e2a37338c5ccbe02555188cdc07046","name":"surgy-ibex","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"3860acd7494fc9eaf2332d7927d4ae2fe5a1a6fc","name":"truer-prob","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"03e8cbe39ba566ae7a331738ca10751004b8b62c","name":"regal-luce","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.09,"metrics.f1":0.1108453583,"metrics.2hops.exact_match":0.14,"metrics.2hops.f1":0.155,"metrics.3hops.exact_match":0.13,"metrics.3hops.f1":0.177536075,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"2d7a2be2a8e3b2b44761bc7714e42daecfcd6f6a","name":"perky-salp","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.57,"metrics.f1":0.6932057202,"metrics.2hops.exact_match":0.68,"metrics.2hops.f1":0.7898565324,"metrics.3hops.exact_match":0.52,"metrics.3hops.f1":0.6503015873,"metrics.4hops.exact_match":0.51,"metrics.4hops.f1":0.639459041,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"ce1f2d68d4f68853d0e9ab38257b9e5c93d2a027","name":"ruddy-axon","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0066666667,"metrics.f1":0.0100822511,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.012,"metrics.3hops.exact_match":0.01,"metrics.3hops.f1":0.0182467532,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"bf974f9c46c8b016a9c111703de5fec0604c1be7","name":"adust-dohs","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0533333333,"metrics.f1":0.0664570707,"metrics.2hops.exact_match":0.14,"metrics.2hops.f1":0.1793712121,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.02,"metrics.4hops.f1":0.02,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"4b4d7042cc99987b3981352dcb18925eaf67e6f5","name":"staid-eild","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.004,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.002,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"759713143c06d24111e5340f165ed3abdd50ba8f","name":"runic-loft","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"57534236d68577bc757c99c1d55936e9eb07442f","name":"mural-dean","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"946811817f60adf1353122bb7bbd9f886b7a692f","name":"group-pees","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0059040404,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.0137121212,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.004,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"e3b803a2d6d6b8631701770386de50ac1d1177f1","name":"dormy-doll","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.009485792,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.0143181818,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0074725275,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0066666667,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"6784667c02cae0b483024b5cf1fa51b853bd63ab","name":"mixed-duke","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"d014043104b3d5a1794aa8d94770445def2804ed","name":"felon-diva","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0,"metrics.f1":0.0050588928,"metrics.2hops.exact_match":0.0,"metrics.2hops.f1":0.0089385832,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0033809524,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0028571429,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"a6590eb9ec254f73a533ae487bd200a6fa9658bf","name":"tined-lees","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"7bdc5e2f6a50ecff761a68278aaf84de04a406a3","name":"fusil-seal","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0766666667,"metrics.f1":0.1048412698,"metrics.2hops.exact_match":0.07,"metrics.2hops.f1":0.1018571429,"metrics.3hops.exact_match":0.11,"metrics.3hops.f1":0.1403333333,"metrics.4hops.exact_match":0.05,"metrics.4hops.f1":0.0723333333,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"26609ca53cba44c7d9cb73b790a88e5437a79386","name":"beefy-poss","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"08e385a5314622720e307045657c6f1a4ea136c8","name":"beady-lich","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.64,"metrics.f1":0.7460815573,"metrics.2hops.exact_match":0.71,"metrics.2hops.f1":0.8332936508,"metrics.3hops.exact_match":0.6,"metrics.3hops.f1":0.6884300977,"metrics.4hops.exact_match":0.61,"metrics.4hops.f1":0.7165209235,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"7beadbaf44ce3af540dd6bd832d28678ceba16e6","name":"solar-cant","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.6733333333,"metrics.f1":0.7678440356,"metrics.2hops.exact_match":0.76,"metrics.2hops.f1":0.8570079365,"metrics.3hops.exact_match":0.64,"metrics.3hops.f1":0.7250436508,"metrics.4hops.exact_match":0.62,"metrics.4hops.f1":0.7214805195,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"6de86ef2e55c1b1cce53cab2da09615d073f3457","name":"stoic-coal","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.63,"metrics.f1":0.7366863877,"metrics.2hops.exact_match":0.71,"metrics.2hops.f1":0.8206428571,"metrics.3hops.exact_match":0.59,"metrics.3hops.f1":0.6882936508,"metrics.4hops.exact_match":0.59,"metrics.4hops.f1":0.7011226551,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"eb26a7fdcfa7fa6e117c171a57586c32ef28b71b","name":"moony-dops","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.03,"metrics.f1":0.0417186641,"metrics.2hops.exact_match":0.09,"metrics.2hops.f1":0.1251559922,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":31.88,"metrics.gen_token_count.all.std":185.3007289078,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":5.0,"metrics.gen_token_count.all.50%":9.0,"metrics.gen_token_count.all.75%":23.0,"metrics.gen_token_count.all.max":3083.0,"metrics.gen_token_count.success.count":12.0,"metrics.gen_token_count.success.mean":55.5833333333,"metrics.gen_token_count.success.std":52.821239415,"metrics.gen_token_count.success.min":17.0,"metrics.gen_token_count.success.25%":28.5,"metrics.gen_token_count.success.50%":35.0,"metrics.gen_token_count.success.75%":54.0,"metrics.gen_token_count.success.max":201.0,"metrics.gen_token_count.fail.count":288.0,"metrics.gen_token_count.fail.mean":30.8923611111,"metrics.gen_token_count.fail.std":188.7872321835,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":5.0,"metrics.gen_token_count.fail.50%":9.0,"metrics.gen_token_count.fail.75%":18.0,"metrics.gen_token_count.fail.max":3083.0,"params.qa.technique":"cte"}
{"id":"069559514288db6c57fcfa81a8bab2707b6ebd15","name":"surfy-dops","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.05,"metrics.f1":0.0593968254,"metrics.2hops.exact_match":0.15,"metrics.2hops.f1":0.1771904762,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.001,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":45.4966666667,"metrics.gen_token_count.all.std":252.5765488566,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":9.0,"metrics.gen_token_count.all.50%":16.0,"metrics.gen_token_count.all.75%":30.0,"metrics.gen_token_count.all.max":4234.0,"metrics.gen_token_count.success.count":17.0,"metrics.gen_token_count.success.mean":44.9411764706,"metrics.gen_token_count.success.std":26.5623572661,"metrics.gen_token_count.success.min":16.0,"metrics.gen_token_count.success.25%":30.0,"metrics.gen_token_count.success.50%":37.0,"metrics.gen_token_count.success.75%":45.0,"metrics.gen_token_count.success.max":115.0,"metrics.gen_token_count.fail.count":283.0,"metrics.gen_token_count.fail.mean":45.5300353357,"metrics.gen_token_count.fail.std":260.0012581441,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":9.0,"metrics.gen_token_count.fail.50%":15.0,"metrics.gen_token_count.fail.75%":29.0,"metrics.gen_token_count.fail.max":4234.0,"params.qa.technique":"cte"}
{"id":"d91b7675cb1b24005d21ad882a1e6f7066d40209","name":"podgy-areg","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.65,"metrics.f1":0.7480261792,"metrics.2hops.exact_match":0.74,"metrics.2hops.f1":0.83107493,"metrics.3hops.exact_match":0.66,"metrics.3hops.f1":0.742452381,"metrics.4hops.exact_match":0.55,"metrics.4hops.f1":0.6705512266,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":56.5766666667,"metrics.gen_token_count.all.std":21.8905178436,"metrics.gen_token_count.all.min":14.0,"metrics.gen_token_count.all.25%":40.0,"metrics.gen_token_count.all.50%":52.0,"metrics.gen_token_count.all.75%":69.25,"metrics.gen_token_count.all.max":164.0,"metrics.gen_token_count.success.count":224.0,"metrics.gen_token_count.success.mean":53.4107142857,"metrics.gen_token_count.success.std":18.9266005283,"metrics.gen_token_count.success.min":22.0,"metrics.gen_token_count.success.25%":39.0,"metrics.gen_token_count.success.50%":49.0,"metrics.gen_token_count.success.75%":64.25,"metrics.gen_token_count.success.max":118.0,"metrics.gen_token_count.fail.count":76.0,"metrics.gen_token_count.fail.mean":65.9078947368,"metrics.gen_token_count.fail.std":26.9652505429,"metrics.gen_token_count.fail.min":14.0,"metrics.gen_token_count.fail.25%":48.75,"metrics.gen_token_count.fail.50%":64.5,"metrics.gen_token_count.fail.75%":76.25,"metrics.gen_token_count.fail.max":164.0,"params.qa.technique":"cot"}
{"id":"437808024903f02dc8da19438c619cde1a8f7cd6","name":"gawsy-genu","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.1866666667,"metrics.f1":0.2404126984,"metrics.2hops.exact_match":0.32,"metrics.2hops.f1":0.3992380952,"metrics.3hops.exact_match":0.11,"metrics.3hops.f1":0.1553333333,"metrics.4hops.exact_match":0.13,"metrics.4hops.f1":0.1666666667,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":53.9666666667,"metrics.gen_token_count.all.std":32.5674841773,"metrics.gen_token_count.all.min":1.0,"metrics.gen_token_count.all.25%":31.0,"metrics.gen_token_count.all.50%":49.5,"metrics.gen_token_count.all.75%":69.0,"metrics.gen_token_count.all.max":302.0,"metrics.gen_token_count.success.count":67.0,"metrics.gen_token_count.success.mean":58.4925373134,"metrics.gen_token_count.success.std":40.6262988172,"metrics.gen_token_count.success.min":15.0,"metrics.gen_token_count.success.25%":34.5,"metrics.gen_token_count.success.50%":51.0,"metrics.gen_token_count.success.75%":72.0,"metrics.gen_token_count.success.max":302.0,"metrics.gen_token_count.fail.count":233.0,"metrics.gen_token_count.fail.mean":52.6652360515,"metrics.gen_token_count.fail.std":29.8293919225,"metrics.gen_token_count.fail.min":1.0,"metrics.gen_token_count.fail.25%":30.0,"metrics.gen_token_count.fail.50%":49.0,"metrics.gen_token_count.fail.75%":68.0,"metrics.gen_token_count.fail.max":178.0,"params.qa.technique":"cot"}
{"id":"8bc02803dc8348cbd55dcd2b3adb63dd71ff06eb","name":"grand-sack","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.3466666667,"metrics.f1":0.4003450047,"metrics.2hops.exact_match":0.55,"metrics.2hops.f1":0.6243207283,"metrics.3hops.exact_match":0.25,"metrics.3hops.f1":0.2987142857,"metrics.4hops.exact_match":0.24,"metrics.4hops.f1":0.278,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":51.4633333333,"metrics.gen_token_count.all.std":25.2613494257,"metrics.gen_token_count.all.min":1.0,"metrics.gen_token_count.all.25%":35.75,"metrics.gen_token_count.all.50%":47.5,"metrics.gen_token_count.all.75%":64.0,"metrics.gen_token_count.all.max":162.0,"metrics.gen_token_count.success.count":118.0,"metrics.gen_token_count.success.mean":52.4661016949,"metrics.gen_token_count.success.std":20.1378506578,"metrics.gen_token_count.success.min":22.0,"metrics.gen_token_count.success.25%":38.25,"metrics.gen_token_count.success.50%":48.0,"metrics.gen_token_count.success.75%":62.5,"metrics.gen_token_count.success.max":148.0,"metrics.gen_token_count.fail.count":182.0,"metrics.gen_token_count.fail.mean":50.8131868132,"metrics.gen_token_count.fail.std":28.1236072315,"metrics.gen_token_count.fail.min":1.0,"metrics.gen_token_count.fail.25%":33.0,"metrics.gen_token_count.fail.50%":46.0,"metrics.gen_token_count.fail.75%":64.0,"metrics.gen_token_count.fail.max":162.0,"params.qa.technique":"cot"}
{"id":"e1a28af32bd0957544658b900f517512dc02e06d","name":"leafy-taka","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.69,"metrics.f1":0.7738236994,"metrics.2hops.exact_match":0.78,"metrics.2hops.f1":0.8515511204,"metrics.3hops.exact_match":0.7,"metrics.3hops.f1":0.7655097769,"metrics.4hops.exact_match":0.59,"metrics.4hops.f1":0.7044102009,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":45.0066666667,"metrics.gen_token_count.all.std":12.4998978814,"metrics.gen_token_count.all.min":23.0,"metrics.gen_token_count.all.25%":36.0,"metrics.gen_token_count.all.50%":43.5,"metrics.gen_token_count.all.75%":52.0,"metrics.gen_token_count.all.max":90.0,"metrics.gen_token_count.success.count":228.0,"metrics.gen_token_count.success.mean":43.5570175439,"metrics.gen_token_count.success.std":11.5975576139,"metrics.gen_token_count.success.min":23.0,"metrics.gen_token_count.success.25%":36.0,"metrics.gen_token_count.success.50%":42.0,"metrics.gen_token_count.success.75%":50.25,"metrics.gen_token_count.success.max":90.0,"metrics.gen_token_count.fail.count":72.0,"metrics.gen_token_count.fail.mean":49.5972222222,"metrics.gen_token_count.fail.std":14.1368161069,"metrics.gen_token_count.fail.min":26.0,"metrics.gen_token_count.fail.25%":40.0,"metrics.gen_token_count.fail.50%":47.0,"metrics.gen_token_count.fail.75%":58.0,"metrics.gen_token_count.fail.max":89.0,"params.qa.technique":"cte"}
{"id":"a7a2e241b542f6cb1b43d50ed4e58bb5aa31335c","name":"jowly-kibe","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.34,"metrics.f1":0.4084603175,"metrics.2hops.exact_match":0.55,"metrics.2hops.f1":0.6508095238,"metrics.3hops.exact_match":0.27,"metrics.3hops.f1":0.3323333333,"metrics.4hops.exact_match":0.2,"metrics.4hops.f1":0.2422380952,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":40.1633333333,"metrics.gen_token_count.all.std":101.029102676,"metrics.gen_token_count.all.min":8.0,"metrics.gen_token_count.all.25%":25.0,"metrics.gen_token_count.all.50%":32.0,"metrics.gen_token_count.all.75%":41.25,"metrics.gen_token_count.all.max":1766.0,"metrics.gen_token_count.success.count":118.0,"metrics.gen_token_count.success.mean":35.6525423729,"metrics.gen_token_count.success.std":12.9531549921,"metrics.gen_token_count.success.min":15.0,"metrics.gen_token_count.success.25%":28.0,"metrics.gen_token_count.success.50%":34.0,"metrics.gen_token_count.success.75%":41.0,"metrics.gen_token_count.success.max":98.0,"metrics.gen_token_count.fail.count":182.0,"metrics.gen_token_count.fail.mean":43.0879120879,"metrics.gen_token_count.fail.std":129.3474611634,"metrics.gen_token_count.fail.min":8.0,"metrics.gen_token_count.fail.25%":23.25,"metrics.gen_token_count.fail.50%":31.0,"metrics.gen_token_count.fail.75%":42.0,"metrics.gen_token_count.fail.max":1766.0,"params.qa.technique":"ccot"}
{"id":"2e2be194ccef916f9f8496774991bbaa56a00830","name":"paled-mush","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.2466666667,"metrics.f1":0.3028650794,"metrics.2hops.exact_match":0.36,"metrics.2hops.f1":0.424,"metrics.3hops.exact_match":0.25,"metrics.3hops.f1":0.2983333333,"metrics.4hops.exact_match":0.13,"metrics.4hops.f1":0.1862619048,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":39.0133333333,"metrics.gen_token_count.all.std":23.9240679158,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":23.0,"metrics.gen_token_count.all.50%":35.0,"metrics.gen_token_count.all.75%":51.0,"metrics.gen_token_count.all.max":145.0,"metrics.gen_token_count.success.count":88.0,"metrics.gen_token_count.success.mean":42.4204545455,"metrics.gen_token_count.success.std":20.3180015257,"metrics.gen_token_count.success.min":5.0,"metrics.gen_token_count.success.25%":27.0,"metrics.gen_token_count.success.50%":38.0,"metrics.gen_token_count.success.75%":51.25,"metrics.gen_token_count.success.max":117.0,"metrics.gen_token_count.fail.count":212.0,"metrics.gen_token_count.fail.mean":37.5990566038,"metrics.gen_token_count.fail.std":25.1794431887,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":20.0,"metrics.gen_token_count.fail.50%":33.0,"metrics.gen_token_count.fail.75%":50.25,"metrics.gen_token_count.fail.max":145.0,"params.qa.technique":"cot"}
{"id":"8254525d6849bee9f63186fa5929ddbb824386b8","name":"lumpy-amyl","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0733333333,"metrics.f1":0.0964847375,"metrics.2hops.exact_match":0.17,"metrics.2hops.f1":0.2152637363,"metrics.3hops.exact_match":0.03,"metrics.3hops.f1":0.0408571429,"metrics.4hops.exact_match":0.02,"metrics.4hops.f1":0.0333333333,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":25.98,"metrics.gen_token_count.all.std":99.3411722046,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":9.0,"metrics.gen_token_count.all.50%":17.0,"metrics.gen_token_count.all.75%":26.0,"metrics.gen_token_count.all.max":1696.0,"metrics.gen_token_count.success.count":27.0,"metrics.gen_token_count.success.mean":30.2222222222,"metrics.gen_token_count.success.std":14.457719081,"metrics.gen_token_count.success.min":6.0,"metrics.gen_token_count.success.25%":20.5,"metrics.gen_token_count.success.50%":27.0,"metrics.gen_token_count.success.75%":36.5,"metrics.gen_token_count.success.max":65.0,"metrics.gen_token_count.fail.count":273.0,"metrics.gen_token_count.fail.mean":25.5604395604,"metrics.gen_token_count.fail.std":104.0496779814,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":8.0,"metrics.gen_token_count.fail.50%":16.0,"metrics.gen_token_count.fail.75%":25.0,"metrics.gen_token_count.fail.max":1696.0,"params.qa.technique":"ccot"}
{"id":"f55a988b59894c2ebdb1c227af14ecc853731984","name":"hunky-iron","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.6,"metrics.f1":0.6968361573,"metrics.2hops.exact_match":0.72,"metrics.2hops.f1":0.8370636206,"metrics.3hops.exact_match":0.54,"metrics.3hops.f1":0.6203919414,"metrics.4hops.exact_match":0.54,"metrics.4hops.f1":0.6330529101,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":7.1333333333,"metrics.gen_token_count.all.std":7.8277156735,"metrics.gen_token_count.all.min":3.0,"metrics.gen_token_count.all.25%":4.0,"metrics.gen_token_count.all.50%":5.0,"metrics.gen_token_count.all.75%":7.0,"metrics.gen_token_count.all.max":77.0,"metrics.gen_token_count.success.count":206.0,"metrics.gen_token_count.success.mean":5.6699029126,"metrics.gen_token_count.success.std":2.1225311605,"metrics.gen_token_count.success.min":3.0,"metrics.gen_token_count.success.25%":4.0,"metrics.gen_token_count.success.50%":5.0,"metrics.gen_token_count.success.75%":6.0,"metrics.gen_token_count.success.max":19.0,"metrics.gen_token_count.fail.count":94.0,"metrics.gen_token_count.fail.mean":10.3404255319,"metrics.gen_token_count.fail.std":13.1120507582,"metrics.gen_token_count.fail.min":3.0,"metrics.gen_token_count.fail.25%":4.0,"metrics.gen_token_count.fail.50%":5.0,"metrics.gen_token_count.fail.75%":9.0,"metrics.gen_token_count.fail.max":77.0,"params.qa.technique":"direct"}
