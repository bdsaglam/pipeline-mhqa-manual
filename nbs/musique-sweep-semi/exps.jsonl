{"id":"adeef57e52d2151538b028e975d5f9b6d5d197a2","name":"woven-salp","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.6633333333,"metrics.f1":0.775723564,"metrics.2hops.exact_match":0.7,"metrics.2hops.f1":0.8157623225,"metrics.3hops.exact_match":0.68,"metrics.3hops.f1":0.7759365079,"metrics.4hops.exact_match":0.61,"metrics.4hops.f1":0.7354718615,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"fea39a952605f42eb1fafacded2c761c06eab85e","name":"gutsy-vine","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.5966666667,"metrics.f1":0.7018764111,"metrics.2hops.exact_match":0.62,"metrics.2hops.f1":0.7502324079,"metrics.3hops.exact_match":0.6,"metrics.3hops.f1":0.6825555556,"metrics.4hops.exact_match":0.57,"metrics.4hops.f1":0.6728412698,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"5c32d10fbd52954c8ad351010a14273e3c2fce1b","name":"erect-furl","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.2833333333,"metrics.f1":0.346814901,"metrics.2hops.exact_match":0.7,"metrics.2hops.f1":0.8171951872,"metrics.3hops.exact_match":0.13,"metrics.3hops.f1":0.1719312705,"metrics.4hops.exact_match":0.02,"metrics.4hops.f1":0.0513182455,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"81514878020b22218c57033edd34039c5d326619","name":"sewed-limb","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0366666667,"metrics.f1":0.0463333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.1,"metrics.4hops.f1":0.129,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"667fbccdb702e97d387190d4cc16bd90f5d55da0","name":"azoic-noma","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.55,"metrics.f1":0.6634340474,"metrics.2hops.exact_match":0.66,"metrics.2hops.f1":0.7833351648,"metrics.3hops.exact_match":0.48,"metrics.3hops.f1":0.5882142857,"metrics.4hops.exact_match":0.51,"metrics.4hops.f1":0.6187526918,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"03504f312b9302f86e4892bb71ea0b1aa3b52f48","name":"toxic-plop","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.23,"metrics.f1":0.2897089947,"metrics.2hops.exact_match":0.36,"metrics.2hops.f1":0.4399047619,"metrics.3hops.exact_match":0.19,"metrics.3hops.f1":0.2486666667,"metrics.4hops.exact_match":0.14,"metrics.4hops.f1":0.1805555556,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"0cc87c10d0d5d3ae4fd5a594e8dbbe4ce8d6dd08","name":"licht-teff","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0066666667,"metrics.f1":0.0066666667,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.01,"metrics.4hops.f1":0.01,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":7.2533333333,"metrics.gen_token_count.all.std":15.0458326175,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":2.0,"metrics.gen_token_count.all.50%":4.0,"metrics.gen_token_count.all.75%":8.0,"metrics.gen_token_count.all.max":190.0,"metrics.gen_token_count.success.count":2.0,"metrics.gen_token_count.success.mean":19.5,"metrics.gen_token_count.success.std":20.5060966544,"metrics.gen_token_count.success.min":5.0,"metrics.gen_token_count.success.25%":12.25,"metrics.gen_token_count.success.50%":19.5,"metrics.gen_token_count.success.75%":26.75,"metrics.gen_token_count.success.max":34.0,"metrics.gen_token_count.fail.count":298.0,"metrics.gen_token_count.fail.mean":7.1711409396,"metrics.gen_token_count.fail.std":15.0156228196,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":2.0,"metrics.gen_token_count.fail.50%":4.0,"metrics.gen_token_count.fail.75%":8.0,"metrics.gen_token_count.fail.max":190.0,"params.qa.technique":"cot"}
{"id":"8d80c0c6fa4d7a0b0853486a9a9eaa79d6e63480","name":"cured-cart","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":1.1366666667,"metrics.gen_token_count.all.std":2.388235286,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":0.0,"metrics.gen_token_count.all.50%":1.0,"metrics.gen_token_count.all.75%":1.0,"metrics.gen_token_count.all.max":31.0,"metrics.gen_token_count.success.count":1.0,"metrics.gen_token_count.success.mean":0.0,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":0.0,"metrics.gen_token_count.success.25%":0.0,"metrics.gen_token_count.success.50%":0.0,"metrics.gen_token_count.success.75%":0.0,"metrics.gen_token_count.success.max":0.0,"metrics.gen_token_count.fail.count":299.0,"metrics.gen_token_count.fail.mean":1.1404682274,"metrics.gen_token_count.fail.std":2.3913296507,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":0.0,"metrics.gen_token_count.fail.50%":1.0,"metrics.gen_token_count.fail.75%":1.0,"metrics.gen_token_count.fail.max":31.0,"params.qa.technique":"cot"}
{"id":"7daeeeb67965b8d479e3f75daf0872a25a11d9ad","name":"balmy-orle","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":0.4766666667,"metrics.gen_token_count.all.std":1.0832205584,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":0.0,"metrics.gen_token_count.all.50%":0.0,"metrics.gen_token_count.all.75%":0.0,"metrics.gen_token_count.all.max":10.0,"metrics.gen_token_count.success.count":1.0,"metrics.gen_token_count.success.mean":0.0,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":0.0,"metrics.gen_token_count.success.25%":0.0,"metrics.gen_token_count.success.50%":0.0,"metrics.gen_token_count.success.75%":0.0,"metrics.gen_token_count.success.max":0.0,"metrics.gen_token_count.fail.count":299.0,"metrics.gen_token_count.fail.mean":0.4782608696,"metrics.gen_token_count.fail.std":1.0846839388,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":0.0,"metrics.gen_token_count.fail.50%":0.0,"metrics.gen_token_count.fail.75%":0.0,"metrics.gen_token_count.fail.max":10.0,"params.qa.technique":"ccot"}
{"id":"ee36d3dbccdac286b6df5fc67103140139458f03","name":"shock-chis","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.55,"metrics.f1":0.6525228264,"metrics.2hops.exact_match":0.62,"metrics.2hops.f1":0.7440588972,"metrics.3hops.exact_match":0.61,"metrics.3hops.f1":0.6837510352,"metrics.4hops.exact_match":0.42,"metrics.4hops.f1":0.5297585468,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"70d105c333ec6ed6fc58f8a82e9c29e84f5b8e9f","name":"worst-teff","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.6133333333,"metrics.f1":0.7405686242,"metrics.2hops.exact_match":0.68,"metrics.2hops.f1":0.7988150183,"metrics.3hops.exact_match":0.65,"metrics.3hops.f1":0.7552936508,"metrics.4hops.exact_match":0.51,"metrics.4hops.f1":0.6675972036,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"edf86131a1565f94f49aed680ae3b40dea18bc4c","name":"webby-dean","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.2733333333,"metrics.f1":0.3710312465,"metrics.2hops.exact_match":0.42,"metrics.2hops.f1":0.5527820513,"metrics.3hops.exact_match":0.19,"metrics.3hops.f1":0.271961039,"metrics.4hops.exact_match":0.21,"metrics.4hops.f1":0.2883506494,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"ffd1614d3ca6da1076f89d8190183454be15354b","name":"wormy-pein","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.46,"metrics.f1":0.5263314256,"metrics.2hops.exact_match":0.68,"metrics.2hops.f1":0.7625276101,"metrics.3hops.exact_match":0.49,"metrics.3hops.f1":0.5813555556,"metrics.4hops.exact_match":0.21,"metrics.4hops.f1":0.2351111111,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"483fd0e99f455a5b89cdcb409d78eb179a5c3909","name":"muzzy-coal","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.5933333333,"metrics.f1":0.6669603175,"metrics.2hops.exact_match":0.73,"metrics.2hops.f1":0.8134047619,"metrics.3hops.exact_match":0.64,"metrics.3hops.f1":0.7206190476,"metrics.4hops.exact_match":0.41,"metrics.4hops.f1":0.4668571429,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"970b4151b0a455ce60592f0832428fdb75c0fd74","name":"lower-lier","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"2e33e3f61ab0d2af7b6ca6c582e73fa0db4ed931","name":"flown-name","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"48efbc2613724440b629f375bb6573cceaf31bb6","name":"moody-sine","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"40bb70e277e514def0b36106c3e39898e88add0d","name":"gimpy-bree","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.2566666667,"metrics.f1":0.298015873,"metrics.2hops.exact_match":0.22,"metrics.2hops.f1":0.2849047619,"metrics.3hops.exact_match":0.33,"metrics.3hops.f1":0.3673333333,"metrics.4hops.exact_match":0.22,"metrics.4hops.f1":0.2418095238,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"4f654ad1686e597db674f43adb6587911fc247eb","name":"tenty-wads","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.01,"metrics.f1":0.0108333333,"metrics.2hops.exact_match":0.03,"metrics.2hops.f1":0.03,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0025,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"ae0fa527f8962d3c71d65c783a71fa6eeb8ada54","name":"comfy-cull","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.1366666667,"metrics.f1":0.1689126984,"metrics.2hops.exact_match":0.03,"metrics.2hops.f1":0.03,"metrics.3hops.exact_match":0.06,"metrics.3hops.f1":0.0821428571,"metrics.4hops.exact_match":0.32,"metrics.4hops.f1":0.3945952381,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"7d71802116254444bd5f0aab61e5f0f638fb9f6b","name":"guest-hull","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"0d027fc7a65a52cc294be49c2aa7ce7acee43588","name":"inner-tort","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"f65fa908cc676e8f0e5b4f93f648d57142bcf74e","name":"beady-keep","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"ba77af16af6ed734add7b9a15f1167ecf32e2017","name":"least-bael","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"5f865317e3797c61fe37b3264028e86ab28b289a","name":"cadgy-wise","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"bba108a971d85ac6c3a06db0660c9a88f129e0db","name":"outer-vlei","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"d1d7e8ccd3c62962ebce0bad40911cb6e5b993c2","name":"loamy-look","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"97bd50e4a1cd6bb7f249a53a0a53ea0768c34f0e","name":"least-pats","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"4489f00ff4e9aa5489602794ae7bc3381b95f661","name":"melic-clip","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"f412dfea3020face666cd66bed3b8856b4449f78","name":"aural-bait","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.16,"metrics.f1":0.1773433454,"metrics.2hops.exact_match":0.3,"metrics.2hops.f1":0.3200362319,"metrics.3hops.exact_match":0.15,"metrics.3hops.f1":0.1819938043,"metrics.4hops.exact_match":0.03,"metrics.4hops.f1":0.03,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"7cacbde889c1343bd9d28b8ce38a4c9b91c13245","name":"jaggy-keek","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"718a724f8bec09ce095dbf65fbf8e3915aeda4a5","name":"pyoid-mats","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0333333333,"metrics.f1":0.0470740741,"metrics.2hops.exact_match":0.09,"metrics.2hops.f1":0.1133333333,"metrics.3hops.exact_match":0.01,"metrics.3hops.f1":0.0256666667,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0022222222,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"080e36602cca13b70f7044068fbb9f6d3a463c3b","name":"about-clip","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"d73ab860b7889ec31d23ed9a9fd443dfc739330e","name":"agley-thar","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"9172f0b0dad9fbb384452421a383ec178646fac7","name":"loath-ludo","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"72cfe33da6e509553f9b802cc441a7c762b030dc","name":"iodic-tote","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0043202015,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.0129606046,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"b67228ea0df9597424e8140f0b2e7d26ad7ddf7e","name":"unapt-gude","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"d55d719a4d01a0388b74c4ff0dbfb398fe4a4f87","name":"beamy-quey","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"698ef2df3b8d6ec2a136b0b54f2c181333b642cc","name":"faint-life","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"c3c61a479b505cdfb76afd64b077f77f6f90a4c5","name":"ruddy-esse","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"0826bd912e8bbe6dbde853452f5df23d6f6ffea9","name":"nowed-tiff","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.1533333333,"metrics.f1":0.1902528892,"metrics.2hops.exact_match":0.46,"metrics.2hops.f1":0.5657586676,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.005,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"8e4e70cb64bf8d14c25a2d1df979453d95582442","name":"aspen-ados","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"5b3b61831c68c2d58bdb539068fe00a791190c86","name":"tutti-whop","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"9a87ec5670ef0dc242bafe9d9661e55cacc9b217","name":"bardy-jaws","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"4af6856cf63f7cd2e00afd559663c458fb8b8205","name":"melic-grip","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0133333333,"metrics.f1":0.02075,"metrics.2hops.exact_match":0.02,"metrics.2hops.f1":0.0289166667,"metrics.3hops.exact_match":0.02,"metrics.3hops.f1":0.0216666667,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0116666667,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"5a893ebb2d5f55337238087312d52e031721b075","name":"yarer-kids","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"53b56f5498764690de468a70233536e14130e2a1","name":"rabid-taka","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.006,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.018,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"00a1fc2c1d6f7e57ca8e8b280dcc099550a10492","name":"noted-mold","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"7226e9a9940dfbfc109843683612c43e8f511d8a","name":"humid-fils","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.1066666667,"metrics.f1":0.1200275444,"metrics.2hops.exact_match":0.32,"metrics.2hops.f1":0.3600826331,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"488acfb2b00b6ddee91227f0f932af44c08447cb","name":"soppy-doss","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.17,"metrics.f1":0.2069613672,"metrics.2hops.exact_match":0.24,"metrics.2hops.f1":0.2934475936,"metrics.3hops.exact_match":0.17,"metrics.3hops.f1":0.2241031746,"metrics.4hops.exact_match":0.1,"metrics.4hops.f1":0.1033333333,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"7441c5932732139f82c93dee485eb61a4833a861","name":"rusty-bunt","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033962264,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0001886792,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"319e1150a8df691233ebc6aa104b3f763c49d5e2","name":"melic-flit","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"993f639dac866abe24776a4723bfdbab0a3daf88","name":"undue-amyl","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.33,"metrics.f1":0.389039886,"metrics.2hops.exact_match":0.41,"metrics.2hops.f1":0.4763333333,"metrics.3hops.exact_match":0.24,"metrics.3hops.f1":0.2864273504,"metrics.4hops.exact_match":0.34,"metrics.4hops.f1":0.4043589744,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"db7422addff32e3af767b61ab46fda9579333fbf","name":"mossy-cors","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0166666667,"metrics.f1":0.0205,"metrics.2hops.exact_match":0.05,"metrics.2hops.f1":0.0598333333,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0016666667,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"f77da0378e96aa3e0bfe112affa9be14c1c1fb37","name":"yucky-axon","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"ac26f99aa9baecffb16cf5bc819df78837f05d00","name":"toric-rims","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"29486c44cdf48df308e976b0d8c85905351a6648","name":"weeny-size","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0133333333,"metrics.f1":0.0312380952,"metrics.2hops.exact_match":0.04,"metrics.2hops.f1":0.079,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.009,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0057142857,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"61d731dc606dbb6a2dc07b6e8a965bc63bae462a","name":"mesic-tors","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"451edd14bd17f47c19a155e251b500a4a8da8eb6","name":"buggy-teds","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"b896eba17f72d8d3554050506b2b288d1a4e4bf0","name":"uveal-yawl","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.37,"metrics.f1":0.4353873287,"metrics.2hops.exact_match":0.61,"metrics.2hops.f1":0.7120879121,"metrics.3hops.exact_match":0.43,"metrics.3hops.f1":0.4840740741,"metrics.4hops.exact_match":0.07,"metrics.4hops.f1":0.11,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"8dca32208ba0e60a5467ebcdc036756c57d063fa","name":"white-rede","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"b22b08ecbf17525ff86de12df2261ed276dcf5b9","name":"goofy-bolo","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.1266666667,"metrics.f1":0.1629891502,"metrics.2hops.exact_match":0.38,"metrics.2hops.f1":0.4889674507,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"caa2300584e58850f68ab14fa10d5786181bf535","name":"pupal-walk","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"828f1112f97261b41da33d4826d2c6c096ea8a00","name":"faery-sima","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"0334ed679ca6f44e1602e96ca3b94e04044d0aab","name":"elect-sech","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"bcb3c848161ff88f81ba617f19e02643550f3a67","name":"shill-furl","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"7b9064703975d2d36cd7f9895f10507f3da10560","name":"milky-plum","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"099a28e42497fced2c12e285fa1c4f221d849bb5","name":"piney-seam","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"b9f9ae9658677b40f12d4ff62063858ee351000f","name":"flory-cull","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"31e49bce83bb5695860e68fdc525888a97e711be","name":"calmy-shah","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0066666667,"metrics.f1":0.0082905983,"metrics.2hops.exact_match":0.02,"metrics.2hops.f1":0.0215384615,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0033333333,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"6454baed78a40a9db1587638f641b5ef384695a1","name":"quasi-saga","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"ae3ebbddeed568a2e68b15f198dd77267a6b7630","name":"nival-prob","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"be8e9395b262aadb106cd52942b93777d1bf21fb","name":"power-prat","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"0403e05c3c69d1006218e31c46a9ee352a5ff51a","name":"savvy-gird","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"d0e158d577be37845b4d6acd13407269ef83f487","name":"barky-ambo","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0366666667,"metrics.f1":0.0470799666,"metrics.2hops.exact_match":0.09,"metrics.2hops.f1":0.1052380952,"metrics.3hops.exact_match":0.02,"metrics.3hops.f1":0.0331038961,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0028979085,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"5df5970c2b01fda6c4e7bdd0a6b747aa1e66a80a","name":"toned-ossa","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0366666667,"metrics.f1":0.0489960317,"metrics.2hops.exact_match":0.11,"metrics.2hops.f1":0.1469880952,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"1092985eaeaf140f79362fd3e6d484050c021b37","name":"acold-neck","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"f6ea092930adc89cb7ea68fd0f519908703882f1","name":"tense-loge","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"54ed3b18ca57659b23c8a069ae0a5a5d84f2e2cc","name":"world-bate","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0066666667,"metrics.f1":0.0066666667,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.01,"metrics.4hops.f1":0.01,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"c392b39659a78ff8b1894ebc994bc19210940bd4","name":"slimy-fond","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"43c3dec805d32485e518cf32f58a91038131042f","name":"above-hows","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"adb00a59445d6cbdbc60d24bf724494fef429a03","name":"cased-mina","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"3ca63735a1c932b1dc67148404cb23ecd1e06e65","name":"fewer-chin","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"299f9668df3f8a30c2dbaa46c01b8036d4efb5f6","name":"least-bang","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0166666667,"metrics.f1":0.0229816207,"metrics.2hops.exact_match":0.05,"metrics.2hops.f1":0.0689448622,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"d90538f24d380ce4cea28bdd108f1191a1f259e0","name":"fetal-toke","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"f45cca27b37dc9daab1d8c6b143c9133a225ceb5","name":"sedgy-dado","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"3c012448c64d22857f713628f315b167da6e4175","name":"unapt-azan","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.18,"metrics.f1":0.2343167989,"metrics.2hops.exact_match":0.51,"metrics.2hops.f1":0.6584265873,"metrics.3hops.exact_match":0.03,"metrics.3hops.f1":0.0445238095,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"9fbcb6ca09074974575e54f7fb88fc2b3ca053b1","name":"bluff-wire","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0041666667,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0025,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"0c56fb4132c16881ad6cdbda72cf16a9aa56929e","name":"downy-flap","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.56,"metrics.f1":0.6887120657,"metrics.2hops.exact_match":0.65,"metrics.2hops.f1":0.7890494505,"metrics.3hops.exact_match":0.55,"metrics.3hops.f1":0.6568571429,"metrics.4hops.exact_match":0.48,"metrics.4hops.f1":0.6202296037,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"d7e98f5b5ed8a71ccf649d9a4c61391ca7644cc8","name":"goosy-pang","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"7530d5ba57e2a37338c5ccbe02555188cdc07046","name":"surgy-ibex","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"3860acd7494fc9eaf2332d7927d4ae2fe5a1a6fc","name":"truer-prob","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"03e8cbe39ba566ae7a331738ca10751004b8b62c","name":"regal-luce","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.09,"metrics.f1":0.1108453583,"metrics.2hops.exact_match":0.14,"metrics.2hops.f1":0.155,"metrics.3hops.exact_match":0.13,"metrics.3hops.f1":0.177536075,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"2d7a2be2a8e3b2b44761bc7714e42daecfcd6f6a","name":"perky-salp","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.57,"metrics.f1":0.6932057202,"metrics.2hops.exact_match":0.68,"metrics.2hops.f1":0.7898565324,"metrics.3hops.exact_match":0.52,"metrics.3hops.f1":0.6503015873,"metrics.4hops.exact_match":0.51,"metrics.4hops.f1":0.639459041,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"ce1f2d68d4f68853d0e9ab38257b9e5c93d2a027","name":"ruddy-axon","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0066666667,"metrics.f1":0.0100822511,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.012,"metrics.3hops.exact_match":0.01,"metrics.3hops.f1":0.0182467532,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"bf974f9c46c8b016a9c111703de5fec0604c1be7","name":"adust-dohs","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0533333333,"metrics.f1":0.0664570707,"metrics.2hops.exact_match":0.14,"metrics.2hops.f1":0.1793712121,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.02,"metrics.4hops.f1":0.02,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"4b4d7042cc99987b3981352dcb18925eaf67e6f5","name":"staid-eild","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.004,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.002,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"759713143c06d24111e5340f165ed3abdd50ba8f","name":"runic-loft","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"57534236d68577bc757c99c1d55936e9eb07442f","name":"mural-dean","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"946811817f60adf1353122bb7bbd9f886b7a692f","name":"group-pees","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"ccot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot-original.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0059040404,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.0137121212,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.004,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"e3b803a2d6d6b8631701770386de50ac1d1177f1","name":"dormy-doll","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.009485792,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.0143181818,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0074725275,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0066666667,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"6784667c02cae0b483024b5cf1fa51b853bd63ab","name":"mixed-duke","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"d014043104b3d5a1794aa8d94770445def2804ed","name":"felon-diva","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0,"metrics.f1":0.0050588928,"metrics.2hops.exact_match":0.0,"metrics.2hops.f1":0.0089385832,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0033809524,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0028571429,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cot"}
{"id":"a6590eb9ec254f73a533ae487bd200a6fa9658bf","name":"tined-lees","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"7bdc5e2f6a50ecff761a68278aaf84de04a406a3","name":"fusil-seal","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.0766666667,"metrics.f1":0.1048412698,"metrics.2hops.exact_match":0.07,"metrics.2hops.f1":0.1018571429,"metrics.3hops.exact_match":0.11,"metrics.3hops.f1":0.1403333333,"metrics.4hops.exact_match":0.05,"metrics.4hops.f1":0.0723333333,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"ccot"}
{"id":"26609ca53cba44c7d9cb73b790a88e5437a79386","name":"beefy-poss","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.0033333333,"metrics.f1":0.0033333333,"metrics.2hops.exact_match":0.01,"metrics.2hops.f1":0.01,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"cte"}
{"id":"08e385a5314622720e307045657c6f1a4ea136c8","name":"beady-lich","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.1,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.64,"metrics.f1":0.7460815573,"metrics.2hops.exact_match":0.71,"metrics.2hops.f1":0.8332936508,"metrics.3hops.exact_match":0.6,"metrics.3hops.f1":0.6884300977,"metrics.4hops.exact_match":0.61,"metrics.4hops.f1":0.7165209235,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"7beadbaf44ce3af540dd6bd832d28678ceba16e6","name":"solar-cant","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.7,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.6733333333,"metrics.f1":0.7678440356,"metrics.2hops.exact_match":0.76,"metrics.2hops.f1":0.8570079365,"metrics.3hops.exact_match":0.64,"metrics.3hops.f1":0.7250436508,"metrics.4hops.exact_match":0.62,"metrics.4hops.f1":0.7214805195,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"6de86ef2e55c1b1cce53cab2da09615d073f3457","name":"stoic-coal","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":1.0,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.63,"metrics.f1":0.7366863877,"metrics.2hops.exact_match":0.71,"metrics.2hops.f1":0.8206428571,"metrics.3hops.exact_match":0.59,"metrics.3hops.f1":0.6882936508,"metrics.4hops.exact_match":0.59,"metrics.4hops.f1":0.7011226551,"metrics.gen_token_count.all.count":null,"metrics.gen_token_count.all.mean":null,"metrics.gen_token_count.all.std":null,"metrics.gen_token_count.all.min":null,"metrics.gen_token_count.all.25%":null,"metrics.gen_token_count.all.50%":null,"metrics.gen_token_count.all.75%":null,"metrics.gen_token_count.all.max":null,"metrics.gen_token_count.success.count":null,"metrics.gen_token_count.success.mean":null,"metrics.gen_token_count.success.std":null,"metrics.gen_token_count.success.min":null,"metrics.gen_token_count.success.25%":null,"metrics.gen_token_count.success.50%":null,"metrics.gen_token_count.success.75%":null,"metrics.gen_token_count.success.max":null,"metrics.gen_token_count.fail.count":null,"metrics.gen_token_count.fail.mean":null,"metrics.gen_token_count.fail.std":null,"metrics.gen_token_count.fail.min":null,"metrics.gen_token_count.fail.25%":null,"metrics.gen_token_count.fail.50%":null,"metrics.gen_token_count.fail.75%":null,"metrics.gen_token_count.fail.max":null,"params.qa.technique":"direct"}
{"id":"eb26a7fdcfa7fa6e117c171a57586c32ef28b71b","name":"moony-dops","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.03,"metrics.f1":0.0417186641,"metrics.2hops.exact_match":0.09,"metrics.2hops.f1":0.1251559922,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.0,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":31.88,"metrics.gen_token_count.all.std":185.3007289078,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":5.0,"metrics.gen_token_count.all.50%":9.0,"metrics.gen_token_count.all.75%":23.0,"metrics.gen_token_count.all.max":3083.0,"metrics.gen_token_count.success.count":12.0,"metrics.gen_token_count.success.mean":55.5833333333,"metrics.gen_token_count.success.std":52.821239415,"metrics.gen_token_count.success.min":17.0,"metrics.gen_token_count.success.25%":28.5,"metrics.gen_token_count.success.50%":35.0,"metrics.gen_token_count.success.75%":54.0,"metrics.gen_token_count.success.max":201.0,"metrics.gen_token_count.fail.count":288.0,"metrics.gen_token_count.fail.mean":30.8923611111,"metrics.gen_token_count.fail.std":188.7872321835,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":5.0,"metrics.gen_token_count.fail.50%":9.0,"metrics.gen_token_count.fail.75%":18.0,"metrics.gen_token_count.fail.max":3083.0,"params.qa.technique":"cte"}
{"id":"069559514288db6c57fcfa81a8bab2707b6ebd15","name":"surfy-dops","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":1,"params.run":1,"metrics.exact_match":0.05,"metrics.f1":0.0593968254,"metrics.2hops.exact_match":0.15,"metrics.2hops.f1":0.1771904762,"metrics.3hops.exact_match":0.0,"metrics.3hops.f1":0.001,"metrics.4hops.exact_match":0.0,"metrics.4hops.f1":0.0,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":45.4966666667,"metrics.gen_token_count.all.std":252.5765488566,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":9.0,"metrics.gen_token_count.all.50%":16.0,"metrics.gen_token_count.all.75%":30.0,"metrics.gen_token_count.all.max":4234.0,"metrics.gen_token_count.success.count":17.0,"metrics.gen_token_count.success.mean":44.9411764706,"metrics.gen_token_count.success.std":26.5623572661,"metrics.gen_token_count.success.min":16.0,"metrics.gen_token_count.success.25%":30.0,"metrics.gen_token_count.success.50%":37.0,"metrics.gen_token_count.success.75%":45.0,"metrics.gen_token_count.success.max":115.0,"metrics.gen_token_count.fail.count":283.0,"metrics.gen_token_count.fail.mean":45.5300353357,"metrics.gen_token_count.fail.std":260.0012581441,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":9.0,"metrics.gen_token_count.fail.50%":15.0,"metrics.gen_token_count.fail.75%":29.0,"metrics.gen_token_count.fail.max":4234.0,"params.qa.technique":"cte"}
{"id":"d91b7675cb1b24005d21ad882a1e6f7066d40209","name":"podgy-areg","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.65,"metrics.f1":0.7480261792,"metrics.2hops.exact_match":0.74,"metrics.2hops.f1":0.83107493,"metrics.3hops.exact_match":0.66,"metrics.3hops.f1":0.742452381,"metrics.4hops.exact_match":0.55,"metrics.4hops.f1":0.6705512266,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":56.5766666667,"metrics.gen_token_count.all.std":21.8905178436,"metrics.gen_token_count.all.min":14.0,"metrics.gen_token_count.all.25%":40.0,"metrics.gen_token_count.all.50%":52.0,"metrics.gen_token_count.all.75%":69.25,"metrics.gen_token_count.all.max":164.0,"metrics.gen_token_count.success.count":224.0,"metrics.gen_token_count.success.mean":53.4107142857,"metrics.gen_token_count.success.std":18.9266005283,"metrics.gen_token_count.success.min":22.0,"metrics.gen_token_count.success.25%":39.0,"metrics.gen_token_count.success.50%":49.0,"metrics.gen_token_count.success.75%":64.25,"metrics.gen_token_count.success.max":118.0,"metrics.gen_token_count.fail.count":76.0,"metrics.gen_token_count.fail.mean":65.9078947368,"metrics.gen_token_count.fail.std":26.9652505429,"metrics.gen_token_count.fail.min":14.0,"metrics.gen_token_count.fail.25%":48.75,"metrics.gen_token_count.fail.50%":64.5,"metrics.gen_token_count.fail.75%":76.25,"metrics.gen_token_count.fail.max":164.0,"params.qa.technique":"cot"}
{"id":"437808024903f02dc8da19438c619cde1a8f7cd6","name":"gawsy-genu","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/original.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot-original.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.1866666667,"metrics.f1":0.2404126984,"metrics.2hops.exact_match":0.32,"metrics.2hops.f1":0.3992380952,"metrics.3hops.exact_match":0.11,"metrics.3hops.f1":0.1553333333,"metrics.4hops.exact_match":0.13,"metrics.4hops.f1":0.1666666667,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":53.9666666667,"metrics.gen_token_count.all.std":32.5674841773,"metrics.gen_token_count.all.min":1.0,"metrics.gen_token_count.all.25%":31.0,"metrics.gen_token_count.all.50%":49.5,"metrics.gen_token_count.all.75%":69.0,"metrics.gen_token_count.all.max":302.0,"metrics.gen_token_count.success.count":67.0,"metrics.gen_token_count.success.mean":58.4925373134,"metrics.gen_token_count.success.std":40.6262988172,"metrics.gen_token_count.success.min":15.0,"metrics.gen_token_count.success.25%":34.5,"metrics.gen_token_count.success.50%":51.0,"metrics.gen_token_count.success.75%":72.0,"metrics.gen_token_count.success.max":302.0,"metrics.gen_token_count.fail.count":233.0,"metrics.gen_token_count.fail.mean":52.6652360515,"metrics.gen_token_count.fail.std":29.8293919225,"metrics.gen_token_count.fail.min":1.0,"metrics.gen_token_count.fail.25%":30.0,"metrics.gen_token_count.fail.50%":49.0,"metrics.gen_token_count.fail.75%":68.0,"metrics.gen_token_count.fail.max":178.0,"params.qa.technique":"cot"}
{"id":"8bc02803dc8348cbd55dcd2b3adb63dd71ff06eb","name":"grand-sack","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.3466666667,"metrics.f1":0.4003450047,"metrics.2hops.exact_match":0.55,"metrics.2hops.f1":0.6243207283,"metrics.3hops.exact_match":0.25,"metrics.3hops.f1":0.2987142857,"metrics.4hops.exact_match":0.24,"metrics.4hops.f1":0.278,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":51.4633333333,"metrics.gen_token_count.all.std":25.2613494257,"metrics.gen_token_count.all.min":1.0,"metrics.gen_token_count.all.25%":35.75,"metrics.gen_token_count.all.50%":47.5,"metrics.gen_token_count.all.75%":64.0,"metrics.gen_token_count.all.max":162.0,"metrics.gen_token_count.success.count":118.0,"metrics.gen_token_count.success.mean":52.4661016949,"metrics.gen_token_count.success.std":20.1378506578,"metrics.gen_token_count.success.min":22.0,"metrics.gen_token_count.success.25%":38.25,"metrics.gen_token_count.success.50%":48.0,"metrics.gen_token_count.success.75%":62.5,"metrics.gen_token_count.success.max":148.0,"metrics.gen_token_count.fail.count":182.0,"metrics.gen_token_count.fail.mean":50.8131868132,"metrics.gen_token_count.fail.std":28.1236072315,"metrics.gen_token_count.fail.min":1.0,"metrics.gen_token_count.fail.25%":33.0,"metrics.gen_token_count.fail.50%":46.0,"metrics.gen_token_count.fail.75%":64.0,"metrics.gen_token_count.fail.max":162.0,"params.qa.technique":"cot"}
{"id":"e1a28af32bd0957544658b900f517512dc02e06d","name":"leafy-taka","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cte\/format-triplets-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cte.json","params.qa.n_shot":3,"params.run":1,"metrics.exact_match":0.69,"metrics.f1":0.7738236994,"metrics.2hops.exact_match":0.78,"metrics.2hops.f1":0.8515511204,"metrics.3hops.exact_match":0.7,"metrics.3hops.f1":0.7655097769,"metrics.4hops.exact_match":0.59,"metrics.4hops.f1":0.7044102009,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":45.0066666667,"metrics.gen_token_count.all.std":12.4998978814,"metrics.gen_token_count.all.min":23.0,"metrics.gen_token_count.all.25%":36.0,"metrics.gen_token_count.all.50%":43.5,"metrics.gen_token_count.all.75%":52.0,"metrics.gen_token_count.all.max":90.0,"metrics.gen_token_count.success.count":228.0,"metrics.gen_token_count.success.mean":43.5570175439,"metrics.gen_token_count.success.std":11.5975576139,"metrics.gen_token_count.success.min":23.0,"metrics.gen_token_count.success.25%":36.0,"metrics.gen_token_count.success.50%":42.0,"metrics.gen_token_count.success.75%":50.25,"metrics.gen_token_count.success.max":90.0,"metrics.gen_token_count.fail.count":72.0,"metrics.gen_token_count.fail.mean":49.5972222222,"metrics.gen_token_count.fail.std":14.1368161069,"metrics.gen_token_count.fail.min":26.0,"metrics.gen_token_count.fail.25%":40.0,"metrics.gen_token_count.fail.50%":47.0,"metrics.gen_token_count.fail.75%":58.0,"metrics.gen_token_count.fail.max":89.0,"params.qa.technique":"cte"}
{"id":"a7a2e241b542f6cb1b43d50ed4e58bb5aa31335c","name":"jowly-kibe","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.34,"metrics.f1":0.4084603175,"metrics.2hops.exact_match":0.55,"metrics.2hops.f1":0.6508095238,"metrics.3hops.exact_match":0.27,"metrics.3hops.f1":0.3323333333,"metrics.4hops.exact_match":0.2,"metrics.4hops.f1":0.2422380952,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":40.1633333333,"metrics.gen_token_count.all.std":101.029102676,"metrics.gen_token_count.all.min":8.0,"metrics.gen_token_count.all.25%":25.0,"metrics.gen_token_count.all.50%":32.0,"metrics.gen_token_count.all.75%":41.25,"metrics.gen_token_count.all.max":1766.0,"metrics.gen_token_count.success.count":118.0,"metrics.gen_token_count.success.mean":35.6525423729,"metrics.gen_token_count.success.std":12.9531549921,"metrics.gen_token_count.success.min":15.0,"metrics.gen_token_count.success.25%":28.0,"metrics.gen_token_count.success.50%":34.0,"metrics.gen_token_count.success.75%":41.0,"metrics.gen_token_count.success.max":98.0,"metrics.gen_token_count.fail.count":182.0,"metrics.gen_token_count.fail.mean":43.0879120879,"metrics.gen_token_count.fail.std":129.3474611634,"metrics.gen_token_count.fail.min":8.0,"metrics.gen_token_count.fail.25%":23.25,"metrics.gen_token_count.fail.50%":31.0,"metrics.gen_token_count.fail.75%":42.0,"metrics.gen_token_count.fail.max":1766.0,"params.qa.technique":"ccot"}
{"id":"2e2be194ccef916f9f8496774991bbaa56a00830","name":"paled-mush","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"cot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/cot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.2466666667,"metrics.f1":0.3028650794,"metrics.2hops.exact_match":0.36,"metrics.2hops.f1":0.424,"metrics.3hops.exact_match":0.25,"metrics.3hops.f1":0.2983333333,"metrics.4hops.exact_match":0.13,"metrics.4hops.f1":0.1862619048,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":39.0133333333,"metrics.gen_token_count.all.std":23.9240679158,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":23.0,"metrics.gen_token_count.all.50%":35.0,"metrics.gen_token_count.all.75%":51.0,"metrics.gen_token_count.all.max":145.0,"metrics.gen_token_count.success.count":88.0,"metrics.gen_token_count.success.mean":42.4204545455,"metrics.gen_token_count.success.std":20.3180015257,"metrics.gen_token_count.success.min":5.0,"metrics.gen_token_count.success.25%":27.0,"metrics.gen_token_count.success.50%":38.0,"metrics.gen_token_count.success.75%":51.25,"metrics.gen_token_count.success.max":117.0,"metrics.gen_token_count.fail.count":212.0,"metrics.gen_token_count.fail.mean":37.5990566038,"metrics.gen_token_count.fail.std":25.1794431887,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":20.0,"metrics.gen_token_count.fail.50%":33.0,"metrics.gen_token_count.fail.75%":50.25,"metrics.gen_token_count.fail.max":145.0,"params.qa.technique":"cot"}
{"id":"8254525d6849bee9f63186fa5929ddbb824386b8","name":"lumpy-amyl","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"ccot\/format-thought.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/ccot.json","params.qa.n_shot":0,"params.run":1,"metrics.exact_match":0.0733333333,"metrics.f1":0.0964847375,"metrics.2hops.exact_match":0.17,"metrics.2hops.f1":0.2152637363,"metrics.3hops.exact_match":0.03,"metrics.3hops.f1":0.0408571429,"metrics.4hops.exact_match":0.02,"metrics.4hops.f1":0.0333333333,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":25.98,"metrics.gen_token_count.all.std":99.3411722046,"metrics.gen_token_count.all.min":0.0,"metrics.gen_token_count.all.25%":9.0,"metrics.gen_token_count.all.50%":17.0,"metrics.gen_token_count.all.75%":26.0,"metrics.gen_token_count.all.max":1696.0,"metrics.gen_token_count.success.count":27.0,"metrics.gen_token_count.success.mean":30.2222222222,"metrics.gen_token_count.success.std":14.457719081,"metrics.gen_token_count.success.min":6.0,"metrics.gen_token_count.success.25%":20.5,"metrics.gen_token_count.success.50%":27.0,"metrics.gen_token_count.success.75%":36.5,"metrics.gen_token_count.success.max":65.0,"metrics.gen_token_count.fail.count":273.0,"metrics.gen_token_count.fail.mean":25.5604395604,"metrics.gen_token_count.fail.std":104.0496779814,"metrics.gen_token_count.fail.min":0.0,"metrics.gen_token_count.fail.25%":8.0,"metrics.gen_token_count.fail.50%":16.0,"metrics.gen_token_count.fail.75%":25.0,"metrics.gen_token_count.fail.max":1696.0,"params.qa.technique":"ccot"}
{"id":"f55a988b59894c2ebdb1c227af14ecc853731984","name":"hunky-iron","params.dataset.path":"bdsaglam\/musique-sweep","params.dataset.name":"answerable","params.dataset.split":"train","params.qa.model":"llama-3-70b-tgi","params.qa.temperature":0.5,"params.qa.system_prompt":"direct\/format-few.txt","params.qa.user_prompt_template":"cq.txt","params.qa.few_shot_examples":"semi\/direct.json","params.qa.n_shot":2,"params.run":1,"metrics.exact_match":0.6,"metrics.f1":0.6968361573,"metrics.2hops.exact_match":0.72,"metrics.2hops.f1":0.8370636206,"metrics.3hops.exact_match":0.54,"metrics.3hops.f1":0.6203919414,"metrics.4hops.exact_match":0.54,"metrics.4hops.f1":0.6330529101,"metrics.gen_token_count.all.count":300.0,"metrics.gen_token_count.all.mean":7.1333333333,"metrics.gen_token_count.all.std":7.8277156735,"metrics.gen_token_count.all.min":3.0,"metrics.gen_token_count.all.25%":4.0,"metrics.gen_token_count.all.50%":5.0,"metrics.gen_token_count.all.75%":7.0,"metrics.gen_token_count.all.max":77.0,"metrics.gen_token_count.success.count":206.0,"metrics.gen_token_count.success.mean":5.6699029126,"metrics.gen_token_count.success.std":2.1225311605,"metrics.gen_token_count.success.min":3.0,"metrics.gen_token_count.success.25%":4.0,"metrics.gen_token_count.success.50%":5.0,"metrics.gen_token_count.success.75%":6.0,"metrics.gen_token_count.success.max":19.0,"metrics.gen_token_count.fail.count":94.0,"metrics.gen_token_count.fail.mean":10.3404255319,"metrics.gen_token_count.fail.std":13.1120507582,"metrics.gen_token_count.fail.min":3.0,"metrics.gen_token_count.fail.25%":4.0,"metrics.gen_token_count.fail.50%":5.0,"metrics.gen_token_count.fail.75%":9.0,"metrics.gen_token_count.fail.max":77.0,"params.qa.technique":"direct"}
