{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_experiment_configs(params_record):\n",
    "    # Generate all possible combinations of parameters\n",
    "    keys = params_record.keys()\n",
    "    values = params_record.values()\n",
    "    for instance in itertools.product(*values):\n",
    "        yield dict(zip(keys, instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_configs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_params = {\n",
    "    \"params.dataset.path\": [\"bdsaglam/musique\"],\n",
    "    \"params.dataset.split\": [\"validation\"],\n",
    "    \"params.qa.temperature\": [\n",
    "        0.0,\n",
    "        # 0.5,\n",
    "        # 1.0,\n",
    "    ],\n",
    "    \"params.qa.user_prompt_template\": [\"cq.txt\"],\n",
    "    \"params.qa.n_sc\": [\n",
    "        1,\n",
    "    ],\n",
    "    \"params.run\": [\n",
    "        1,\n",
    "        2,\n",
    "        3,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_records = [\n",
    "    {\n",
    "        \"params.qa.model\": [\n",
    "            \"llama-3-8b\",\n",
    "            \"llama-3-70b\",\n",
    "            \"llama-3.3-70b\",\n",
    "        ],\n",
    "        \"params.qa.n_shot\": [\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        \"params.qa.system_prompt\": [\"direct/format-few.txt\"],\n",
    "        \"params.qa.few_shot_examples\": [\"manual/direct.json\"],\n",
    "    },\n",
    "    {\n",
    "        \"params.qa.model\": [\n",
    "            \"llama-3-8b\",\n",
    "            \"llama-3-70b\",\n",
    "            \"llama-3.3-70b\",\n",
    "        ],\n",
    "        \"params.qa.n_shot\": [\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        \"params.qa.system_prompt\": [\"cot/format-thought.txt\"],\n",
    "        \"params.qa.few_shot_examples\": [\"manual/cot.json\"],\n",
    "    },\n",
    "    {\n",
    "        \"params.qa.model\": [\n",
    "            \"llama-3-8b\",\n",
    "            \"llama-3-70b\",\n",
    "            \"llama-3.3-70b\",\n",
    "        ],\n",
    "        \"params.qa.n_shot\": [\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        \"params.qa.system_prompt\": [\"ccot/format-thought.txt\"],\n",
    "        \"params.qa.few_shot_examples\": [\"manual/ccot.json\"],\n",
    "    },\n",
    "    {\n",
    "        \"params.qa.model\": [\n",
    "            \"llama-3-8b\",\n",
    "            \"llama-3-70b\",\n",
    "            \"llama-3.3-70b\",\n",
    "        ],\n",
    "        \"params.qa.n_shot\": [\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        \"params.qa.system_prompt\": [\"cok/adapted.txt\"],\n",
    "        \"params.qa.few_shot_examples\": [\"manual/cok.json\"],\n",
    "    },\n",
    "    {\n",
    "        \"params.qa.model\": [\n",
    "            \"llama-3-8b\",\n",
    "            \"llama-3-70b\",\n",
    "            \"llama-3.3-70b\",\n",
    "        ],\n",
    "        \"params.qa.n_shot\": [\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        \"params.qa.system_prompt\": [\n",
    "            \"cte/format-triples-few.txt\",\n",
    "            \"cte/format-triples-ere-few.txt\",\n",
    "            \"cte/format-sro-triples-few.txt\",\n",
    "        ],\n",
    "        \"params.qa.few_shot_examples\": [\"manual/cte-triples.json\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# for params_record in params_records:\n",
    "#     for exp_config in product_experiment_configs({**common_params, **params_record}):\n",
    "#         exp_configs.append(exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_records = [\n",
    "    {\n",
    "        \"params.qa.model\": [\n",
    "            # \"deepseek-r1-llama-8b\",\n",
    "            \"deepseek-r1-llama-70b\",\n",
    "            # \"deepseek-r1-qwen-32b\",\n",
    "        ],\n",
    "        \"params.qa.n_shot\": [\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        \"params.qa.system_prompt\": [\"empty.txt\"],\n",
    "        \"params.qa.user_prompt_template\": [\"icq-format.txt\"],\n",
    "        \"params.qa.few_shot_examples\": [\"manual/reasoning.json\"],\n",
    "    },\n",
    "    # {\n",
    "    #     \"params.qa.model\": [\n",
    "    #         \"deepseek-r1-llama-8b\",\n",
    "    #         \"deepseek-r1-llama-70b\",\n",
    "    #         \"deepseek-r1-qwen-32b\",\n",
    "    #     ],\n",
    "    #     \"params.qa.n_shot\": [0],\n",
    "    #     \"params.qa.system_prompt\": [\"direct/format-few.txt\"],\n",
    "    #     \"params.qa.user_prompt_template\": [\"cq.txt\"],\n",
    "    #     \"params.qa.few_shot_examples\": [\"empty.json\"],\n",
    "    # },\n",
    "]\n",
    "\n",
    "for params_record in params_records:\n",
    "    for exp_config in product_experiment_configs({**common_params, **params_record}):\n",
    "        exp_configs.append(exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 experiment configurations\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(exp_configs)} experiment configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['params.dataset.path', 'params.dataset.split', 'params.qa.temperature', 'params.qa.user_prompt_template', 'params.qa.n_sc', 'params.run', 'params.qa.model', 'params.qa.n_shot', 'params.qa.system_prompt', 'params.qa.few_shot_examples'])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_params = exp_configs[0].keys()\n",
    "target_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392 experiments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '89ceb09a69f6dd22d587ad0e1d1161a7f31b166d',\n",
       " 'name': 'coxal-eyas',\n",
       " 'params.dataset.path': 'bdsaglam/musique',\n",
       " 'params.dataset.name': 'answerable',\n",
       " 'params.dataset.split': 'validation',\n",
       " 'params.qa.model': 'llama-3.3-70b',\n",
       " 'params.qa.temperature': 1.0,\n",
       " 'params.qa.system_prompt': 'cok/adapted.txt',\n",
       " 'params.qa.user_prompt_template': 'cq.txt',\n",
       " 'params.qa.few_shot_examples': 'manual/cok.json',\n",
       " 'params.qa.n_shot': 0,\n",
       " 'params.qa.n_sc': 1,\n",
       " 'params.run': 1,\n",
       " 'metrics.exact_match': 0.6052958213,\n",
       " 'metrics.f1': 0.72491734,\n",
       " 'metrics.2hops.exact_match': 0.642172524,\n",
       " 'metrics.2hops.f1': 0.7550383123,\n",
       " 'metrics.3hops.exact_match': 0.5815789474,\n",
       " 'metrics.3hops.f1': 0.7294157195,\n",
       " 'metrics.4hops.exact_match': 0.5358024691,\n",
       " 'metrics.4hops.f1': 0.6233612268,\n",
       " 'metrics.gen_token_count.all.count': 2417.0,\n",
       " 'metrics.gen_token_count.all.mean': 96.9242863053,\n",
       " 'metrics.gen_token_count.all.std': 26.7317829936,\n",
       " 'metrics.gen_token_count.all.min': 44.0,\n",
       " 'metrics.gen_token_count.all.25%': 80.0,\n",
       " 'metrics.gen_token_count.all.50%': 92.0,\n",
       " 'metrics.gen_token_count.all.75%': 108.0,\n",
       " 'metrics.gen_token_count.all.max': 283.0,\n",
       " 'metrics.gen_token_count.success.count': 1744.0,\n",
       " 'metrics.gen_token_count.success.mean': 94.8469036697,\n",
       " 'metrics.gen_token_count.success.std': 24.8118117643,\n",
       " 'metrics.gen_token_count.success.min': 44.0,\n",
       " 'metrics.gen_token_count.success.25%': 79.0,\n",
       " 'metrics.gen_token_count.success.50%': 91.0,\n",
       " 'metrics.gen_token_count.success.75%': 106.0,\n",
       " 'metrics.gen_token_count.success.max': 283.0,\n",
       " 'metrics.gen_token_count.fail.count': 673.0,\n",
       " 'metrics.gen_token_count.fail.mean': 102.3075780089,\n",
       " 'metrics.gen_token_count.fail.std': 30.5305109722,\n",
       " 'metrics.gen_token_count.fail.min': 45.0,\n",
       " 'metrics.gen_token_count.fail.25%': 83.0,\n",
       " 'metrics.gen_token_count.fail.50%': 94.0,\n",
       " 'metrics.gen_token_count.fail.75%': 114.0,\n",
       " 'metrics.gen_token_count.fail.max': 239.0,\n",
       " 'params.qa.technique': 'COK',\n",
       " 'params.qa.instruction': 'cok/adapted:cq:manual/cok'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_path = Path(\"exps.jsonl\")\n",
    "if results_path.exists():\n",
    "    with open(results_path) as f:\n",
    "        experiments = [json.loads(line) for line in f]\n",
    "else:\n",
    "    experiments = []\n",
    "\n",
    "print(f\"{len(experiments)} experiments\")\n",
    "next(iter(experiments), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392 experiments after preprocessing\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(experiments)\n",
    "\n",
    "param_cols = [col for col in df.columns if col.startswith(\"params.\")]\n",
    "metric_cols = [col for col in df.columns if col.startswith(\"metrics.\")]\n",
    "\n",
    "df.dropna(subset=param_cols, inplace=True, how=\"any\")\n",
    "df.drop_duplicates(subset=param_cols, inplace=True)\n",
    "\n",
    "print(f\"{len(df)} experiments after preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params.dataset.path': 'bdsaglam/musique',\n",
       " 'params.dataset.split': 'validation',\n",
       " 'params.qa.temperature': 1.0,\n",
       " 'params.qa.user_prompt_template': 'cq.txt',\n",
       " 'params.qa.n_sc': 1,\n",
       " 'params.run': 1,\n",
       " 'params.qa.model': 'llama-3.3-70b',\n",
       " 'params.qa.n_shot': 0,\n",
       " 'params.qa.system_prompt': 'cok/adapted.txt',\n",
       " 'params.qa.few_shot_examples': 'manual/cok.json'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(df):\n",
    "    existing_configs = df[target_params].to_dict(orient=\"records\")\n",
    "else:\n",
    "    existing_configs = []\n",
    "\n",
    "next(iter(existing_configs), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['params.dataset.path',\n",
       " 'params.dataset.split',\n",
       " 'params.qa.temperature',\n",
       " 'params.qa.user_prompt_template',\n",
       " 'params.qa.n_sc',\n",
       " 'params.qa.model',\n",
       " 'params.qa.n_shot',\n",
       " 'params.qa.system_prompt',\n",
       " 'params.qa.few_shot_examples']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_params = list({**common_params, **params_records[0]}.keys())\n",
    "target_params.remove(\"params.run\")\n",
    "target_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 missing configurations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'params.dataset.path': 'bdsaglam/musique',\n",
       " 'params.dataset.split': 'validation',\n",
       " 'params.qa.few_shot_examples': 'manual/reasoning.json',\n",
       " 'params.qa.model': 'deepseek-r1-llama-70b',\n",
       " 'params.qa.n_sc': 1,\n",
       " 'params.qa.n_shot': 1,\n",
       " 'params.qa.system_prompt': 'empty.txt',\n",
       " 'params.qa.temperature': 0.0,\n",
       " 'params.qa.user_prompt_template': 'icq-format.txt',\n",
       " 'params.run': 2}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the missing configurations\n",
    "missing_configs = [\n",
    "    dict(kv)\n",
    "    for kv in list(\n",
    "        {tuple(sorted(config.items())) for config in exp_configs}\n",
    "        - {tuple(sorted(config.items())) for config in existing_configs}\n",
    "    )\n",
    "]\n",
    "print(f\"{len(missing_configs)} missing configurations\")\n",
    "next(iter(missing_configs), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_command(exp_config, force: bool = False):\n",
    "    run = exp_config[\"params.run\"]\n",
    "    lines = []\n",
    "    if force:\n",
    "        lines.append(\"dvc exp run -f --queue\")\n",
    "    else:\n",
    "        lines.append(\"dvc exp run --queue\")\n",
    "    lines.append(f\"-S run={run}\")\n",
    "    for target_param in target_params:\n",
    "        arg_name = target_param.split(\".\", 1)[-1]\n",
    "        arg_value = exp_config[target_param]\n",
    "        lines.append(f\"-S {arg_name}='{arg_value}'\")\n",
    "\n",
    "    command = \" \\\\\\n    \".join(lines)\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"run.sh\", \"w\") as f:\n",
    "    f.write(\"#!/bin/sh\\n\\n\")\n",
    "    for exp_config in missing_configs:\n",
    "        f.write(make_command(exp_config, force=True))\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
