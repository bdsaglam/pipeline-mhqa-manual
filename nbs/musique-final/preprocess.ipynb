{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 experiments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'commit': 'workspace',\n",
       " 'id': 'workspace',\n",
       " 'name': None,\n",
       " 'params': {'dataset': {'path': 'bdsaglam/musique-mini',\n",
       "   'name': 'answerable',\n",
       "   'split': 'validation'},\n",
       "  'qa': {'model': 'llama-3-70b-tgi',\n",
       "   'temperature': 0.7,\n",
       "   'system_prompt': 'direct/helpful-output-format-few.txt',\n",
       "   'user_prompt_template': 'cq.txt',\n",
       "   'few_shot_examples': 'auto/direct.json',\n",
       "   'n_shot': 0},\n",
       "  'run': 1},\n",
       " 'metrics': {'exact_match': 0.55,\n",
       "  'f1': 0.6719070243482008,\n",
       "  'fuzzy_match': 0.6233333333333333,\n",
       "  '2hops': {'exact_match': 0.65,\n",
       "   'f1': 0.7548031968031969,\n",
       "   'fuzzy_match': 0.72},\n",
       "  '3hops': {'exact_match': 0.54,\n",
       "   'f1': 0.6851904761904762,\n",
       "   'fuzzy_match': 0.67},\n",
       "  '4hops': {'exact_match': 0.46,\n",
       "   'f1': 0.5757274000509295,\n",
       "   'fuzzy_match': 0.48},\n",
       "  'gen_token_count': {'all': {'count': 300.0,\n",
       "    'mean': 5.76,\n",
       "    'std': 1.939485847117882,\n",
       "    'min': 3.0,\n",
       "    '25%': 5.0,\n",
       "    '50%': 5.0,\n",
       "    '75%': 7.0,\n",
       "    'max': 13.0},\n",
       "   'success': {'count': 198.0,\n",
       "    'mean': 5.777777777777778,\n",
       "    'std': 1.6093354277137282,\n",
       "    'min': 3.0,\n",
       "    '25%': 5.0,\n",
       "    '50%': 5.0,\n",
       "    '75%': 6.0,\n",
       "    'max': 12.0},\n",
       "   'fail': {'count': 102.0,\n",
       "    'mean': 5.7254901960784315,\n",
       "    'std': 2.4662348050752017,\n",
       "    'min': 3.0,\n",
       "    '25%': 4.0,\n",
       "    '50%': 5.0,\n",
       "    '75%': 7.0,\n",
       "    'max': 13.0}}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bellem.dvc.experiment import load_experiments\n",
    "\n",
    "filepaths = list(Path(\"../../tmp/musique-final/\").glob(\"*.json\"))\n",
    "experiments = [exp for fp in filepaths for exp in load_experiments(fp)]\n",
    "print(f\"{len(experiments)} experiments\")\n",
    "experiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 experiments after preprocessing\n"
     ]
    }
   ],
   "source": [
    "df = pd.json_normalize(experiments).drop(columns=[\"commit\"])\n",
    "mask = (\n",
    "    (df[\"params.dataset.path\"] == \"bdsaglam/musique\") \n",
    ")\n",
    "\n",
    "df = df.loc[mask].copy()\n",
    "df.drop(columns=[col for col in df.columns if \"fuzzy\" in col], inplace=True)\n",
    "\n",
    "param_cols = [col for col in df.columns if col.startswith(\"params.\")]\n",
    "metric_cols = [col for col in df.columns if col.startswith(\"metrics.\")]\n",
    "df.dropna(subset=param_cols, inplace=True, how=\"any\")\n",
    "df.drop_duplicates(subset=param_cols + metric_cols, inplace=True)\n",
    "\n",
    "print(f\"{len(df)} experiments after preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_qa_technique(system_prompt_filename):\n",
    "    return system_prompt_filename.split(\"/\")[0]\n",
    "\n",
    "df[\"params.qa.technique\"] = df[\"params.qa.system_prompt\"].map(parse_qa_technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params.qa.system_prompt</th>\n",
       "      <th>params.qa.user_prompt_template</th>\n",
       "      <th>params.qa.few_shot_examples</th>\n",
       "      <th>params.qa.n_shot</th>\n",
       "      <th>params.qa.temperature</th>\n",
       "      <th>params.run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [params.qa.system_prompt, params.qa.user_prompt_template, params.qa.few_shot_examples, params.qa.n_shot, params.qa.temperature, params.run]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sorted_tuple(x):\n",
    "    return tuple(sorted(x))\n",
    "\n",
    "run_counts = (\n",
    "    df.groupby(\n",
    "        [\n",
    "            \"params.qa.system_prompt\",\n",
    "            \"params.qa.user_prompt_template\",\n",
    "            \"params.qa.few_shot_examples\",\n",
    "            \"params.qa.n_shot\",\n",
    "            \"params.qa.temperature\",\n",
    "        ]\n",
    "    )[\"params.run\"]\n",
    "    .aggregate(sorted_tuple)\n",
    "    .reset_index()\n",
    ")\n",
    "run_counts.loc[run_counts[\"params.run\"].map(len) != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- params.qa.system_prompt\n",
      "\tccot/format-thought.txt\n",
      "\tcot/format-thought.txt\n",
      "\tcte/excellent-format-triplets-few.txt\n",
      "\tcte/format-triplets-few.txt\n",
      "\tdirect/format-few.txt\n",
      "- params.qa.user_prompt_template\n",
      "\tcq.txt\n",
      "- params.qa.few_shot_examples\n",
      "\tauto/ccot.json\n",
      "\tauto/cot.json\n",
      "\tauto/cte.json\n",
      "\tauto/direct.json\n",
      "- params.qa.n_shot\n",
      "\t0\n",
      "\t1\n",
      "\t3\n",
      "\t6\n",
      "\t9\n",
      "- params.qa.temperature\n",
      "\t0.1\n",
      "\t0.5\n",
      "- params.run\n",
      "\t(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "for col in run_counts.columns:\n",
    "    print(f\"- {col}\")\n",
    "    for value in run_counts[col].unique():\n",
    "        print(f\"\\t{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('results.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
