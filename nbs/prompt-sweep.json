[{"rev": "workspace", "name": null, "data": {"rev": "workspace", "timestamp": null, "params": {"pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "no-role.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 1}}, "pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}}, "metrics": {"data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.586568361921958, "f1": 0.6939285759126523, "fuzzy_match": 0.6545290400240746, "2hops": {"exact_match": 0.6145659432387313, "f1": 0.7205072396670257, "fuzzy_match": 0.6814134668892599}, "3hops": {"exact_match": 0.49988602689765216, "f1": 0.6124656855355362, "fuzzy_match": 0.5767038978801003}, "4hops": {"exact_match": 0.5676595744680851, "f1": 0.6728926865097078, "fuzzy_match": 0.6161702127659574}}}, "data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}}, "deps": {"pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": null, "size": null, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/no-role.txt": {"hash": null, "size": null, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": null, "size": null, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": null, "size": null, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": null, "size": null, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": null, "size": null, "nfiles": null}, "pipelines/research-mhqa-evaluation/report.py": {"hash": null, "size": null, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": null, "size": null, "nfiles": null}, "pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": null, "size": null, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": null, "size": null, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": null, "size": null, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}, {"rev": "d6e184dbebe6e4188166ebb7fc393b5142ceaced", "name": "master", "data": {"rev": "d6e184dbebe6e4188166ebb7fc393b5142ceaced", "timestamp": "2024-10-30T10:47:54", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "no-role.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"error": {"type": "FileNotFoundError", "msg": "[Errno 2] No storage files available: 'data/generated/research-mhqa-evaluation/reports/scores.json'"}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": null, "size": null, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/no-role.txt": {"hash": null, "size": null, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": null, "size": null, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": null, "size": null, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": null, "size": null, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": null, "size": null, "nfiles": null}, "pipelines/research-mhqa-evaluation/report.py": {"hash": null, "size": null, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": null, "size": null, "nfiles": null}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": null, "size": null, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": null, "size": null, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": null, "size": null, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": [{"revs": [{"rev": "7e9bbe3d98cdec1c77407592c1b6b8cb858d341f", "name": "gulfy-beth", "data": {"rev": "7e9bbe3d98cdec1c77407592c1b6b8cb858d341f", "timestamp": "2024-10-31T19:08:00", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cot.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5370293752585851, "f1": 0.6595111909549376, "fuzzy_match": 0.6143980140670252, "2hops": {"exact_match": 0.6006389776357828, "f1": 0.7231909927146775, "fuzzy_match": 0.6717252396166135}, "3hops": {"exact_match": 0.49473684210526314, "f1": 0.6316824712954743, "fuzzy_match": 0.6026315789473684}, "4hops": {"exact_match": 0.41975308641975306, "f1": 0.5148759196907345, "fuzzy_match": 0.45925925925925926}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cot.txt": {"hash": "88021337dd159156750cbb8a8f3e2dc6", "size": 175, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "dde852cf4722694f1d96e677d7623118.dir", "size": 10061663, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "dc6487be504d1c0562de8b49de8db58c.dir", "size": 390868, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "dde852cf4722694f1d96e677d7623118.dir", "size": 10061663, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "dc6487be504d1c0562de8b49de8db58c.dir", "size": 390868, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "00135772aeb3626dfe27baf116cbb0cb", "size": 9873089, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/c0dc287e00c3ac21978d0fa89e5528996c5ef29c/c0dc287e00c3ac21978d0fa89e5528996c5ef29c.out", "pid": 2411660, "returncode": 0, "task_id": "c0dc287e00c3ac21978d0fa89e5528996c5ef29c"}}, "name": "gulfy-beth"}, {"revs": [{"rev": "621a34207ad82542fe1f50942d8d2a3c51b1676b", "name": "ropey-lama", "data": {"rev": "621a34207ad82542fe1f50942d8d2a3c51b1676b", "timestamp": "2024-10-31T19:02:14", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cot.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.533305750930906, "f1": 0.6575636831179676, "fuzzy_match": 0.6061232933388498, "2hops": {"exact_match": 0.5902555910543131, "f1": 0.7161011143298307, "fuzzy_match": 0.6613418530351438}, "3hops": {"exact_match": 0.4986842105263158, "f1": 0.6307297012985867, "fuzzy_match": 0.5960526315789474}, "4hops": {"exact_match": 0.4222222222222222, "f1": 0.5269586517734666, "fuzzy_match": 0.454320987654321}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cot.txt": {"hash": "88021337dd159156750cbb8a8f3e2dc6", "size": 175, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "442aff3c1798c23bfd1f3cfcdb569443.dir", "size": 10062376, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "713dd7dd8a72efe325d0e41c8c875f42.dir", "size": 391492, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "442aff3c1798c23bfd1f3cfcdb569443.dir", "size": 10062376, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "713dd7dd8a72efe325d0e41c8c875f42.dir", "size": 391492, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "252fac0a188fc556ffa19b927e628758", "size": 9874471, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/01b705f1ed6191f6462b238c25a78f57035949b5/01b705f1ed6191f6462b238c25a78f57035949b5.out", "pid": 2401452, "returncode": 0, "task_id": "01b705f1ed6191f6462b238c25a78f57035949b5"}}, "name": "ropey-lama"}, {"revs": [{"rev": "7d4a8047a88f0846d2e2e31fe243cbed7d5b79a7", "name": "bluer-weep", "data": {"rev": "7d4a8047a88f0846d2e2e31fe243cbed7d5b79a7", "timestamp": "2024-10-31T19:02:07", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cot.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5353744311129499, "f1": 0.6556249844885169, "fuzzy_match": 0.6069507654116674, "2hops": {"exact_match": 0.5894568690095847, "f1": 0.7110203580051204, "fuzzy_match": 0.6565495207667732}, "3hops": {"exact_match": 0.5052631578947369, "f1": 0.6387328791779256, "fuzzy_match": 0.6065789473684211}, "4hops": {"exact_match": 0.4246913580246914, "f1": 0.516076817558299, "fuzzy_match": 0.454320987654321}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cot.txt": {"hash": "88021337dd159156750cbb8a8f3e2dc6", "size": 175, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "ee4a6d1d2fa04a91906df5512b4295ee.dir", "size": 10058922, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "c1b1909247fb1c753da3956e58f1ca74.dir", "size": 391006, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "ee4a6d1d2fa04a91906df5512b4295ee.dir", "size": 10058922, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "c1b1909247fb1c753da3956e58f1ca74.dir", "size": 391006, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "6f8e1170dd669074aa1d7657f85779ff", "size": 9870513, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/67efa6a7b4ab184a612e74db5d1d43f37fed2d9b/67efa6a7b4ab184a612e74db5d1d43f37fed2d9b.out", "pid": 2401783, "returncode": 0, "task_id": "67efa6a7b4ab184a612e74db5d1d43f37fed2d9b"}}, "name": "bluer-weep"}, {"revs": [{"rev": "bb79efe0047e39115bf9686b5a8b39d89172e876", "name": "score-areg", "data": {"rev": "bb79efe0047e39115bf9686b5a8b39d89172e876", "timestamp": "2024-10-31T19:00:03", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.0, "f1": 9.194134142417137e-05, "fuzzy_match": 0.0, "2hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}, "3hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}, "4hops": {"exact_match": 0.0, "f1": 0.0005486968449931412, "fuzzy_match": 0.0}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal.txt": {"hash": "277fdcc43a53ddedd4d2f4d30c96331f", "size": 81, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "2c1cfb56a9ce13c8af194074d4842a6b.dir", "size": 9604567, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "34e825f11c0acbadd47c82f531c9911e.dir", "size": 346978, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "2c1cfb56a9ce13c8af194074d4842a6b.dir", "size": 9604567, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "34e825f11c0acbadd47c82f531c9911e.dir", "size": 346978, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "03a27a1ee21f625aca2032c54a3c5285", "size": 9377463, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/49138e4b68fe8667b1bad1b59102e35dce784ddf/49138e4b68fe8667b1bad1b59102e35dce784ddf.out", "pid": 2427620, "returncode": 0, "task_id": "49138e4b68fe8667b1bad1b59102e35dce784ddf"}}, "name": "score-areg"}, {"revs": [{"rev": "e711a759e031193453919254922ebb033bb9e79f", "name": "dosed-hows", "data": {"rev": "e711a759e031193453919254922ebb033bb9e79f", "timestamp": "2024-10-31T18:59:50", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.0008274720728175424, "f1": 0.0008274720728175424, "fuzzy_match": 0.0008274720728175424, "2hops": {"exact_match": 0.0007987220447284345, "f1": 0.0007987220447284345, "fuzzy_match": 0.0007987220447284345}, "3hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}, "4hops": {"exact_match": 0.0024691358024691358, "f1": 0.0024691358024691358, "fuzzy_match": 0.0024691358024691358}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal.txt": {"hash": "277fdcc43a53ddedd4d2f4d30c96331f", "size": 81, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "f7e34d716c6597a36b8fd83246690dea.dir", "size": 9601177, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "5e568df43390c60c011e4864cdbc02ca.dir", "size": 346935, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "f7e34d716c6597a36b8fd83246690dea.dir", "size": 9601177, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "5e568df43390c60c011e4864cdbc02ca.dir", "size": 346935, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "5b36d8d1cb801fba6ec45bfd46764013", "size": 9374037, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/016f38ce8ecadda18aa7f0b7382c1aa7ddd7f171/016f38ce8ecadda18aa7f0b7382c1aa7ddd7f171.out", "pid": 2428106, "returncode": 0, "task_id": "016f38ce8ecadda18aa7f0b7382c1aa7ddd7f171"}}, "name": "dosed-hows"}, {"revs": [{"rev": "8df3727d685ab6d0bfe491c22f0439c2a7041ee9", "name": "sappy-shes", "data": {"rev": "8df3727d685ab6d0bfe491c22f0439c2a7041ee9", "timestamp": "2024-10-31T18:52:25", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-cte.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cte-2-shot.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.6479106330161357, "f1": 0.7497808330306749, "fuzzy_match": 0.6983864294580058, "2hops": {"exact_match": 0.6629392971246006, "f1": 0.7625598326243698, "fuzzy_match": 0.7172523961661342}, "3hops": {"exact_match": 0.6723684210526316, "f1": 0.7846053065760322, "fuzzy_match": 0.7210526315789474}, "4hops": {"exact_match": 0.5555555555555556, "f1": 0.644926740720113, "fuzzy_match": 0.5975308641975309}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-cte.txt": {"hash": "0effab8496c59a1f390a4fd3d26aeaff", "size": 518, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cte-2-shot.json": {"hash": "5ce5053d023f6717df1ab4adf4c31230", "size": 1752, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "8436f44faa42d2d1cc7e8d6c63cf6350.dir", "size": 9800190, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "cbd7578b1aea7ec33afa372434b2fd5c.dir", "size": 398496, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "8436f44faa42d2d1cc7e8d6c63cf6350.dir", "size": 9800190, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "cbd7578b1aea7ec33afa372434b2fd5c.dir", "size": 398496, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "7b7d18cbf982521b835f8f3ef591e95b", "size": 9619519, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/1d460e1346e081deeff7018f093ed2d729924a9e/1d460e1346e081deeff7018f093ed2d729924a9e.out", "pid": 2413468, "returncode": 0, "task_id": "1d460e1346e081deeff7018f093ed2d729924a9e"}}, "name": "sappy-shes"}, {"revs": [{"rev": "42ca212a2c5b8713df2195645a96db4d2ff56ff2", "name": "hi-fi-trey", "data": {"rev": "42ca212a2c5b8713df2195645a96db4d2ff56ff2", "timestamp": "2024-10-31T18:51:43", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-cte.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cte-2-shot.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.6483243690525444, "f1": 0.751309394625449, "fuzzy_match": 0.6992139015308233, "2hops": {"exact_match": 0.6661341853035144, "f1": 0.7671732866827685, "fuzzy_match": 0.7228434504792333}, "3hops": {"exact_match": 0.6671052631578948, "f1": 0.7817049429536697, "fuzzy_match": 0.7157894736842105}, "4hops": {"exact_match": 0.5580246913580247, "f1": 0.6452298647854203, "fuzzy_match": 0.5950617283950618}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-cte.txt": {"hash": "0effab8496c59a1f390a4fd3d26aeaff", "size": 518, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cte-2-shot.json": {"hash": "5ce5053d023f6717df1ab4adf4c31230", "size": 1752, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "c16ab62214e820d366e5dc2da4c3b628.dir", "size": 9793126, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "2fff47c5fee9a17eb0510d6331b802b0.dir", "size": 397053, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "c16ab62214e820d366e5dc2da4c3b628.dir", "size": 9793126, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "2fff47c5fee9a17eb0510d6331b802b0.dir", "size": 397053, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "2e98432d3ed550d5ea3db4b9986148e0", "size": 9610996, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/a4943802bc2591262cf4bdfde172a7c24063ec04/a4943802bc2591262cf4bdfde172a7c24063ec04.out", "pid": 2413227, "returncode": 0, "task_id": "a4943802bc2591262cf4bdfde172a7c24063ec04"}}, "name": "hi-fi-trey"}, {"revs": [{"rev": "7317ce79346ae2e827924b71f7f1f425a3c73531", "name": "gules-bawl", "data": {"rev": "7317ce79346ae2e827924b71f7f1f425a3c73531", "timestamp": "2024-10-31T18:51:19", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-cte.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cte-2-shot.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.6499793131981796, "f1": 0.7530371130948683, "fuzzy_match": 0.7025237898220935, "2hops": {"exact_match": 0.6693290734824281, "f1": 0.7693791425120149, "fuzzy_match": 0.7252396166134185}, "3hops": {"exact_match": 0.6710526315789473, "f1": 0.7851091270528615, "fuzzy_match": 0.7210526315789474}, "4hops": {"exact_match": 0.5506172839506173, "f1": 0.6423335292964922, "fuzzy_match": 0.5975308641975309}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-cte.txt": {"hash": "0effab8496c59a1f390a4fd3d26aeaff", "size": 518, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cte-2-shot.json": {"hash": "5ce5053d023f6717df1ab4adf4c31230", "size": 1752, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "7732f31e58a5ec25dc9bc7e63643f1e9.dir", "size": 9799366, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "545da2f5f61c9cad6074ff58b6ed9732.dir", "size": 398155, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "7732f31e58a5ec25dc9bc7e63643f1e9.dir", "size": 9799366, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "545da2f5f61c9cad6074ff58b6ed9732.dir", "size": 398155, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "48e26587e6e74a5c1c27c39c1b1e02ed", "size": 9618355, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/ed6bdecc9ef4703a655f1f0b0f4c1431feae45cc/ed6bdecc9ef4703a655f1f0b0f4c1431feae45cc.out", "pid": 2412289, "returncode": 0, "task_id": "ed6bdecc9ef4703a655f1f0b0f4c1431feae45cc"}}, "name": "gules-bawl"}, {"revs": [{"rev": "ef6b05fd7ce1e5ce6017f3d799d0f4dfa32d6a33", "name": "lated-much", "data": {"rev": "ef6b05fd7ce1e5ce6017f3d799d0f4dfa32d6a33", "timestamp": "2024-10-31T18:35:29", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-few.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "standard-2-shot.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5990897807199007, "f1": 0.7092353502405303, "fuzzy_match": 0.6570128258171287, "2hops": {"exact_match": 0.6365814696485623, "f1": 0.7418915081037728, "fuzzy_match": 0.7092651757188498}, "3hops": {"exact_match": 0.5815789473684211, "f1": 0.705296205772212, "fuzzy_match": 0.6302631578947369}, "4hops": {"exact_match": 0.5160493827160494, "f1": 0.6156754493791531, "fuzzy_match": 0.5456790123456791}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-few.txt": {"hash": "6e209b60faa4e581de1a8907e797f7aa", "size": 254, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/standard-2-shot.json": {"hash": "a103f39c617bfcf05538c84c77f6616d", "size": 1553, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "a58cbb37ea6e653cc0e903accb0bfa2d.dir", "size": 9418725, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "28bd7f132218a673f8b1bb43e880704c.dir", "size": 391307, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "a58cbb37ea6e653cc0e903accb0bfa2d.dir", "size": 9418725, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "28bd7f132218a673f8b1bb43e880704c.dir", "size": 391307, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "d543cf200f3594ac0e457d9c28636406", "size": 9229518, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/64fee0250ce41752515af1de33338626f4e6203d/64fee0250ce41752515af1de33338626f4e6203d.out", "pid": 2436520, "returncode": 0, "task_id": "64fee0250ce41752515af1de33338626f4e6203d"}}, "name": "lated-much"}, {"revs": [{"rev": "455398cf6464c622656d0685d0c98d8e559dc0cc", "name": "melic-jots", "data": {"rev": "455398cf6464c622656d0685d0c98d8e559dc0cc", "timestamp": "2024-10-31T18:35:29", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-few.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "standard-2-shot.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.600330988829127, "f1": 0.7104464386051146, "fuzzy_match": 0.6586677699627638, "2hops": {"exact_match": 0.6381789137380192, "f1": 0.7434346091277045, "fuzzy_match": 0.7108626198083067}, "3hops": {"exact_match": 0.5802631578947368, "f1": 0.7044346769501568, "fuzzy_match": 0.631578947368421}, "4hops": {"exact_match": 0.5209876543209877, "f1": 0.6197495234532271, "fuzzy_match": 0.5481481481481482}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-few.txt": {"hash": "6e209b60faa4e581de1a8907e797f7aa", "size": 254, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/standard-2-shot.json": {"hash": "a103f39c617bfcf05538c84c77f6616d", "size": 1553, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "f684147e74f1d136cbfc5c0c5a796b09.dir", "size": 9418465, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "aac8fcd2683796eaec12e28fa32f1fa4.dir", "size": 391274, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "f684147e74f1d136cbfc5c0c5a796b09.dir", "size": 9418465, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "aac8fcd2683796eaec12e28fa32f1fa4.dir", "size": 391274, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "940ddbbbb43faeee6b597b774574a74e", "size": 9229250, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/72591716ddffc7a6aa405a4e170b977ba67a4892/72591716ddffc7a6aa405a4e170b977ba67a4892.out", "pid": 2436045, "returncode": 0, "task_id": "72591716ddffc7a6aa405a4e170b977ba67a4892"}}, "name": "melic-jots"}, {"revs": [{"rev": "f277b7dac7d5ab38125843ce5db3ea2e4fd0e965", "name": "meaty-abbs", "data": {"rev": "f277b7dac7d5ab38125843ce5db3ea2e4fd0e965", "timestamp": "2024-10-31T18:29:39", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.0004137360364087712, "f1": 0.0005056773778329426, "fuzzy_match": 0.0004137360364087712, "2hops": {"exact_match": 0.0007987220447284345, "f1": 0.0007987220447284345, "fuzzy_match": 0.0007987220447284345}, "3hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}, "4hops": {"exact_match": 0.0, "f1": 0.0005486968449931412, "fuzzy_match": 0.0}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal.txt": {"hash": "277fdcc43a53ddedd4d2f4d30c96331f", "size": 81, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "0a4b9afa712eb2ada4a4d150ba81f0d4.dir", "size": 9604266, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "061422fe232bc9d0f92a4a7f9e21dfcf.dir", "size": 346969, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "0a4b9afa712eb2ada4a4d150ba81f0d4.dir", "size": 9604266, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "061422fe232bc9d0f92a4a7f9e21dfcf.dir", "size": 346969, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "538919bf9ce4e26ec05771a24d9230cc", "size": 9377162, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/c5d7da88531c5ccab1a107cf20030129add56cb7/c5d7da88531c5ccab1a107cf20030129add56cb7.out", "pid": 2413972, "returncode": 0, "task_id": "c5d7da88531c5ccab1a107cf20030129add56cb7"}}, "name": "meaty-abbs"}, {"revs": [{"rev": "561d162e1af01b555bb069dc8b9560e5ca04bd61", "name": "suave-vows", "data": {"rev": "561d162e1af01b555bb069dc8b9560e5ca04bd61", "timestamp": "2024-10-31T18:12:50", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-few.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "standard-2-shot.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5999172527927182, "f1": 0.7091263490040983, "fuzzy_match": 0.658254033926355, "2hops": {"exact_match": 0.6365814696485623, "f1": 0.7403527291688278, "fuzzy_match": 0.7084664536741214}, "3hops": {"exact_match": 0.5842105263157895, "f1": 0.7076802909852445, "fuzzy_match": 0.6368421052631579}, "4hops": {"exact_match": 0.5160493827160494, "f1": 0.6153080184561666, "fuzzy_match": 0.5432098765432098}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-few.txt": {"hash": "6e209b60faa4e581de1a8907e797f7aa", "size": 254, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/standard-2-shot.json": {"hash": "a103f39c617bfcf05538c84c77f6616d", "size": 1553, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "e0a842c476bfa12d1e459587999b6ebe.dir", "size": 9418757, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "36e45d67db0b3b29e36d8f81d19dff47.dir", "size": 391287, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "e0a842c476bfa12d1e459587999b6ebe.dir", "size": 9418757, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "36e45d67db0b3b29e36d8f81d19dff47.dir", "size": 391287, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "ab34274d6713ccea4ce317b9c80d3c10", "size": 9229562, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/bd221ceb9d576edb341796725da6663346a8acff/bd221ceb9d576edb341796725da6663346a8acff.out", "pid": 2428595, "returncode": 0, "task_id": "bd221ceb9d576edb341796725da6663346a8acff"}}, "name": "suave-vows"}, {"revs": [{"rev": "044d3fd9285ed7de94ae9631eed056936a113887", "name": "ohmic-tola", "data": {"rev": "044d3fd9285ed7de94ae9631eed056936a113887", "timestamp": "2024-10-31T18:12:26", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-cot.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cot-2-shot.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.48655357881671496, "f1": 0.5686032232666031, "fuzzy_match": 0.5440628878775341, "2hops": {"exact_match": 0.5638977635782748, "f1": 0.6551932626232537, "fuzzy_match": 0.6206070287539937}, "3hops": {"exact_match": 0.43157894736842106, "f1": 0.5087134197253147, "fuzzy_match": 0.5039473684210526}, "4hops": {"exact_match": 0.3506172839506173, "f1": 0.41330821441932547, "fuzzy_match": 0.38271604938271603}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-cot.txt": {"hash": "5658759cf229361109257f0710eae328", "size": 399, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cot-2-shot.json": {"hash": "b536995986f0bff92e731a4ad4d36f81", "size": 2115, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "3cb019a71b0fd03701c2372a2a329615.dir", "size": 10167009, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "7dc5555e116b8fb7026137a9d1c232ba.dir", "size": 381025, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "3cb019a71b0fd03701c2372a2a329615.dir", "size": 10167009, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "7dc5555e116b8fb7026137a9d1c232ba.dir", "size": 381025, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "7e630787a9803d2b6a298b1682fbc67a", "size": 9970343, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/fe5d66d8c3d5198034e73d312193cad6335cb8a0/fe5d66d8c3d5198034e73d312193cad6335cb8a0.out", "pid": 2320850, "returncode": 0, "task_id": "fe5d66d8c3d5198034e73d312193cad6335cb8a0"}}, "name": "ohmic-tola"}, {"revs": [{"rev": "490f1ffd118825d1a7af72ca13c6bd739df480b5", "name": "randy-sale", "data": {"rev": "490f1ffd118825d1a7af72ca13c6bd739df480b5", "timestamp": "2024-10-31T18:11:42", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-cot.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cot-2-shot.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.48655357881671496, "f1": 0.5664142044821581, "fuzzy_match": 0.5440628878775341, "2hops": {"exact_match": 0.5702875399361023, "f1": 0.6559618530000499, "fuzzy_match": 0.6206070287539937}, "3hops": {"exact_match": 0.41578947368421054, "f1": 0.4994850997724959, "fuzzy_match": 0.49605263157894736}, "4hops": {"exact_match": 0.36049382716049383, "f1": 0.415185719630164, "fuzzy_match": 0.39753086419753086}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-cot.txt": {"hash": "5658759cf229361109257f0710eae328", "size": 399, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cot-2-shot.json": {"hash": "b536995986f0bff92e731a4ad4d36f81", "size": 2115, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "fc6041d90bf430b6ed844d24bde3170e.dir", "size": 10167368, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "8ba77597489de9bcbde0ef8e0f559a1a.dir", "size": 381326, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "fc6041d90bf430b6ed844d24bde3170e.dir", "size": 10167368, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "8ba77597489de9bcbde0ef8e0f559a1a.dir", "size": 381326, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "808fbdb37d0a194ba347bb96f30fa611", "size": 9971059, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/ba6e8d23bd794fbf09d5342d4267fd9ccd8be0d4/ba6e8d23bd794fbf09d5342d4267fd9ccd8be0d4.out", "pid": 2321201, "returncode": 0, "task_id": "ba6e8d23bd794fbf09d5342d4267fd9ccd8be0d4"}}, "name": "randy-sale"}, {"revs": [{"rev": "9838b9bd57a9293a73a92f0b7f66de982b00de08", "name": "flash-zone", "data": {"rev": "9838b9bd57a9293a73a92f0b7f66de982b00de08", "timestamp": "2024-10-31T18:11:32", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-cot.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cot-2-shot.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.49151841125362017, "f1": 0.5719734472599016, "fuzzy_match": 0.5482002482416218, "2hops": {"exact_match": 0.5726837060702875, "f1": 0.6629355802270653, "fuzzy_match": 0.6269968051118211}, "3hops": {"exact_match": 0.41973684210526313, "f1": 0.49810991793678766, "fuzzy_match": 0.4934210526315789}, "4hops": {"exact_match": 0.37530864197530867, "f1": 0.4293850319776245, "fuzzy_match": 0.4074074074074074}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-cot.txt": {"hash": "5658759cf229361109257f0710eae328", "size": 399, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cot-2-shot.json": {"hash": "b536995986f0bff92e731a4ad4d36f81", "size": 2115, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "4d7a54cb55b3a3d6dd0381ea1ec24d6f.dir", "size": 10166037, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "cfdbe30f50cb3dd95606c3390c6a1d1d.dir", "size": 381263, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "4d7a54cb55b3a3d6dd0381ea1ec24d6f.dir", "size": 10166037, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "cfdbe30f50cb3dd95606c3390c6a1d1d.dir", "size": 381263, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "73754dbe791edee6bb90ca30565196d2", "size": 9969613, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/07b3f00786412663151aeff0389e50cec223c65d/07b3f00786412663151aeff0389e50cec223c65d.out", "pid": 2320859, "returncode": 0, "task_id": "07b3f00786412663151aeff0389e50cec223c65d"}}, "name": "flash-zone"}, {"revs": [{"rev": "40f81c37facc24e7a19f88300aeec575ed8ad77e", "name": "fined-rugs", "data": {"rev": "40f81c37facc24e7a19f88300aeec575ed8ad77e", "timestamp": "2024-10-31T16:17:36", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5345469590401324, "f1": 0.6584984961614269, "fuzzy_match": 0.5924700041373604, "2hops": {"exact_match": 0.5870607028753994, "f1": 0.7182148705907905, "fuzzy_match": 0.65814696485623}, "3hops": {"exact_match": 0.5210526315789473, "f1": 0.6542229802569323, "fuzzy_match": 0.5776315789473684}, "4hops": {"exact_match": 0.39753086419753086, "f1": 0.48191699320303855, "fuzzy_match": 0.41728395061728396}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format.txt": {"hash": "a52a365ad92c7cfe0e821aac8ce9112c", "size": 96, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "6a75bbec5ca7b59f54f99f7aa18ca06e.dir", "size": 9730557, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "0dac200fe32556c967bd4fbc8f20db39.dir", "size": 472548, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "6a75bbec5ca7b59f54f99f7aa18ca06e.dir", "size": 9730557, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "0dac200fe32556c967bd4fbc8f20db39.dir", "size": 472548, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "70224fda2eb5899ae93316cd9fb7f46d", "size": 9621894, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/3923127a3fdeabbb97ee9b118bddb457f76b6357/3923127a3fdeabbb97ee9b118bddb457f76b6357.out", "pid": 2401142, "returncode": 0, "task_id": "3923127a3fdeabbb97ee9b118bddb457f76b6357"}}, "name": "fined-rugs"}, {"revs": [{"rev": "4a4bb2d591eacb2e3d19b845d39c0b644edfa44d", "name": "tarot-he'd", "data": {"rev": "4a4bb2d591eacb2e3d19b845d39c0b644edfa44d", "timestamp": "2024-10-31T16:14:45", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5362019031857674, "f1": 0.6598837587088626, "fuzzy_match": 0.5932974762101779, "2hops": {"exact_match": 0.5894568690095847, "f1": 0.7183881429700565, "fuzzy_match": 0.6573482428115016}, "3hops": {"exact_match": 0.5223684210526316, "f1": 0.6573143247717842, "fuzzy_match": 0.5828947368421052}, "4hops": {"exact_match": 0.39753086419753086, "f1": 0.483847414751245, "fuzzy_match": 0.4148148148148148}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format.txt": {"hash": "a52a365ad92c7cfe0e821aac8ce9112c", "size": 96, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "2bb272262e32febf419e3a3d5a7f0687.dir", "size": 9726397, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "63b596ad85110365d4b89ffaa99f1ef4.dir", "size": 471545, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "2bb272262e32febf419e3a3d5a7f0687.dir", "size": 9726397, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "63b596ad85110365d4b89ffaa99f1ef4.dir", "size": 471545, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "0dfe07eff97a7719ddd1bc31872a7da0", "size": 9616509, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/3017b075317bd954efc3cfcc2f3574ec31ac998e/3017b075317bd954efc3cfcc2f3574ec31ac998e.out", "pid": 2399368, "returncode": 0, "task_id": "3017b075317bd954efc3cfcc2f3574ec31ac998e"}}, "name": "tarot-he'd"}, {"revs": [{"rev": "b013df2d491cdbb6bce7bdd280ace4aa205f1bb3", "name": "garni-mast", "data": {"rev": "b013df2d491cdbb6bce7bdd280ace4aa205f1bb3", "timestamp": "2024-10-31T16:14:27", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5366156392221763, "f1": 0.6606726151958211, "fuzzy_match": 0.5928837401737691, "2hops": {"exact_match": 0.5894568690095847, "f1": 0.7189303780359036, "fuzzy_match": 0.6573482428115016}, "3hops": {"exact_match": 0.525, "f1": 0.6594406973738626, "fuzzy_match": 0.5815789473684211}, "4hops": {"exact_match": 0.3950617283950617, "f1": 0.4828887595634882, "fuzzy_match": 0.4148148148148148}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format.txt": {"hash": "a52a365ad92c7cfe0e821aac8ce9112c", "size": 96, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "ed139e6b60f984f6b264cbcdfe7a5db3.dir", "size": 9724329, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "b0df4eaa178b671ca104b6de31b9d486.dir", "size": 471086, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "ed139e6b60f984f6b264cbcdfe7a5db3.dir", "size": 9724329, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "b0df4eaa178b671ca104b6de31b9d486.dir", "size": 471086, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "4d3187bd91cbb4d2a8a69b9acefd454b", "size": 9614046, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/7c13e9b6755ddb696c4b4634e52b0435dc142533/7c13e9b6755ddb696c4b4634e52b0435dc142533.out", "pid": 2399871, "returncode": 0, "task_id": "7c13e9b6755ddb696c4b4634e52b0435dc142533"}}, "name": "garni-mast"}, {"revs": [{"rev": "b6b83bdb571563cba3ddd5e976a1be71d631f69b", "name": "nodal-kale", "data": {"rev": "b6b83bdb571563cba3ddd5e976a1be71d631f69b", "timestamp": "2024-10-31T15:41:15", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cte.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5854364915184113, "f1": 0.6991245339501974, "fuzzy_match": 0.6466694249069094, "2hops": {"exact_match": 0.6190095846645367, "f1": 0.7283000396716901, "fuzzy_match": 0.6797124600638977}, "3hops": {"exact_match": 0.5868421052631579, "f1": 0.7174673619081533, "fuzzy_match": 0.6618421052631579}, "4hops": {"exact_match": 0.47901234567901235, "f1": 0.5745114909591965, "fuzzy_match": 0.5160493827160494}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cte.txt": {"hash": "0d0d2d8712ac90d790ba7a8def4be6d3", "size": 301, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "76a85cd4ad5f4e123698f3df494d6c0f.dir", "size": 9814842, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "8ddf181baf26762bed8ac2efb99c16b0.dir", "size": 398370, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "76a85cd4ad5f4e123698f3df494d6c0f.dir", "size": 9814842, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "8ddf181baf26762bed8ac2efb99c16b0.dir", "size": 398370, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "6c9f99ea4241f78d736d131b4c56de65", "size": 9633674, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/e03270011a01608986402ea6cea9fa6d6254f250/e03270011a01608986402ea6cea9fa6d6254f250.out", "pid": 2321122, "returncode": 0, "task_id": "e03270011a01608986402ea6cea9fa6d6254f250"}}, "name": "nodal-kale"}, {"revs": [{"rev": "79fa8100d3614582ac4f53aa962ef655c9c5abc4", "name": "gamic-link", "data": {"rev": "79fa8100d3614582ac4f53aa962ef655c9c5abc4", "timestamp": "2024-10-31T15:41:00", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cte.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5887463798096815, "f1": 0.7028978429177855, "fuzzy_match": 0.6524617294166322, "2hops": {"exact_match": 0.6253993610223643, "f1": 0.7328529626893389, "fuzzy_match": 0.6884984025559105}, "3hops": {"exact_match": 0.5868421052631579, "f1": 0.7178009535056352, "fuzzy_match": 0.6605263157894737}, "4hops": {"exact_match": 0.47901234567901235, "f1": 0.5823295120517343, "fuzzy_match": 0.5259259259259259}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cte.txt": {"hash": "0d0d2d8712ac90d790ba7a8def4be6d3", "size": 301, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "7fac4de3aa616f2ef87b8e3394afe56e.dir", "size": 9811248, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "b9155b8ac212ad829728d7d46f2aff05.dir", "size": 397662, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "7fac4de3aa616f2ef87b8e3394afe56e.dir", "size": 9811248, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "b9155b8ac212ad829728d7d46f2aff05.dir", "size": 397662, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "f4c48e0a71c585ca646ca6982623eaf4", "size": 9629421, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/cf5511e03da8b2c5b2ea2820d42d3d479473d2f2/cf5511e03da8b2c5b2ea2820d42d3d479473d2f2.out", "pid": 2321116, "returncode": 0, "task_id": "cf5511e03da8b2c5b2ea2820d42d3d479473d2f2"}}, "name": "gamic-link"}, {"revs": [{"rev": "c6c98c1013c4c08a6c6d9f39c7c1abbd42127cf6", "name": "snuff-craw", "data": {"rev": "c6c98c1013c4c08a6c6d9f39c7c1abbd42127cf6", "timestamp": "2024-10-31T15:40:38", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cte.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5887463798096815, "f1": 0.702679229642587, "fuzzy_match": 0.6541166735622673, "2hops": {"exact_match": 0.6214057507987221, "f1": 0.7281003668940862, "fuzzy_match": 0.6853035143769968}, "3hops": {"exact_match": 0.593421052631579, "f1": 0.724172196322729, "fuzzy_match": 0.675}, "4hops": {"exact_match": 0.47901234567901235, "f1": 0.5837609123196615, "fuzzy_match": 0.5185185185185185}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cte.txt": {"hash": "0d0d2d8712ac90d790ba7a8def4be6d3", "size": 301, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "d08c4062dd072bd07c4ef83fff8334f6.dir", "size": 9806797, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "af051e81f1b1f86b7cb37cb85b227a51.dir", "size": 396626, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "d08c4062dd072bd07c4ef83fff8334f6.dir", "size": 9806797, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "af051e81f1b1f86b7cb37cb85b227a51.dir", "size": 396626, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "f8e7e8640be1b05b427d1f239dedc870", "size": 9623954, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/fc13a04d21f74788d12a514f333f9ded649bba3e/fc13a04d21f74788d12a514f333f9ded649bba3e.out", "pid": 2321468, "returncode": 0, "task_id": "fc13a04d21f74788d12a514f333f9ded649bba3e"}}, "name": "snuff-craw"}, {"revs": [{"rev": "e84a7d1e61240a2282074d62339577905ae8f3f0", "name": "pupal-yoke", "data": {"rev": "e84a7d1e61240a2282074d62339577905ae8f3f0", "timestamp": "2024-10-31T14:40:10", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0, "2hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}, "3hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}, "4hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal.txt": {"hash": "277fdcc43a53ddedd4d2f4d30c96331f", "size": 81, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "eaca2c08e8ead9a3119bd792da24d6de.dir", "size": 9597588, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "dcc20ef8fea8fa5068b02da47b37b606.dir", "size": 346895, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "eaca2c08e8ead9a3119bd792da24d6de.dir", "size": 9597588, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "dcc20ef8fea8fa5068b02da47b37b606.dir", "size": 346895, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "ea98a5874424b198a6fa6418d11c54b6", "size": 9365641, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/065cac03e3433fea545749899ae886da7a627564/065cac03e3433fea545749899ae886da7a627564.out", "pid": 2320847, "returncode": 0, "task_id": "065cac03e3433fea545749899ae886da7a627564"}}, "name": "pupal-yoke"}, {"revs": [{"rev": "4b96eb6abb67e60e5ed6c8d482ef807af9d3e24d", "name": "moody-crag", "data": {"rev": "4b96eb6abb67e60e5ed6c8d482ef807af9d3e24d", "timestamp": "2024-10-31T14:39:48", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.0, "f1": 9.194134142417137e-05, "fuzzy_match": 0.0, "2hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}, "3hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}, "4hops": {"exact_match": 0.0, "f1": 0.0005486968449931412, "fuzzy_match": 0.0}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal.txt": {"hash": "277fdcc43a53ddedd4d2f4d30c96331f", "size": 81, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "cf3be76c7d292520690af3cf092e6849.dir", "size": 9597354, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "fa737aa8dba69dddbc7e894e104f10bb.dir", "size": 346964, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "cf3be76c7d292520690af3cf092e6849.dir", "size": 9597354, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "fa737aa8dba69dddbc7e894e104f10bb.dir", "size": 346964, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "1f2edf9b222c922d21a828e32e920488", "size": 9370278, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/44b36b259ce6a3b18783248bce25b23991cc66ce/44b36b259ce6a3b18783248bce25b23991cc66ce.out", "pid": 2320857, "returncode": 0, "task_id": "44b36b259ce6a3b18783248bce25b23991cc66ce"}}, "name": "moody-crag"}, {"revs": [{"rev": "3d6a5e1fa8651d818da65f7c4199ebf3775e525c", "name": "lucky-here", "data": {"rev": "3d6a5e1fa8651d818da65f7c4199ebf3775e525c", "timestamp": "2024-10-31T14:39:42", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0, "2hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}, "3hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}, "4hops": {"exact_match": 0.0, "f1": 0.0, "fuzzy_match": 0.0}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal.txt": {"hash": "277fdcc43a53ddedd4d2f4d30c96331f", "size": 81, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "76c26ab1b308f3f80d25fe222b4971fc.dir", "size": 9596441, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "8aa178c189fe319584946f5cf98a2b63.dir", "size": 346895, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "76c26ab1b308f3f80d25fe222b4971fc.dir", "size": 9596441, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "8aa178c189fe319584946f5cf98a2b63.dir", "size": 346895, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "f3e863c091ef0fb9a50840592591037a", "size": 9364474, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/1558edb9557178d5cbcc1478fb32b69f00de95c2/1558edb9557178d5cbcc1478fb32b69f00de95c2.out", "pid": 2320844, "returncode": 0, "task_id": "1558edb9557178d5cbcc1478fb32b69f00de95c2"}}, "name": "lucky-here"}, {"revs": [{"rev": "61815a49b0e3969c687b2ca1c49b00066b75ef00", "name": "azoic-hips", "data": {"rev": "61815a49b0e3969c687b2ca1c49b00066b75ef00", "timestamp": "2024-10-31T14:38:07", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-few.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5676458419528341, "f1": 0.6883539933416901, "fuzzy_match": 0.6359122879602813, "2hops": {"exact_match": 0.615814696485623, "f1": 0.729778763839066, "fuzzy_match": 0.6900958466453674}, "3hops": {"exact_match": 0.5473684210526316, "f1": 0.6940906861456396, "fuzzy_match": 0.6289473684210526}, "4hops": {"exact_match": 0.4567901234567901, "f1": 0.5495300447152299, "fuzzy_match": 0.48148148148148145}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-few.txt": {"hash": "6e209b60faa4e581de1a8907e797f7aa", "size": 254, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "7e6d327ba9d72a9240b2eb520e8bf0af.dir", "size": 9426181, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "9c39c755108dd77dbf209cdf5b23d751.dir", "size": 393689, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "7e6d327ba9d72a9240b2eb520e8bf0af.dir", "size": 9426181, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "9c39c755108dd77dbf209cdf5b23d751.dir", "size": 393689, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "e17be1b0cb9698e43986e9045b84ad98", "size": 9239054, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/51f1e5eeb572ce2af7e0c4d2aaf2d868996f39ef/51f1e5eeb572ce2af7e0c4d2aaf2d868996f39ef.out", "pid": 2376895, "returncode": 0, "task_id": "51f1e5eeb572ce2af7e0c4d2aaf2d868996f39ef"}}, "name": "azoic-hips"}, {"revs": [{"rev": "813a12cd6151d9b1895d089f7d5b679a5ae3b55e", "name": "fluid-flap", "data": {"rev": "813a12cd6151d9b1895d089f7d5b679a5ae3b55e", "timestamp": "2024-10-31T14:37:08", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-few.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5688870500620604, "f1": 0.6888228184462226, "fuzzy_match": 0.6367397600330988, "2hops": {"exact_match": 0.615814696485623, "f1": 0.7291418213764131, "fuzzy_match": 0.6884984025559105}, "3hops": {"exact_match": 0.55, "f1": 0.6945914785678718, "fuzzy_match": 0.6328947368421053}, "4hops": {"exact_match": 0.45925925925925926, "f1": 0.5533572052090571, "fuzzy_match": 0.4839506172839506}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-few.txt": {"hash": "6e209b60faa4e581de1a8907e797f7aa", "size": 254, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "5b4a6fc53e7cf6a6af9ac4282a418660.dir", "size": 9425329, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "dfe3cbfa7fc841ccd104391c54ef284b.dir", "size": 393481, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "5b4a6fc53e7cf6a6af9ac4282a418660.dir", "size": 9425329, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "dfe3cbfa7fc841ccd104391c54ef284b.dir", "size": 393481, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "2a6ed49681af2a0beec6c33b8fdea708", "size": 9237945, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/a06ae035e62134dbf79abf64b26900c884235823/a06ae035e62134dbf79abf64b26900c884235823.out", "pid": 2376191, "returncode": 0, "task_id": "a06ae035e62134dbf79abf64b26900c884235823"}}, "name": "fluid-flap"}, {"revs": [{"rev": "13e19d7b77d021ccee1c7e48714814a9004b4f14", "name": "bijou-tirl", "data": {"rev": "13e19d7b77d021ccee1c7e48714814a9004b4f14", "timestamp": "2024-10-31T13:59:40", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-fewest.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "standard-2-shot.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.6015721969383533, "f1": 0.7003887007618637, "fuzzy_match": 0.6603227141083988, "2hops": {"exact_match": 0.6325878594249201, "f1": 0.7362723333608926, "fuzzy_match": 0.7028753993610224}, "3hops": {"exact_match": 0.5973684210526315, "f1": 0.691935782655597, "fuzzy_match": 0.6473684210526316}, "4hops": {"exact_match": 0.5135802469135803, "f1": 0.6053218112477372, "fuzzy_match": 0.5530864197530864}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-fewest.txt": {"hash": "7fa9cb6698054df80d424f77d1ba3186", "size": 259, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/standard-2-shot.json": {"hash": "a103f39c617bfcf05538c84c77f6616d", "size": 1553, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "e2619dd692cf55281f4d35b0832e4ed9.dir", "size": 9421593, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "374440914c4a54b3ce5b69dbf9ae16a8.dir", "size": 391578, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "e2619dd692cf55281f4d35b0832e4ed9.dir", "size": 9421593, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "374440914c4a54b3ce5b69dbf9ae16a8.dir", "size": 391578, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "a72943e3496d3179abc7a64e2458edc1", "size": 9232882, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/212062b76b4123a5f1e55340f9758da544d9716e/212062b76b4123a5f1e55340f9758da544d9716e.out", "pid": 2358386, "returncode": 0, "task_id": "212062b76b4123a5f1e55340f9758da544d9716e"}}, "name": "bijou-tirl"}, {"revs": [{"rev": "8ed104e14ebcc0987fe10c73843c7a169b125045", "name": "raked-door", "data": {"rev": "8ed104e14ebcc0987fe10c73843c7a169b125045", "timestamp": "2024-10-31T13:59:30", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-fewest.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "standard-2-shot.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.604054613156806, "f1": 0.7022451605042792, "fuzzy_match": 0.6611501861812163, "2hops": {"exact_match": 0.6381789137380192, "f1": 0.7398235732601541, "fuzzy_match": 0.7060702875399361}, "3hops": {"exact_match": 0.5960526315789474, "f1": 0.6923456140522704, "fuzzy_match": 0.6447368421052632}, "4hops": {"exact_match": 0.5135802469135803, "f1": 0.604653759351615, "fuzzy_match": 0.5530864197530864}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-fewest.txt": {"hash": "7fa9cb6698054df80d424f77d1ba3186", "size": 259, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/standard-2-shot.json": {"hash": "a103f39c617bfcf05538c84c77f6616d", "size": 1553, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "a2a29f49e976c1e077ad5e870f408fd6.dir", "size": 9422661, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "db1cd75b9a53469c0b60c7d5ba13e481.dir", "size": 391925, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "a2a29f49e976c1e077ad5e870f408fd6.dir", "size": 9422661, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "db1cd75b9a53469c0b60c7d5ba13e481.dir", "size": 391925, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "ae75607386b073d46c8282f0d8742803", "size": 9234227, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/c4c5d1e89f243f195598ff66ad1e870fcbd416b0/c4c5d1e89f243f195598ff66ad1e870fcbd416b0.out", "pid": 2358362, "returncode": 0, "task_id": "c4c5d1e89f243f195598ff66ad1e870fcbd416b0"}}, "name": "raked-door"}, {"revs": [{"rev": "e95ba39b05de44be10dd70f0fbe1e2f59ecfb2f2", "name": "crumb-lays", "data": {"rev": "e95ba39b05de44be10dd70f0fbe1e2f59ecfb2f2", "timestamp": "2024-10-31T13:59:25", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-fewest.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "standard-2-shot.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.6028134050475796, "f1": 0.7033904605576751, "fuzzy_match": 0.6611501861812163, "2hops": {"exact_match": 0.6349840255591054, "f1": 0.7388822792321467, "fuzzy_match": 0.7036741214057508}, "3hops": {"exact_match": 0.5960526315789474, "f1": 0.6941425091492504, "fuzzy_match": 0.6473684210526316}, "4hops": {"exact_match": 0.5160493827160494, "f1": 0.611026722508204, "fuzzy_match": 0.5555555555555556}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-fewest.txt": {"hash": "7fa9cb6698054df80d424f77d1ba3186", "size": 259, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/standard-2-shot.json": {"hash": "a103f39c617bfcf05538c84c77f6616d", "size": 1553, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "b8fbb2d2d28f03d45634af279e9f3fc3.dir", "size": 9420785, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "c54309df422d3b664f3f606fa905282f.dir", "size": 391510, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "b8fbb2d2d28f03d45634af279e9f3fc3.dir", "size": 9420785, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "c54309df422d3b664f3f606fa905282f.dir", "size": 391510, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "abbc75a065861fa8881ad05963c45f7d", "size": 9231952, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/96f49f03a6a5c17b2c7526b45e12515fa1aa8686/96f49f03a6a5c17b2c7526b45e12515fa1aa8686.out", "pid": 2358619, "returncode": 0, "task_id": "96f49f03a6a5c17b2c7526b45e12515fa1aa8686"}}, "name": "crumb-lays"}, {"revs": [{"rev": "5b067cb476b44c2e0ef6a842c71ab3b39d1af0a8", "name": "wacky-esne", "data": {"rev": "5b067cb476b44c2e0ef6a842c71ab3b39d1af0a8", "timestamp": "2024-10-31T13:56:47", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-few.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5697145221348779, "f1": 0.6894551643019151, "fuzzy_match": 0.6367397600330988, "2hops": {"exact_match": 0.615814696485623, "f1": 0.7298069904642046, "fuzzy_match": 0.6884984025559105}, "3hops": {"exact_match": 0.55, "f1": 0.6947391823862412, "fuzzy_match": 0.631578947368421}, "4hops": {"exact_match": 0.4641975308641975, "f1": 0.5547975344271641, "fuzzy_match": 0.48641975308641977}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-few.txt": {"hash": "6e209b60faa4e581de1a8907e797f7aa", "size": 254, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "3a8805a8e38db2a19de6ebefaa4af2b3.dir", "size": 9425881, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "79199351dae68b3aefffb77bd2c73fea.dir", "size": 393570, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "3a8805a8e38db2a19de6ebefaa4af2b3.dir", "size": 9425881, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "79199351dae68b3aefffb77bd2c73fea.dir", "size": 393570, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "9a4cf9ff47b5681ee4f17120b4f003e9", "size": 9238678, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/d29aa0e0eb0b6dad8bb1c1b1b69eadef59770cdf/d29aa0e0eb0b6dad8bb1c1b1b69eadef59770cdf.out", "pid": 2358755, "returncode": 0, "task_id": "d29aa0e0eb0b6dad8bb1c1b1b69eadef59770cdf"}}, "name": "wacky-esne"}, {"revs": [{"rev": "883d602f46bd489401c90d59fae4673166746eb9", "name": "natal-libs", "data": {"rev": "883d602f46bd489401c90d59fae4673166746eb9", "timestamp": "2024-10-31T13:56:23", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5693007860984691, "f1": 0.6929507727611907, "fuzzy_match": 0.6404633843607779, "2hops": {"exact_match": 0.6222044728434505, "f1": 0.7350269531288262, "fuzzy_match": 0.6972843450479234}, "3hops": {"exact_match": 0.5394736842105263, "f1": 0.6925503774691081, "fuzzy_match": 0.6328947368421053}, "4hops": {"exact_match": 0.4617283950617284, "f1": 0.5636295939999644, "fuzzy_match": 0.47901234567901235}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue.txt": {"hash": "bb5bc978acf0f8a75d991daf1db0b497", "size": 111, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "1b8a85f3f8311e796d3abc6aebdd0525.dir", "size": 9427669, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "6e4d98c299578073c653b990261faf39.dir", "size": 394085, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "1b8a85f3f8311e796d3abc6aebdd0525.dir", "size": 9427669, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "6e4d98c299578073c653b990261faf39.dir", "size": 394085, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "9f22165065a153c0e102dfb88038b8cd", "size": 9240941, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/e7309c3c9566a90291de4689fbf09a277b314a54/e7309c3c9566a90291de4689fbf09a277b314a54.out", "pid": 2358140, "returncode": 0, "task_id": "e7309c3c9566a90291de4689fbf09a277b314a54"}}, "name": "natal-libs"}, {"revs": [{"rev": "d5e4c4df70f609183ebe140cc08531eeeaa90a62", "name": "pseud-buoy", "data": {"rev": "d5e4c4df70f609183ebe140cc08531eeeaa90a62", "timestamp": "2024-10-31T12:41:18", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5399255275134465, "f1": 0.6634784352288294, "fuzzy_match": 0.5995035167563095, "2hops": {"exact_match": 0.5926517571884984, "f1": 0.7211920628899339, "fuzzy_match": 0.6645367412140575}, "3hops": {"exact_match": 0.5171052631578947, "f1": 0.6561213122742903, "fuzzy_match": 0.5789473684210527}, "4hops": {"exact_match": 0.41975308641975306, "f1": 0.4988709083491927, "fuzzy_match": 0.43703703703703706}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format.txt": {"hash": "a52a365ad92c7cfe0e821aac8ce9112c", "size": 96, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "aef38fcc75f94be1e4b9558ae8784dfa.dir", "size": 9701638, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "021bc51a1d73b9c0c094f0ecff29cf7c.dir", "size": 464936, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "aef38fcc75f94be1e4b9558ae8784dfa.dir", "size": 9701638, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "021bc51a1d73b9c0c094f0ecff29cf7c.dir", "size": 464936, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "b1e1e2caab02708f1d3391aa2f8c45ce", "size": 9585354, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/bae60626b3af0c1f99099da2d010431d8a25574b/bae60626b3af0c1f99099da2d010431d8a25574b.out", "pid": 2320845, "returncode": 0, "task_id": "bae60626b3af0c1f99099da2d010431d8a25574b"}}, "name": "pseud-buoy"}, {"revs": [{"rev": "1a96e7786dc4584a049ad1bc8217b83d4d0762fb", "name": "rummy-mobs", "data": {"rev": "1a96e7786dc4584a049ad1bc8217b83d4d0762fb", "timestamp": "2024-10-31T12:40:26", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5399255275134465, "f1": 0.6638841961915194, "fuzzy_match": 0.5999172527927182, "2hops": {"exact_match": 0.5958466453674122, "f1": 0.7249605816250685, "fuzzy_match": 0.6669329073482428}, "3hops": {"exact_match": 0.5171052631578947, "f1": 0.6532034999348826, "fuzzy_match": 0.5815789473684211}, "4hops": {"exact_match": 0.40987654320987654, "f1": 0.4951180099995209, "fuzzy_match": 0.4271604938271605}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format.txt": {"hash": "a52a365ad92c7cfe0e821aac8ce9112c", "size": 96, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "503efc18c74f7a60e12cfc5e7ce1844a.dir", "size": 9699541, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "fbac714436b335a91b2c459e4e451a6f.dir", "size": 464455, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "503efc18c74f7a60e12cfc5e7ce1844a.dir", "size": 9699541, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "fbac714436b335a91b2c459e4e451a6f.dir", "size": 464455, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "15a6ca39931f7be526114a53bb7808a8", "size": 9582727, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/2a3538d21ed3094d3c6e767fd2b00cfc3127bf51/2a3538d21ed3094d3c6e767fd2b00cfc3127bf51.out", "pid": 2320846, "returncode": 0, "task_id": "2a3538d21ed3094d3c6e767fd2b00cfc3127bf51"}}, "name": "rummy-mobs"}, {"revs": [{"rev": "ce3432bab86380d0c33d9653b0c2184103619a28", "name": "ducky-flip", "data": {"rev": "ce3432bab86380d0c33d9653b0c2184103619a28", "timestamp": "2024-10-31T11:55:13", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5697145221348779, "f1": 0.694208747980951, "fuzzy_match": 0.643773272652048, "2hops": {"exact_match": 0.6230031948881789, "f1": 0.7371074737521859, "fuzzy_match": 0.700479233226837}, "3hops": {"exact_match": 0.5407894736842105, "f1": 0.6937408536595843, "fuzzy_match": 0.6381578947368421}, "4hops": {"exact_match": 0.45925925925925926, "f1": 0.562471451730711, "fuzzy_match": 0.47901234567901235}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue.txt": {"hash": "bb5bc978acf0f8a75d991daf1db0b497", "size": 111, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "a000cfa77999cdd3a88361ebd36b3926.dir", "size": 9427457, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "6ace4dd2240da278920954d3d04726d5.dir", "size": 393974, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "a000cfa77999cdd3a88361ebd36b3926.dir", "size": 9427457, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "6ace4dd2240da278920954d3d04726d5.dir", "size": 393974, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "5630cca76672824e68fda2b7dd898620", "size": 9240619, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/32109f9bcc4601ff33d9da24d9ab3a12d9e70f7a/32109f9bcc4601ff33d9da24d9ab3a12d9e70f7a.out", "pid": 2321190, "returncode": 0, "task_id": "32109f9bcc4601ff33d9da24d9ab3a12d9e70f7a"}}, "name": "ducky-flip"}, {"revs": [{"rev": "25ba554abc99b9b268a2224614f2abf09503efb4", "name": "stung-dean", "data": {"rev": "25ba554abc99b9b268a2224614f2abf09503efb4", "timestamp": "2024-10-31T11:55:13", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue-least.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5668183698800165, "f1": 0.6784667506828832, "fuzzy_match": 0.6280513032685147, "2hops": {"exact_match": 0.6174121405750799, "f1": 0.7265278541336538, "fuzzy_match": 0.6789137380191693}, "3hops": {"exact_match": 0.5657894736842105, "f1": 0.6787709529892191, "fuzzy_match": 0.6394736842105263}, "4hops": {"exact_match": 0.4123456790123457, "f1": 0.5293218240824383, "fuzzy_match": 0.44938271604938274}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue-least.txt": {"hash": "25f7c2f0e8ac8e8b0fd9482db43def40", "size": 112, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "c95a215f153e6361f1bde95ea36b2ccd.dir", "size": 9416597, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "5ca34e0f3e95258fe84988ee9604a7f9.dir", "size": 391229, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "c95a215f153e6361f1bde95ea36b2ccd.dir", "size": 9416597, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "5ca34e0f3e95258fe84988ee9604a7f9.dir", "size": 391229, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "9871884a16cf2da06627c52f94f3b063", "size": 9227161, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/b55477c4a3b885b1c8ff7022525e17e45544f587/b55477c4a3b885b1c8ff7022525e17e45544f587.out", "pid": 2320860, "returncode": 0, "task_id": "b55477c4a3b885b1c8ff7022525e17e45544f587"}}, "name": "stung-dean"}, {"revs": [{"rev": "e943420b0e65c8fb34b3331f8196acf07d1b0cf1", "name": "tubby-razz", "data": {"rev": "e943420b0e65c8fb34b3331f8196acf07d1b0cf1", "timestamp": "2024-10-31T11:55:09", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5705419942076955, "f1": 0.6934940351537314, "fuzzy_match": 0.6425320645428216, "2hops": {"exact_match": 0.6214057507987221, "f1": 0.7356953274887058, "fuzzy_match": 0.6972843450479234}, "3hops": {"exact_match": 0.5434210526315789, "f1": 0.6925410711149876, "fuzzy_match": 0.6368421052631579}, "4hops": {"exact_match": 0.4641975308641975, "f1": 0.5648230096378244, "fuzzy_match": 0.4839506172839506}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue.txt": {"hash": "bb5bc978acf0f8a75d991daf1db0b497", "size": 111, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "e07bb9db44c57c92ca213ab220035ecb.dir", "size": 9426897, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "81cca0098a6158716ff7be467bbde752.dir", "size": 393805, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "e07bb9db44c57c92ca213ab220035ecb.dir", "size": 9426897, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "81cca0098a6158716ff7be467bbde752.dir", "size": 393805, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "3c33a392c36324ba1fd92a304111df2a", "size": 9239924, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/9627a41df3c5ecf802d2f3a19dcc01b7d5ba5412/9627a41df3c5ecf802d2f3a19dcc01b7d5ba5412.out", "pid": 2321194, "returncode": 0, "task_id": "9627a41df3c5ecf802d2f3a19dcc01b7d5ba5412"}}, "name": "tubby-razz"}, {"revs": [{"rev": "160fbef201132bc9e6cdef2b8cf37be6fa0d7f5d", "name": "axile-muss", "data": {"rev": "160fbef201132bc9e6cdef2b8cf37be6fa0d7f5d", "timestamp": "2024-10-31T11:55:09", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue-least.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5680595779892429, "f1": 0.6787760061385704, "fuzzy_match": 0.630947455523376, "2hops": {"exact_match": 0.6206070287539937, "f1": 0.7273727651625506, "fuzzy_match": 0.6837060702875399}, "3hops": {"exact_match": 0.5631578947368421, "f1": 0.6765077377616078, "fuzzy_match": 0.6394736842105263}, "4hops": {"exact_match": 0.4148148148148148, "f1": 0.5328025287767638, "fuzzy_match": 0.45185185185185184}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue-least.txt": {"hash": "25f7c2f0e8ac8e8b0fd9482db43def40", "size": 112, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "1e5feac2a3d75bc86569a1187ec2ddf9.dir", "size": 9415741, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "ab89f7668032b293d510f02f0f8a532e.dir", "size": 391019, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "1e5feac2a3d75bc86569a1187ec2ddf9.dir", "size": 9415741, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "ab89f7668032b293d510f02f0f8a532e.dir", "size": 391019, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "aa4533230e2309b41d155a22803511ce", "size": 9226085, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/146f5f11b8a2e1436b03ebb6bd0e55db2d18febb/146f5f11b8a2e1436b03ebb6bd0e55db2d18febb.out", "pid": 2321608, "returncode": 0, "task_id": "146f5f11b8a2e1436b03ebb6bd0e55db2d18febb"}}, "name": "axile-muss"}, {"revs": [{"rev": "39eb6c6cf5ad9d231eadec0d4aa7e26b94fe0e1a", "name": "bosom-trug", "data": {"rev": "39eb6c6cf5ad9d231eadec0d4aa7e26b94fe0e1a", "timestamp": "2024-10-31T11:55:06", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue-least.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5684733140256516, "f1": 0.6800936324960235, "fuzzy_match": 0.630947455523376, "2hops": {"exact_match": 0.6182108626198083, "f1": 0.7262500946611942, "fuzzy_match": 0.6805111821086262}, "3hops": {"exact_match": 0.5697368421052632, "f1": 0.6836128873706274, "fuzzy_match": 0.6460526315789473}, "4hops": {"exact_match": 0.4123456790123457, "f1": 0.5308034489515971, "fuzzy_match": 0.44938271604938274}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue-least.txt": {"hash": "25f7c2f0e8ac8e8b0fd9482db43def40", "size": 112, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "d4cf02fff355910d7619857d44ce2f9d.dir", "size": 9415093, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "18a07b7e0b9b339720d5fe5b1b83f8e6.dir", "size": 390885, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "d4cf02fff355910d7619857d44ce2f9d.dir", "size": 9415093, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "18a07b7e0b9b339720d5fe5b1b83f8e6.dir", "size": 390885, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "15cf7e55098a0bcd16f096da1ca652f7", "size": 9225289, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/de7a615caa45ec7721e055e52b10549ab3f989db/de7a615caa45ec7721e055e52b10549ab3f989db.out", "pid": 2321120, "returncode": 0, "task_id": "de7a615caa45ec7721e055e52b10549ab3f989db"}}, "name": "bosom-trug"}, {"revs": [{"rev": "ce933eab18c8921d3152923887140e9803284aad", "name": "diazo-snip", "data": {"rev": "ce933eab18c8921d3152923887140e9803284aad", "timestamp": "2024-10-30T15:47:02", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cot.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cot-2-shot.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5204799338022342, "f1": 0.6294411018522693, "fuzzy_match": 0.5908150599917252, "2hops": {"exact_match": 0.5958466453674122, "f1": 0.7059725640256772, "fuzzy_match": 0.6645367412140575}, "3hops": {"exact_match": 0.46578947368421053, "f1": 0.5778331128795525, "fuzzy_match": 0.5513157894736842}, "4hops": {"exact_match": 0.39012345679012345, "f1": 0.4896995734032771, "fuzzy_match": 0.43703703703703706}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cot.txt": {"hash": "88021337dd159156750cbb8a8f3e2dc6", "size": 175, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cot-2-shot.json": {"hash": "b536995986f0bff92e731a4ad4d36f81", "size": 2115, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "36aabccbf4a44f7c1072f67ffea9f2eb.dir", "size": 10139451, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "56cc28115b952702895c197676246fdf.dir", "size": 388259, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "36aabccbf4a44f7c1072f67ffea9f2eb.dir", "size": 10139451, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "56cc28115b952702895c197676246fdf.dir", "size": 388259, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "03f591310c9b40e5e263282231ca2276", "size": 9949271, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/3cddd10f99c0ece4d96db48f6a7a0a90e8775d62/3cddd10f99c0ece4d96db48f6a7a0a90e8775d62.out", "pid": 2135650, "returncode": 0, "task_id": "3cddd10f99c0ece4d96db48f6a7a0a90e8775d62"}}, "name": "diazo-snip"}, {"revs": [{"rev": "463ee7e30963372250123c455d5198233d536fd3", "name": "elect-wino", "data": {"rev": "463ee7e30963372250123c455d5198233d536fd3", "timestamp": "2024-10-30T15:46:43", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cot.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cot-2-shot.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5192387256930079, "f1": 0.6285752348293769, "fuzzy_match": 0.5883326437732727, "2hops": {"exact_match": 0.5902555910543131, "f1": 0.7017878836072636, "fuzzy_match": 0.6589456869009584}, "3hops": {"exact_match": 0.4710526315789474, "f1": 0.5838780316127652, "fuzzy_match": 0.5552631578947368}, "4hops": {"exact_match": 0.39012345679012345, "f1": 0.4861249587175513, "fuzzy_match": 0.43209876543209874}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cot.txt": {"hash": "88021337dd159156750cbb8a8f3e2dc6", "size": 175, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cot-2-shot.json": {"hash": "b536995986f0bff92e731a4ad4d36f81", "size": 2115, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "ecd77ce820507ec4e0d07793641dc857.dir", "size": 10136561, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "94b1524680b84570d38452c14d20f8f2.dir", "size": 388690, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "ecd77ce820507ec4e0d07793641dc857.dir", "size": 10136561, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "94b1524680b84570d38452c14d20f8f2.dir", "size": 388690, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "a4af2ba1aeba4264a96064453b592cac", "size": 9946677, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/6851aae2fcdb10c1a56beeaa6112603ce3b912e8/6851aae2fcdb10c1a56beeaa6112603ce3b912e8.out", "pid": 2135637, "returncode": 0, "task_id": "6851aae2fcdb10c1a56beeaa6112603ce3b912e8"}}, "name": "elect-wino"}, {"revs": [{"rev": "60cc2e6ff08d0bdb7367382c09aa2243e93b5848", "name": "pricy-mina", "data": {"rev": "60cc2e6ff08d0bdb7367382c09aa2243e93b5848", "timestamp": "2024-10-30T15:46:37", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cot.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cot-2-shot.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5200661977658254, "f1": 0.6274533639277052, "fuzzy_match": 0.5904013239553165, "2hops": {"exact_match": 0.5926517571884984, "f1": 0.6992505481543826, "fuzzy_match": 0.6597444089456869}, "3hops": {"exact_match": 0.4644736842105263, "f1": 0.5801823376571827, "fuzzy_match": 0.5539473684210526}, "4hops": {"exact_match": 0.4, "f1": 0.4942086856901672, "fuzzy_match": 0.4444444444444444}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cot.txt": {"hash": "88021337dd159156750cbb8a8f3e2dc6", "size": 175, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cot-2-shot.json": {"hash": "b536995986f0bff92e731a4ad4d36f81", "size": 2115, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "2bb0a2abc3b07cd7d27f3a527f82f63f.dir", "size": 10133525, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "35f5750b500192f08ce6f91918dbfbcc.dir", "size": 387655, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "2bb0a2abc3b07cd7d27f3a527f82f63f.dir", "size": 10133525, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "35f5750b500192f08ce6f91918dbfbcc.dir", "size": 387655, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "a6aa6b81fd2d321b1528c415758341c7", "size": 9942741, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/71da6b861cf559205127a2c6684d838a779cbc0b/71da6b861cf559205127a2c6684d838a779cbc0b.out", "pid": 2135638, "returncode": 0, "task_id": "71da6b861cf559205127a2c6684d838a779cbc0b"}}, "name": "pricy-mina"}, {"revs": [{"rev": "13f75d3bd561db96119cedce218877c89dbdc8bf", "name": "volar-tiff", "data": {"rev": "13f75d3bd561db96119cedce218877c89dbdc8bf", "timestamp": "2024-10-30T15:03:37", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cte.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cte-2-shot.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.6235002068680182, "f1": 0.7409918920689543, "fuzzy_match": 0.6818369880016549, "2hops": {"exact_match": 0.6597444089456869, "f1": 0.7669865653360233, "fuzzy_match": 0.7244408945686901}, "3hops": {"exact_match": 0.6289473684210526, "f1": 0.7668211241373007, "fuzzy_match": 0.6868421052631579}, "4hops": {"exact_match": 0.5012345679012346, "f1": 0.6121633802113904, "fuzzy_match": 0.5407407407407407}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cte.txt": {"hash": "0d0d2d8712ac90d790ba7a8def4be6d3", "size": 301, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cte-2-shot.json": {"hash": "5ce5053d023f6717df1ab4adf4c31230", "size": 1752, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "bf29f7d37234e68b1656390408f7405c.dir", "size": 9825355, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "e5eb13e28780e649e33a0af22def862d.dir", "size": 404050, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "bf29f7d37234e68b1656390408f7405c.dir", "size": 9825355, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "e5eb13e28780e649e33a0af22def862d.dir", "size": 404050, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "ea6fe6591a99ec8fc14c2223deea8ed0", "size": 9649831, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/83e08bb81af247acd6f6033975a0e7b676f36ef9/83e08bb81af247acd6f6033975a0e7b676f36ef9.out", "pid": 2136540, "returncode": 0, "task_id": "83e08bb81af247acd6f6033975a0e7b676f36ef9"}}, "name": "volar-tiff"}, {"revs": [{"rev": "775b04058608cf77cf87af5752d46b5f4fef8c1c", "name": "broch-loge", "data": {"rev": "775b04058608cf77cf87af5752d46b5f4fef8c1c", "timestamp": "2024-10-30T15:03:21", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cte.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cte-2-shot.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.6305337194869673, "f1": 0.7447350447446701, "fuzzy_match": 0.6859743483657427, "2hops": {"exact_match": 0.6589456869009584, "f1": 0.7668876047456401, "fuzzy_match": 0.7228434504792333}, "3hops": {"exact_match": 0.6421052631578947, "f1": 0.7729962883168267, "fuzzy_match": 0.6934210526315789}, "4hops": {"exact_match": 0.5209876543209877, "f1": 0.6232201058902179, "fuzzy_match": 0.5580246913580247}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cte.txt": {"hash": "0d0d2d8712ac90d790ba7a8def4be6d3", "size": 301, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cte-2-shot.json": {"hash": "5ce5053d023f6717df1ab4adf4c31230", "size": 1752, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "22b2d8789bc65cb39b1703e56ee36ac1.dir", "size": 9823133, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "90a595b1cc8779f582b13486029b9e45.dir", "size": 403448, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "22b2d8789bc65cb39b1703e56ee36ac1.dir", "size": 9823133, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "90a595b1cc8779f582b13486029b9e45.dir", "size": 403448, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "7fb0c750d30136bd3371202d29c887b9", "size": 9646808, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/6d37c5070acd7474f628f29de887e549ae585b3e/6d37c5070acd7474f628f29de887e549ae585b3e.out", "pid": 2135719, "returncode": 0, "task_id": "6d37c5070acd7474f628f29de887e549ae585b3e"}}, "name": "broch-loge"}, {"revs": [{"rev": "ac87423c19a8c8b83d710269d16fc9e6f5d6df95", "name": "hazel-bunt", "data": {"rev": "ac87423c19a8c8b83d710269d16fc9e6f5d6df95", "timestamp": "2024-10-30T15:03:18", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "cte.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "cte-2-shot.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.627637567232106, "f1": 0.7438329944348051, "fuzzy_match": 0.6847331402565163, "2hops": {"exact_match": 0.6621405750798722, "f1": 0.7691883713116613, "fuzzy_match": 0.7236421725239617}, "3hops": {"exact_match": 0.631578947368421, "f1": 0.7664118281173768, "fuzzy_match": 0.6868421052631579}, "4hops": {"exact_match": 0.5135802469135803, "f1": 0.6230802896234995, "fuzzy_match": 0.5604938271604938}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/cte.txt": {"hash": "0d0d2d8712ac90d790ba7a8def4be6d3", "size": 301, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/cte-2-shot.json": {"hash": "5ce5053d023f6717df1ab4adf4c31230", "size": 1752, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "4db7943f2effa1a54c2ef70f4ee5a55b.dir", "size": 9822626, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "c478563837a00512f8ab35128cc1ea6f.dir", "size": 403264, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "4db7943f2effa1a54c2ef70f4ee5a55b.dir", "size": 9822626, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "c478563837a00512f8ab35128cc1ea6f.dir", "size": 403264, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "56f2837dc786707245c088696c89e696", "size": 9646394, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/d16812a8453c51e25497e428e221b5c2b8b07b83/d16812a8453c51e25497e428e221b5c2b8b07b83.out", "pid": 2136828, "returncode": 0, "task_id": "d16812a8453c51e25497e428e221b5c2b8b07b83"}}, "name": "hazel-bunt"}, {"revs": [{"rev": "4df5a3d1c4950a49cf9a0196fea647bdbf4fb96f", "name": "leggy-maya", "data": {"rev": "4df5a3d1c4950a49cf9a0196fea647bdbf4fb96f", "timestamp": "2024-10-30T13:44:11", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format.txt", "user_prompt_template": "cq-sep.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5403392635498552, "f1": 0.6637985839194157, "fuzzy_match": 0.5986760446834919, "2hops": {"exact_match": 0.59185303514377, "f1": 0.7214989523933062, "fuzzy_match": 0.6621405750798722}, "3hops": {"exact_match": 0.5210526315789473, "f1": 0.6560346904163183, "fuzzy_match": 0.5815789473684211}, "4hops": {"exact_match": 0.41728395061728396, "f1": 0.4999953684454485, "fuzzy_match": 0.4345679012345679}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format.txt": {"hash": "a52a365ad92c7cfe0e821aac8ce9112c", "size": 96, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq-sep.txt": {"hash": "2100d7906a5933fcb76f607a0408d1cc", "size": 42, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "39e17c1065e95ceab254a81b23bef162.dir", "size": 9702477, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "89d09c11da63ef9a3994de73f294fe4e.dir", "size": 465059, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "39e17c1065e95ceab254a81b23bef162.dir", "size": 9702477, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "89d09c11da63ef9a3994de73f294fe4e.dir", "size": 465059, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "519541c8267928e805b5e88d3da03c34", "size": 9586362, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/95c50fa892db7b4f532a4e105115c715876df8a8/95c50fa892db7b4f532a4e105115c715876df8a8.out", "pid": 2135723, "returncode": 0, "task_id": "95c50fa892db7b4f532a4e105115c715876df8a8"}}, "name": "leggy-maya"}, {"revs": [{"rev": "dc2e765aeb1b84f0c5db6b4640a1ed79e79dd782", "name": "rival-hems", "data": {"rev": "dc2e765aeb1b84f0c5db6b4640a1ed79e79dd782", "timestamp": "2024-10-30T13:28:59", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-fewest.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5639222176251552, "f1": 0.6773554900178509, "fuzzy_match": 0.6326023996690112, "2hops": {"exact_match": 0.6134185303514377, "f1": 0.7246840055243204, "fuzzy_match": 0.6813099041533547}, "3hops": {"exact_match": 0.5460526315789473, "f1": 0.6716201378607323, "fuzzy_match": 0.6342105263157894}, "4hops": {"exact_match": 0.4444444444444444, "f1": 0.5418087399568882, "fuzzy_match": 0.47901234567901235}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-fewest.txt": {"hash": "7fa9cb6698054df80d424f77d1ba3186", "size": 259, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "23f4be2b17b0a1d92f9e0ec6c3295eaa.dir", "size": 9425057, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "6624f54ccfa27fced041d44743ed57f6.dir", "size": 393176, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "23f4be2b17b0a1d92f9e0ec6c3295eaa.dir", "size": 9425057, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "6624f54ccfa27fced041d44743ed57f6.dir", "size": 393176, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "8dbd2bed0c511e3d3c72c392c6579b37", "size": 9237749, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/528c1f684b7a2988400beb262c49eaeb156513a9/528c1f684b7a2988400beb262c49eaeb156513a9.out", "pid": 2136539, "returncode": 0, "task_id": "528c1f684b7a2988400beb262c49eaeb156513a9"}}, "name": "rival-hems"}, {"revs": [{"rev": "4f8f489211c96904b06236669e86c3e568dedb52", "name": "white-hask", "data": {"rev": "4f8f489211c96904b06236669e86c3e568dedb52", "timestamp": "2024-10-30T13:28:51", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-fewest.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.564335953661564, "f1": 0.6777751631465772, "fuzzy_match": 0.6326023996690112, "2hops": {"exact_match": 0.6134185303514377, "f1": 0.7247143198611561, "fuzzy_match": 0.6797124600638977}, "3hops": {"exact_match": 0.5473684210526316, "f1": 0.6725028231855451, "fuzzy_match": 0.6355263157894737}, "4hops": {"exact_match": 0.4444444444444444, "f1": 0.5425631981187536, "fuzzy_match": 0.48148148148148145}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-fewest.txt": {"hash": "7fa9cb6698054df80d424f77d1ba3186", "size": 259, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "8daca68cf983c66a6a80c5c243154e3f.dir", "size": 9424361, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "f5f62590ed66b3026fd1b946af4f4b49.dir", "size": 393003, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "8daca68cf983c66a6a80c5c243154e3f.dir", "size": 9424361, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "f5f62590ed66b3026fd1b946af4f4b49.dir", "size": 393003, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "1681be6f6693577aba5801a207dc67ff", "size": 9236860, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/8efb270fc054f5875aeec208151fe016a3effed9/8efb270fc054f5875aeec208151fe016a3effed9.out", "pid": 2136336, "returncode": 0, "task_id": "8efb270fc054f5875aeec208151fe016a3effed9"}}, "name": "white-hask"}, {"revs": [{"rev": "08c87a1db610fd53f41e0480d7b8ab7eba372dce", "name": "briny-rims", "data": {"rev": "08c87a1db610fd53f41e0480d7b8ab7eba372dce", "timestamp": "2024-10-30T13:28:51", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "excellent-qa-fewest.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5622672734795201, "f1": 0.6761195920096441, "fuzzy_match": 0.630947455523376, "2hops": {"exact_match": 0.6094249201277955, "f1": 0.7220781399246566, "fuzzy_match": 0.6773162939297125}, "3hops": {"exact_match": 0.5486842105263158, "f1": 0.6732105478321492, "fuzzy_match": 0.6368421052631579}, "4hops": {"exact_match": 0.4419753086419753, "f1": 0.539504213207917, "fuzzy_match": 0.4765432098765432}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/excellent-qa-fewest.txt": {"hash": "7fa9cb6698054df80d424f77d1ba3186", "size": 259, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "b67a2cb46ed4d929f9bd1eb0c4b3d12b.dir", "size": 9425809, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "0ff65d1e1198baffc23ba16d2cd9d99a.dir", "size": 393410, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "b67a2cb46ed4d929f9bd1eb0c4b3d12b.dir", "size": 9425809, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "0ff65d1e1198baffc23ba16d2cd9d99a.dir", "size": 393410, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "fa136699597f3fc03a5bed5999026fcd", "size": 9238728, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/c679f140270ab6b1cc2acae21209d4d8098bc28b/c679f140270ab6b1cc2acae21209d4d8098bc28b.out", "pid": 2136808, "returncode": 0, "task_id": "c679f140270ab6b1cc2acae21209d4d8098bc28b"}}, "name": "briny-rims"}, {"revs": [{"rev": "da42a9ed656b464663afea07c631760fd5a82559", "name": "sunny-mash", "data": {"rev": "da42a9ed656b464663afea07c631760fd5a82559", "timestamp": "2024-10-30T13:28:14", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue-least.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5676458419528341, "f1": 0.6798539258341856, "fuzzy_match": 0.6284650393049235, "2hops": {"exact_match": 0.6134185303514377, "f1": 0.722453068045198, "fuzzy_match": 0.6733226837060703}, "3hops": {"exact_match": 0.5697368421052632, "f1": 0.6885782987795371, "fuzzy_match": 0.6473684210526316}, "4hops": {"exact_match": 0.4222222222222222, "f1": 0.531793062904174, "fuzzy_match": 0.454320987654321}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue-least.txt": {"hash": "25f7c2f0e8ac8e8b0fd9482db43def40", "size": 112, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "e60ef8da0c8c0f288580afd73eb2abd4.dir", "size": 9420077, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "c41a0e8f6894be89ef52deee0bba1301.dir", "size": 392032, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "e60ef8da0c8c0f288580afd73eb2abd4.dir", "size": 9420077, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "c41a0e8f6894be89ef52deee0bba1301.dir", "size": 392032, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "714c52630bf17ffb102416476186b5bd", "size": 9231439, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/50149f6b20d20c16fa67167fc376dc215172a14e/50149f6b20d20c16fa67167fc376dc215172a14e.out", "pid": 2136083, "returncode": 0, "task_id": "50149f6b20d20c16fa67167fc376dc215172a14e"}}, "name": "sunny-mash"}, {"revs": [{"rev": "5064082b1a8bc73c707daec912627df644f6488c", "name": "beery-dawk", "data": {"rev": "5064082b1a8bc73c707daec912627df644f6488c", "timestamp": "2024-10-30T13:28:14", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue-least.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5676458419528341, "f1": 0.6792070642859239, "fuzzy_match": 0.6284650393049235, "2hops": {"exact_match": 0.6142172523961661, "f1": 0.7214640905596676, "fuzzy_match": 0.6749201277955271}, "3hops": {"exact_match": 0.5723684210526315, "f1": 0.6890202021490721, "fuzzy_match": 0.6486842105263158}, "4hops": {"exact_match": 0.4148148148148148, "f1": 0.5301606897903194, "fuzzy_match": 0.4469135802469136}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue-least.txt": {"hash": "25f7c2f0e8ac8e8b0fd9482db43def40", "size": 112, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "ad5ea9f2bed7b5528051816bdb8846b7.dir", "size": 9419085, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "124e2283666221a0cf9711d7b7ccfa4f.dir", "size": 391774, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "ad5ea9f2bed7b5528051816bdb8846b7.dir", "size": 9419085, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "124e2283666221a0cf9711d7b7ccfa4f.dir", "size": 391774, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "b8195143e3b05510214c36aeaa578175", "size": 9230214, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/d1d695b2cc0e4023ca400d799af81432b68cdc7c/d1d695b2cc0e4023ca400d799af81432b68cdc7c.out", "pid": 2135636, "returncode": 0, "task_id": "d1d695b2cc0e4023ca400d799af81432b68cdc7c"}}, "name": "beery-dawk"}, {"revs": [{"rev": "ce6df76fa5a3ec4e39e93338833dc01abef74679", "name": "tinct-toby", "data": {"rev": "ce6df76fa5a3ec4e39e93338833dc01abef74679", "timestamp": "2024-10-30T13:27:57", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5734381464625569, "f1": 0.6991782811390698, "fuzzy_match": 0.6421183285064129, "2hops": {"exact_match": 0.6198083067092651, "f1": 0.7367964871012627, "fuzzy_match": 0.6940894568690096}, "3hops": {"exact_match": 0.5513157894736842, "f1": 0.7057306539349884, "fuzzy_match": 0.6407894736842106}, "4hops": {"exact_match": 0.47160493827160493, "f1": 0.5705911275845915, "fuzzy_match": 0.4839506172839506}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue.txt": {"hash": "bb5bc978acf0f8a75d991daf1db0b497", "size": 111, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "0798a1c129fdc7e09c51d944027a6fb4.dir", "size": 9429009, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "045c45d53f35819ed9a465a6de347e92.dir", "size": 394633, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "0798a1c129fdc7e09c51d944027a6fb4.dir", "size": 9429009, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "045c45d53f35819ed9a465a6de347e92.dir", "size": 394633, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "c083ab8562a6dd2076063b43a3b0ccd7", "size": 9242706, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/9bf6d0eb66e4ef8482310694d9540669b0478695/9bf6d0eb66e4ef8482310694d9540669b0478695.out", "pid": 2136809, "returncode": 0, "task_id": "9bf6d0eb66e4ef8482310694d9540669b0478695"}}, "name": "tinct-toby"}, {"revs": [{"rev": "cf646c7a8f1f50d284c0e92a6732c49a89c773af", "name": "young-veil", "data": {"rev": "cf646c7a8f1f50d284c0e92a6732c49a89c773af", "timestamp": "2024-10-30T13:27:40", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue-least.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5684733140256516, "f1": 0.6792536543968608, "fuzzy_match": 0.6301199834505585, "2hops": {"exact_match": 0.6110223642172524, "f1": 0.7197656871377062, "fuzzy_match": 0.6741214057507987}, "3hops": {"exact_match": 0.575, "f1": 0.6906724074768315, "fuzzy_match": 0.65}, "4hops": {"exact_match": 0.4246913580246914, "f1": 0.5325886733294141, "fuzzy_match": 0.4567901234567901}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue-least.txt": {"hash": "25f7c2f0e8ac8e8b0fd9482db43def40", "size": 112, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "3339495f03f1383e4dc4c1653a279a67.dir", "size": 9418545, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "11cdc34e71135aa5d7d802a7faf2b5d2.dir", "size": 391636, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "3339495f03f1383e4dc4c1653a279a67.dir", "size": 9418545, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "11cdc34e71135aa5d7d802a7faf2b5d2.dir", "size": 391636, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "338ce52e1838abc26739889e1d738963", "size": 9229535, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/bd5a68a3528c42a55761efefef451228739e59c1/bd5a68a3528c42a55761efefef451228739e59c1.out", "pid": 2135714, "returncode": 0, "task_id": "bd5a68a3528c42a55761efefef451228739e59c1"}}, "name": "young-veil"}, {"revs": [{"rev": "8d1d85a68fdc09577784a93f427a92cdd9117a18", "name": "utile-genu", "data": {"rev": "8d1d85a68fdc09577784a93f427a92cdd9117a18", "timestamp": "2024-10-30T13:27:37", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5730244104261482, "f1": 0.6994027470222918, "fuzzy_match": 0.6417045924700041, "2hops": {"exact_match": 0.6190095846645367, "f1": 0.7362309709795837, "fuzzy_match": 0.6924920127795527}, "3hops": {"exact_match": 0.5513157894736842, "f1": 0.7080000529226536, "fuzzy_match": 0.6407894736842106}, "4hops": {"exact_match": 0.47160493827160493, "f1": 0.5694203053462312, "fuzzy_match": 0.48641975308641977}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue.txt": {"hash": "bb5bc978acf0f8a75d991daf1db0b497", "size": 111, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "4bad9ebf3c4d55adf16b7812a742d957.dir", "size": 9429357, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "2bb1be4da66ed1943b2e3465c3808970.dir", "size": 394719, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "4bad9ebf3c4d55adf16b7812a742d957.dir", "size": 9429357, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "2bb1be4da66ed1943b2e3465c3808970.dir", "size": 394719, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "08ccd3568f79c26a142a841b5b6c9811", "size": 9243115, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/8dc02717b1c4a8e996ebce4f6c0dbdb4e5a53038/8dc02717b1c4a8e996ebce4f6c0dbdb4e5a53038.out", "pid": 2135657, "returncode": 0, "task_id": "8dc02717b1c4a8e996ebce4f6c0dbdb4e5a53038"}}, "name": "utile-genu"}, {"revs": [{"rev": "92caac0879d374bfb72d2e39a9d54a07cf88a054", "name": "bovid-mold", "data": {"rev": "92caac0879d374bfb72d2e39a9d54a07cf88a054", "timestamp": "2024-10-30T13:27:26", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-cue.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5746793545717832, "f1": 0.7000524721360494, "fuzzy_match": 0.6441870086884568, "2hops": {"exact_match": 0.6246006389776357, "f1": 0.740071722492419, "fuzzy_match": 0.6972843450479234}, "3hops": {"exact_match": 0.5486842105263158, "f1": 0.7062611468339022, "fuzzy_match": 0.6421052631578947}, "4hops": {"exact_match": 0.4691358024691358, "f1": 0.5646877950581655, "fuzzy_match": 0.4839506172839506}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-cue.txt": {"hash": "bb5bc978acf0f8a75d991daf1db0b497", "size": 111, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "48a474831aeda3ad78e7d56d73fa6424.dir", "size": 9429257, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "7368fea9c3e7fe87a3217164b5b0e9a6.dir", "size": 394676, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "48a474831aeda3ad78e7d56d73fa6424.dir", "size": 9429257, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "7368fea9c3e7fe87a3217164b5b0e9a6.dir", "size": 394676, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "0000cecf70115573fb3fa9fa7fdadb12", "size": 9243001, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/e016f3d08fc6e337d7c4ccfd1dea65c53d350e72/e016f3d08fc6e337d7c4ccfd1dea65c53d350e72.out", "pid": 2135717, "returncode": 0, "task_id": "e016f3d08fc6e337d7c4ccfd1dea65c53d350e72"}}, "name": "bovid-mold"}, {"revs": [{"rev": "32184cf41adf5b6c7872aef0e3cdeb113ef707aa", "name": "muddy-luke", "data": {"rev": "32184cf41adf5b6c7872aef0e3cdeb113ef707aa", "timestamp": "2024-10-30T13:16:18", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-few-no-prio.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 2}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5664046338436077, "f1": 0.6906026615037606, "fuzzy_match": 0.6367397600330988, "2hops": {"exact_match": 0.6142172523961661, "f1": 0.7253019270899023, "fuzzy_match": 0.6884984025559105}, "3hops": {"exact_match": 0.5368421052631579, "f1": 0.6959764276830841, "fuzzy_match": 0.6289473684210526}, "4hops": {"exact_match": 0.4740740740740741, "f1": 0.5732507039478717, "fuzzy_match": 0.49135802469135803}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-few-no-prio.txt": {"hash": "a4ffbc2d4c7be6f3796396e6c32acb33", "size": 147, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "646310039cd17f4e428299379743ca94.dir", "size": 9428301, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "effafd0fd1242e800cd855f28eddba88.dir", "size": 394395, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "646310039cd17f4e428299379743ca94.dir", "size": 9428301, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "effafd0fd1242e800cd855f28eddba88.dir", "size": 394395, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "a12215f7a6208abc812c86707dc450c8", "size": 9241777, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/608b80a90ea0af3753c81084731b0e15c70ef613/608b80a90ea0af3753c81084731b0e15c70ef613.out", "pid": 2132497, "returncode": 0, "task_id": "608b80a90ea0af3753c81084731b0e15c70ef613"}}, "name": "muddy-luke"}, {"revs": [{"rev": "2029ad367cd0b1ee841676bfb418665c7391b48f", "name": "oared-nark", "data": {"rev": "2029ad367cd0b1ee841676bfb418665c7391b48f", "timestamp": "2024-10-30T13:16:17", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-few-no-prio.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 1}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5680595779892429, "f1": 0.6920395254279275, "fuzzy_match": 0.6379809681423252, "2hops": {"exact_match": 0.6166134185303515, "f1": 0.7273671389131853, "fuzzy_match": 0.6900958466453674}, "3hops": {"exact_match": 0.5407894736842105, "f1": 0.6978456227295238, "fuzzy_match": 0.631578947368421}, "4hops": {"exact_match": 0.4691358024691358, "f1": 0.5719338315198882, "fuzzy_match": 0.4888888888888889}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-few-no-prio.txt": {"hash": "a4ffbc2d4c7be6f3796396e6c32acb33", "size": 147, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "c826e5c06c43351671be6a41228460ec.dir", "size": 9427717, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "74deab83217b07a78e0abbc8842d9f36.dir", "size": 394237, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "c826e5c06c43351671be6a41228460ec.dir", "size": 9427717, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "74deab83217b07a78e0abbc8842d9f36.dir", "size": 394237, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "aee55857087296fd28fefb92a29fdd26", "size": 9241092, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/1b2733266bbd3ace202ea9ae89f76eefd4476010/1b2733266bbd3ace202ea9ae89f76eefd4476010.out", "pid": 2132495, "returncode": 0, "task_id": "1b2733266bbd3ace202ea9ae89f76eefd4476010"}}, "name": "oared-nark"}, {"revs": [{"rev": "8709ca59c9b429c22e7edd8c41bcb3d7a8ca3354", "name": "bared-hill", "data": {"rev": "8709ca59c9b429c22e7edd8c41bcb3d7a8ca3354", "timestamp": "2024-10-30T13:16:13", "params": {"pipelines/qa-prompt-optim/params.yaml": {"data": {"train": {"dataset": {"path": "bdsaglam/musique-mini", "name": "answerable", "split": "train"}, "optimizer": "noop"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "technique": "standard"}, "evaluation": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}}, "run": 1}}, "pipelines/research-mhqa-evaluation/params.yaml": {"data": {"dataset": {"path": "bdsaglam/musique", "name": "answerable", "split": "validation"}, "qa": {"model": "llama-3-70b-tgi", "temperature": 0.1, "system_prompt": "minimal-output-format-answer-few-no-prio.txt", "user_prompt_template": "cq.txt", "few_shot_examples": "empty.json"}, "run": 3}}}, "metrics": {"data/generated/qa-prompt-optim/evaluation/scores.json": {"data": {"exact_match": 0.55, "f1": 0.6629834609834611, "fuzzy_match": 0.61, "2hops": {"exact_match": 0.6, "f1": 0.7348075258075258, "fuzzy_match": 0.68}, "3hops": {"exact_match": 0.59, "f1": 0.6825476190476191, "fuzzy_match": 0.64}, "4hops": {"exact_match": 0.46, "f1": 0.5715952380952382, "fuzzy_match": 0.51}}}, "data/generated/research-mhqa-evaluation/reports/scores.json": {"data": {"exact_match": 0.5655771617707902, "f1": 0.6904509446338416, "fuzzy_match": 0.634671079851055, "2hops": {"exact_match": 0.615814696485623, "f1": 0.7271957333386599, "fuzzy_match": 0.6876996805111821}, "3hops": {"exact_match": 0.5381578947368421, "f1": 0.6963460097264277, "fuzzy_match": 0.6289473684210526}, "4hops": {"exact_match": 0.4617283950617284, "f1": 0.5657973028343398, "fuzzy_match": 0.48148148148148145}}}}, "deps": {"pipelines/qa-prompt-optim/main.py": {"hash": "32a3b06f59271b13ab0119fc92c3b701", "size": 6925, "nfiles": null}, "data/raw/qa-prompt-optim/optimizer-configs/noop.json": {"hash": "37a6259cc0c1dae299a7866489dff0bd", "size": 4, "nfiles": null}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null}, "pipelines/research-mhqa-evaluation/answer_questions.py": {"hash": "7dab1ff2b395a71e86fb452478cba565", "size": 3711, "nfiles": null}, "data/raw/research-mhqa-evaluation/system-prompts/minimal-output-format-answer-few-no-prio.txt": {"hash": "a4ffbc2d4c7be6f3796396e6c32acb33", "size": 147, "nfiles": null}, "data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt": {"hash": "ac4fa9e31f4b2f7d489ceaae22dbc7ea", "size": 41, "nfiles": null}, "data/raw/research-mhqa-evaluation/few-shot-examples/empty.json": {"hash": "d751713988987e9331980363e24189ce", "size": 2, "nfiles": null}, "pipelines/research-mhqa-evaluation/evaluate_answers.py": {"hash": "959c3effd5a2abd57858463f9f8e4471", "size": 1940, "nfiles": null}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "34d4315d723a34c6e1a6dd132f5d03af.dir", "size": 9428121, "nfiles": 2418}, "pipelines/research-mhqa-evaluation/report.py": {"hash": "5e6c18bc9c310dc222026920268cbb6b", "size": 2148, "nfiles": null}, "data/generated/research-mhqa-evaluation/evals": {"hash": "10bc3ac7c1ddb18ff9fdcce1afd44ed5.dir", "size": 394364, "nfiles": 2418}}, "outs": {"data/raw": {"hash": "0598c65d8afd37282d02a8b1337ff922.dir", "size": 11799, "nfiles": 36, "use_cache": true, "is_data_source": true}, "data/generated/qa-prompt-optim/training/trained-program.json": {"hash": "e5542f827baec8c8a90f98af3f5cbf64", "size": 528, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/qa-prompt-optim/evaluation/results.jsonl": {"hash": "a5b8571b578ecf10fd095cd7ebcbe4dc", "size": 741013, "nfiles": null, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/qa-results": {"hash": "34d4315d723a34c6e1a6dd132f5d03af.dir", "size": 9428121, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/evals": {"hash": "10bc3ac7c1ddb18ff9fdcce1afd44ed5.dir", "size": 394364, "nfiles": 2418, "use_cache": true, "is_data_source": false}, "data/generated/research-mhqa-evaluation/reports/results.jsonl": {"hash": "a892fe117c56ed4a6a357ff87695171f", "size": 9241548, "nfiles": null, "use_cache": true, "is_data_source": false}}, "meta": {}}, "error": null, "experiments": null}], "executor": {"state": "success", "name": "dvc-task", "local": {"root": null, "log": "/home/pc/Documents/baris/bellem/.dvc/tmp/exps/run/61a8bfbd35b80c3ac29cf6c0d82a62eb93db255e/61a8bfbd35b80c3ac29cf6c0d82a62eb93db255e.out", "pid": 2132567, "returncode": 0, "task_id": "61a8bfbd35b80c3ac29cf6c0d82a62eb93db255e"}}, "name": "bared-hill"}]}]
